<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p><img src="https://github.com/user-attachments/assets/77792d79-db23-4b2a-b4fa-29d10b83b8db" alt="tmm-59dd890f48435e692c47919d0df4a5e6">— layout: post title: Speed up matrix multiplication 2<br> date: 2024-11-12 07:59:00-0400 description:<br> tags: ai ml matrix multiplication categories: ml featured: false —</p> <h3 id="benefits-of-tiling">Benefits of Tiling</h3> <p>Reduced Global Memory Accesses:</p> <p>By loading tiles into shared memory, we reduce the number of global memory accesses, which are slower compared to shared memory accesses.</p> <p>Improved Cache Efficiency:</p> <p>Tiling improves cache efficiency by ensuring that data is reused within the shared memory, reducing the need to fetch data from global memory multiple times.</p> <p>Better Utilization of GPU Resources:</p> <p>Tiling allows for better utilization of the GPU’s computational resources by dividing the work into smaller, manageable chunks that fit into the GPU’s shared memory.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kt">void</span> <span class="nf">matrixMulTile</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="kt">int</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">size</span> <span class="o">=</span> <span class="n">width</span> <span class="o">*</span> <span class="n">width</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">);</span>
  <span class="kt">int</span> <span class="o">*</span><span class="n">dev_a</span><span class="p">,</span> <span class="o">*</span><span class="n">dev_b</span><span class="p">,</span> <span class="o">*</span><span class="n">dev_c</span><span class="p">;</span>

    <span class="c1">// Allocate device memory</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_b</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_c</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>

    <span class="c1">// Copy matrices to device memory</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">dev_b</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

  <span class="n">dim3</span> <span class="n">dimBlock</span><span class="p">(</span><span class="n">TILE_WIDTH</span><span class="p">,</span> <span class="n">TILE_WIDTH</span><span class="p">);</span>
  <span class="n">dim3</span> <span class="n">dimGrid</span><span class="p">((</span><span class="n">width</span> <span class="o">+</span> <span class="n">TILE_WIDTH</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span> <span class="n">TILE_WIDTH</span><span class="p">,</span> <span class="p">(</span><span class="n">width</span><span class="o">+</span><span class="n">TILE_WIDTH</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span> <span class="n">TILE_WIDTH</span><span class="p">);</span>
  <span class="n">matrixMulTileKernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">dimGrid</span><span class="p">,</span> <span class="n">dimBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">dev_b</span><span class="p">,</span> <span class="n">dev_c</span><span class="p">,</span> <span class="n">width</span><span class="p">);</span>
  <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>

  <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">dev_c</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>

  <span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_a</span><span class="p">);</span>
  <span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_b</span><span class="p">);</span>
  <span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_c</span><span class="p">);</span>


<span class="p">}</span>

<span class="cp">#define TILE_WIDTH 16
</span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">matrixMulTileKernel</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">da</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">db</span><span class="p">,</span> <span class="kt">int</span><span class="o">*</span><span class="n">dout</span><span class="p">,</span> <span class="kt">int</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">__shared__</span> <span class="kt">int</span> <span class="n">tile_A</span><span class="p">[</span><span class="n">TILE_WIDTH</span> <span class="p">][</span><span class="n">TILE_WIDTH</span><span class="p">];</span>
  <span class="n">__shared__</span> <span class="kt">int</span> <span class="n">tile_B</span><span class="p">[</span><span class="n">TILE_WIDTH</span><span class="p">][</span><span class="n">TILE_WIDTH</span><span class="p">];</span>

  <span class="kt">int</span> <span class="n">row</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">col</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

  <span class="kt">int</span> <span class="n">value</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">width</span><span class="o">+</span><span class="n">TILE_WIDTH</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">TILE_WIDTH</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span> <span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span><span class="p">(</span><span class="n">row</span> <span class="o">&lt;</span> <span class="n">width</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>

      <span class="n">tile_A</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">da</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">width</span> <span class="o">+</span> <span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">)];</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="n">tile_A</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">if</span><span class="p">(</span><span class="n">col</span> <span class="o">&lt;</span> <span class="n">width</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">tile_B</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">db</span><span class="p">[(</span><span class="n">i</span><span class="o">*</span><span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="n">col</span><span class="p">];</span>

    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="n">tile_B</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">__syncthreads</span><span class="p">();</span>

    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">TILE_WIDTH</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">value</span> <span class="o">+=</span> <span class="n">tile_A</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">tile_B</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
    <span class="p">}</span>
    <span class="n">__syncthreads</span><span class="p">();</span>


  <span class="p">}</span>

  <span class="n">dout</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">width</span> <span class="o">+</span> <span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="p">;</span>

<span class="p">}</span>
</code></pre></div></div> <p>This code means that we have one thread for each output element in output matrix.</p> <p>Each block of threads cooperatively loads chunks tiles of A and B into shared memory. This is done in a loop to cover all tiles that contribute to final result for the block.</p> <p><a href="https://penny-xu.github.io/blog/tiled-matrix-multiplication" rel="external nofollow noopener" target="_blank">Another post that talk about the tiling matrix multiplication</a></p> <h2 id="each-block-of-thread-would-load-matrix-elements-multiple-times">Each block of thread would load matrix elements multiple times</h2> <h3 id="how-it-works">How It Works</h3> <ol> <li> <strong>Tile Loading</strong>: <ul> <li>For each iteration of the loop (<code class="language-plaintext highlighter-rouge">for (int i = 0; i &lt; width / TILE_WIDTH; ++i)</code>), every block loads a new set of tiles from global memory into shared memory.</li> <li>This means that each block loads a tile of matrix <code class="language-plaintext highlighter-rouge">A</code> and a corresponding tile of matrix <code class="language-plaintext highlighter-rouge">B</code> multiple times, once for each tile that contributes to the block’s portion of the output matrix <code class="language-plaintext highlighter-rouge">C</code>.</li> </ul> </li> <li> <strong>Computing Partial Results</strong>: <ul> <li>Once the tiles are loaded into shared memory, the threads within the block use them to compute partial results.</li> <li>After computing the partial results, the tiles in shared memory are overwritten by the next set of tiles in the next iteration of the loop.</li> </ul> </li> <li> <strong>Accumulating Results</strong>: <ul> <li>The partial results are accumulated across all iterations to compute the final value for each element in the output matrix <code class="language-plaintext highlighter-rouge">C</code>.</li> </ul> </li> </ol> <h3 id="why-this-is-necessary">Why This is Necessary</h3> <ul> <li> <strong>Matrix Multiplication</strong>: Matrix multiplication requires summing the products of elements from entire rows of <code class="language-plaintext highlighter-rouge">A</code> and columns of <code class="language-plaintext highlighter-rouge">B</code>. Since the matrices are too large to fit entirely into shared memory, they must be processed in smaller chunks (tiles).</li> <li> <strong>Efficiency</strong>: Using tiles and shared memory helps improve the efficiency of these operations by minimizing the slower global memory accesses.</li> </ul> <h3 id="example">Example</h3> <p>For a simplified example, let’s say <code class="language-plaintext highlighter-rouge">TILE_WIDTH</code> is 2 and our matrices are 4x4. Each block processes a 2x2 sub-matrix of the output matrix <code class="language-plaintext highlighter-rouge">C</code>. For each block, the loading process might look like this:</p> <ol> <li> <strong>First Iteration</strong>: <ul> <li>Load the first 2x2 tile of <code class="language-plaintext highlighter-rouge">A</code> and <code class="language-plaintext highlighter-rouge">B</code>.</li> <li>Compute partial results using this tile.</li> </ul> </li> <li> <strong>Second Iteration</strong>: <ul> <li>Load the next 2x2 tile of <code class="language-plaintext highlighter-rouge">A</code> and <code class="language-plaintext highlighter-rouge">B</code>.</li> <li>Add the products to the previously computed partial results.</li> </ul> </li> </ol> <p><img src="https://github.com/user-attachments/assets/a49597da-01cf-4ef3-ae0d-9d797b487b56" alt="tmm-59dd890f48435e692c47919d0df4a5e6"></p> <p>This process repeats until the entire matrices have been processed. So, each block loads and processes multiple tiles to compute the final output elements.</p> <h2 id="the-whole-matrix-is-loaded-multiple-times-by-all-blocks-of-threads">The whole matrix is loaded multiple times by all blocks of threads</h2> <p>Yes, you’ve got it! The matrix elements are indeed loaded multiple times into shared memory by different blocks during the matrix multiplication process.</p> <h3 id="why-this-happens">Why This Happens</h3> <ul> <li> <strong>Tiling</strong>: The entire matrix cannot fit into the limited shared memory available on the GPU. Thus, the matrix is divided into smaller tiles.</li> <li> <strong>Multiple Blocks</strong>: Each block processes a portion of the matrix. Since the matrix multiplication operation requires data from different parts of the matrices, these tiles are loaded multiple times into shared memory by different blocks to complete the computation.</li> </ul> <h3 id="process-recap">Process Recap</h3> <ol> <li> <strong>Loading Tiles</strong>: Each block loads a tile (a small sub-matrix) of the matrices <code class="language-plaintext highlighter-rouge">A</code> and <code class="language-plaintext highlighter-rouge">B</code> into shared memory.</li> <li> <strong>Processing</strong>: The threads within the block process these tiles to compute partial results for the output matrix <code class="language-plaintext highlighter-rouge">C</code>.</li> <li> <strong>Repetition</strong>: This loading and processing is repeated for every required tile until the entire matrix multiplication is complete.</li> </ol> <p>By using tiling and shared memory, the code minimizes the number of slow global memory accesses and maximizes the speed of computations by taking advantage of the faster shared memory.</p> <p>This approach ensures efficient parallel processing, leading to a significant performance boost on the GPU.</p> <h2 id="why-dont-use-threadidxx-as-row-idx-">why don’t use threadIdx.x as row idx ?</h2> <p>I see where you’re coming from, and it’s a valid question! Let’s delve deeper into why <code class="language-plaintext highlighter-rouge">threadIdx.y</code> is used as the row index and not <code class="language-plaintext highlighter-rouge">threadIdx.x</code>.</p> <h3 id="memory-coalescing-and-access-patterns">Memory Coalescing and Access Patterns</h3> <ol> <li> <p><strong>Memory Coalescing</strong>: On GPUs, memory access patterns significantly impact performance. Coalescing refers to combining multiple memory accesses into a single transaction. When threads within a warp (32 threads in modern GPUs) access contiguous memory locations, those accesses can be coalesced.</p> </li> <li> <p><strong>Row-major Order</strong>: In C/C++, arrays are stored in row-major order, meaning the elements of each row are stored in contiguous memory locations. For instance, in a 2D array <code class="language-plaintext highlighter-rouge">A</code>:</p> <ul> <li> <code class="language-plaintext highlighter-rouge">A[0][0], A[0][1], A[0][2], ..., A[0][N-1]</code> are stored consecutively in memory.</li> </ul> </li> </ol> <h3 id="access-efficiency">Access Efficiency</h3> <p>When we use <code class="language-plaintext highlighter-rouge">threadIdx.y</code> as the row index and <code class="language-plaintext highlighter-rouge">threadIdx.x</code> as the column index, it ensures that all threads in the same row of a block access contiguous memory locations in the global memory.</p> <h3 id="example-1">Example</h3> <p>Consider a tile size of 4x4 for simplicity. When loading a tile from global memory to shared memory:</p> <ul> <li> <strong>Using <code class="language-plaintext highlighter-rouge">threadIdx.y</code> as row index</strong>: <div class="language-cpp highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="n">tile_A</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">d_A</span><span class="p">[</span><span class="n">row</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">)];</span>
</code></pre></div> </div> <p>Each row in <code class="language-plaintext highlighter-rouge">tile_A</code> is loaded by threads in a row of the block, accessing contiguous elements in the global memory:</p> <ul> <li>Thread (0,0) accesses <code class="language-plaintext highlighter-rouge">d_A[row * width + (i * TILE_WIDTH + 0)]</code> </li> <li>Thread (0,1) accesses <code class="language-plaintext highlighter-rouge">d_A[row * width + (i * TILE_WIDTH + 1)]</code> </li> <li>Thread (0,2) accesses <code class="language-plaintext highlighter-rouge">d_A[row * width + (i * TILE_WIDTH + 2)]</code> </li> <li>Thread (0,3) accesses <code class="language-plaintext highlighter-rouge">d_A[row * width + (i * TILE_WIDTH + 3)]</code> </li> </ul> <p>All these accesses can be coalesced into a single transaction.</p> </li> <li> <strong>Using <code class="language-plaintext highlighter-rouge">threadIdx.x</code> as row index</strong>: <div class="language-cpp highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="n">tile_A</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">]</span> <span class="o">=</span> <span class="n">d_A</span><span class="p">[</span><span class="n">row</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)];</span>
</code></pre></div> </div> <p>Now, each column in <code class="language-plaintext highlighter-rouge">tile_A</code> is loaded by threads in a column of the block, accessing non-contiguous elements in the global memory:</p> <ul> <li>Thread (0,0) accesses <code class="language-plaintext highlighter-rouge">d_A[row * width + (i * TILE_WIDTH + 0)]</code> </li> <li>Thread (1,0) accesses <code class="language-plaintext highlighter-rouge">d_A[row * width + (i * TILE_WIDTH + 0)] + width</code> </li> <li>Thread (2,0) accesses <code class="language-plaintext highlighter-rouge">d_A[row * width + (i * TILE_WIDTH + 0)] + 2 * width</code> </li> <li>Thread (3,0) accesses <code class="language-plaintext highlighter-rouge">d_A[row * width + (i * TILE_WIDTH + 0)] + 3 * width</code> </li> </ul> <p>These accesses are not contiguous and cannot be efficiently coalesced.</p> </li> </ul> <h3 id="summary">Summary</h3> <p>Using <code class="language-plaintext highlighter-rouge">threadIdx.y</code> as the row index and <code class="language-plaintext highlighter-rouge">threadIdx.x</code> as the column index ensures that threads within the same row of a block access contiguous memory locations. This pattern optimizes memory coalescing and significantly improves performance on GPUs.</p> <p>I hope this clarifies why the indices are arranged this way! If you have more questions or need further explanations, feel free to ask. 😊</p> <p>cuda has a limit on the number of threads per block, typically 1024. If width is larger than 32, kernel launch will fail. And we get this error</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[nsccgz_qylin_1@ln102%tianhe2-K matmul]$ yhrun -p gpu_v100 ./matmul_cuda
CUDA error: invalid configuration argument
cuda Duration: 345.838 ms
cuda tile Duration: 25.2786 ms
check failed: 0, cuda naive: 0, cuda tile: 2000
yhrun: error: gpu29: task 0: Exited with exit code 1
</code></pre></div></div> <p>Comparison between cpu, cuda native and cuda matrix multiplication with tiling.</p> <p>Code:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="cp">#define N 2 // Matrix size
#define BLOCK_SIZE 16 // Block size
</span>
<span class="kt">void</span> <span class="nf">matmul_cpu</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="kt">int</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">input_row_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">input_row_idx</span><span class="o">&lt;</span> <span class="n">width</span><span class="p">;</span> <span class="n">input_row_idx</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">output_col_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span>  <span class="n">output_col_idx</span> <span class="o">&lt;</span> <span class="n">width</span><span class="p">;</span> <span class="n">output_col_idx</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="kt">int</span> <span class="n">value</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
      <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">element_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">element_idx</span> <span class="o">&lt;</span> <span class="n">width</span><span class="p">;</span> <span class="n">element_idx</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
          <span class="c1">// value += a[input_row_idx][element_idx] * b[element_idx][output_col_idx];</span>
          <span class="n">value</span> <span class="o">+=</span> <span class="n">a</span><span class="p">[</span><span class="n">input_row_idx</span><span class="o">*</span><span class="n">width</span> <span class="o">+</span> <span class="n">element_idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">b</span><span class="p">[</span><span class="n">element_idx</span><span class="o">*</span><span class="n">width</span> <span class="o">+</span> <span class="n">output_col_idx</span><span class="p">];</span>

      <span class="p">}</span>
      <span class="n">c</span><span class="p">[</span><span class="n">input_row_idx</span><span class="o">*</span><span class="n">width</span><span class="o">+</span><span class="n">output_col_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="p">;</span>
      <span class="c1">// c[input_row_idx][output_col_idx] = value;</span>
    <span class="p">}</span>
  <span class="p">}</span>

<span class="p">}</span>

<span class="c1">// CUDA Kernel for Matrix Multiplication</span>
<span class="n">__global__</span> <span class="kt">void</span> <span class="nf">MatrixMul</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="kt">int</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">row</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">y</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">col</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

    <span class="k">if</span><span class="p">(</span><span class="n">row</span> <span class="o">&lt;</span> <span class="n">width</span> <span class="o">&amp;&amp;</span> <span class="n">col</span> <span class="o">&lt;</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">int</span> <span class="n">val</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">width</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">val</span> <span class="o">+=</span> <span class="n">a</span><span class="p">[</span><span class="n">row</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="n">col</span><span class="p">];</span>
        <span class="p">}</span>
        <span class="n">c</span><span class="p">[</span><span class="n">row</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>


<span class="kt">int</span> <span class="nf">matmul_cuda_naive</span><span class="p">(</span><span class="kt">int</span><span class="o">*</span> <span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="kt">int</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">size</span> <span class="o">=</span> <span class="n">width</span> <span class="o">*</span> <span class="n">width</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">);</span>
  <span class="kt">int</span> <span class="o">*</span><span class="n">dev_a</span><span class="p">,</span> <span class="o">*</span><span class="n">dev_b</span><span class="p">,</span> <span class="o">*</span><span class="n">dev_c</span><span class="p">;</span>

    <span class="c1">// Allocate device memory</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_b</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_c</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>

    <span class="c1">// Copy matrices to device memory</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">dev_b</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

    <span class="c1">// Launch kernel</span>

    <span class="n">dim3</span> <span class="n">threadsPerBlock</span><span class="p">(</span><span class="n">BLOCK_SIZE</span><span class="p">,</span> <span class="n">BLOCK_SIZE</span><span class="p">);</span>
    <span class="n">dim3</span> <span class="n">numBlocks</span><span class="p">((</span><span class="n">width</span> <span class="o">+</span> <span class="n">BLOCK_SIZE</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">BLOCK_SIZE</span><span class="p">,</span> <span class="p">(</span><span class="n">width</span> <span class="o">+</span> <span class="n">BLOCK_SIZE</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">BLOCK_SIZE</span><span class="p">);</span>
    <span class="c1">// dim3 dimBlock(width, width);</span>
    <span class="c1">// dim3 dimGrid(1, 1);</span>

    <span class="n">MatrixMul</span><span class="o">&lt;&lt;&lt;</span><span class="n">numBlocks</span><span class="p">,</span> <span class="n">threadsPerBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">dev_b</span><span class="p">,</span> <span class="n">dev_c</span><span class="p">,</span> <span class="n">width</span><span class="p">);</span>
    <span class="c1">// MatrixMul&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(dev_a, dev_b, dev_c, width);</span>

    <span class="c1">// Synchronize CPU and GPU</span>
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>

    <span class="c1">// Check for errors</span>
    <span class="n">cudaError_t</span> <span class="n">error</span> <span class="o">=</span> <span class="n">cudaGetLastError</span><span class="p">();</span>
    <span class="k">if</span><span class="p">(</span><span class="n">error</span> <span class="o">!=</span> <span class="n">cudaSuccess</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"CUDA error: %s</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">cudaGetErrorString</span><span class="p">(</span><span class="n">error</span><span class="p">));</span>
        <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="c1">// Copy result back to host memory</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">dev_c</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>

    <span class="c1">// Print the result</span>
    <span class="c1">// for (int y = 0; y &lt; N; y++) {</span>
    <span class="c1">//     for (int x = 0; x &lt; N; x++) {</span>
    <span class="c1">//         printf("%d ", c[y][x]);</span>
    <span class="c1">//     }</span>
    <span class="c1">//     printf("\n");</span>
    <span class="c1">// }</span>

    <span class="c1">// Free device memory</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_a</span><span class="p">);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_b</span><span class="p">);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_c</span><span class="p">);</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>


<span class="p">}</span>


<span class="kt">void</span> <span class="nf">matrixMulTile</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="kt">int</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">size</span> <span class="o">=</span> <span class="n">width</span> <span class="o">*</span> <span class="n">width</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">);</span>
  <span class="kt">int</span> <span class="o">*</span><span class="n">dev_a</span><span class="p">,</span> <span class="o">*</span><span class="n">dev_b</span><span class="p">,</span> <span class="o">*</span><span class="n">dev_c</span><span class="p">;</span>

    <span class="c1">// Allocate device memory</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_b</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_c</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>

    <span class="c1">// Copy matrices to device memory</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">dev_b</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

  <span class="n">dim3</span> <span class="n">dimBlock</span><span class="p">(</span><span class="n">TILE_WIDTH</span><span class="p">,</span> <span class="n">TILE_WIDTH</span><span class="p">);</span>
  <span class="n">dim3</span> <span class="n">dimGrid</span><span class="p">((</span><span class="n">width</span> <span class="o">+</span> <span class="n">TILE_WIDTH</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span> <span class="n">TILE_WIDTH</span><span class="p">,</span> <span class="p">(</span><span class="n">width</span><span class="o">+</span><span class="n">TILE_WIDTH</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span> <span class="n">TILE_WIDTH</span><span class="p">);</span>
  <span class="n">matrixMulTileKernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">dimGrid</span><span class="p">,</span> <span class="n">dimBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">dev_b</span><span class="p">,</span> <span class="n">dev_c</span><span class="p">,</span> <span class="n">width</span><span class="p">);</span>
  <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>

  <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">dev_c</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>

  <span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_a</span><span class="p">);</span>
  <span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_b</span><span class="p">);</span>
  <span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_c</span><span class="p">);</span>


<span class="p">}</span>

<span class="cp">#define TILE_WIDTH 16
</span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">matrixMulTileKernel</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">da</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">db</span><span class="p">,</span> <span class="kt">int</span><span class="o">*</span><span class="n">dout</span><span class="p">,</span> <span class="kt">int</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">__shared__</span> <span class="kt">int</span> <span class="n">tile_A</span><span class="p">[</span><span class="n">TILE_WIDTH</span> <span class="p">][</span><span class="n">TILE_WIDTH</span><span class="p">];</span>
  <span class="n">__shared__</span> <span class="kt">int</span> <span class="n">tile_B</span><span class="p">[</span><span class="n">TILE_WIDTH</span><span class="p">][</span><span class="n">TILE_WIDTH</span><span class="p">];</span>

  <span class="kt">int</span> <span class="n">row</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">col</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

  <span class="kt">int</span> <span class="n">value</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">width</span><span class="o">+</span><span class="n">TILE_WIDTH</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">TILE_WIDTH</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span> <span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span><span class="p">(</span><span class="n">row</span> <span class="o">&lt;</span> <span class="n">width</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>

      <span class="n">tile_A</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">da</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">width</span> <span class="o">+</span> <span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">)];</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="n">tile_A</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">if</span><span class="p">(</span><span class="n">col</span> <span class="o">&lt;</span> <span class="n">width</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">tile_B</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">db</span><span class="p">[(</span><span class="n">i</span><span class="o">*</span><span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="n">col</span><span class="p">];</span>

    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="n">tile_B</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">__syncthreads</span><span class="p">();</span>

    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">TILE_WIDTH</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">value</span> <span class="o">+=</span> <span class="n">tile_A</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">tile_B</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
    <span class="p">}</span>
    <span class="n">__syncthreads</span><span class="p">();</span>


  <span class="p">}</span>

  <span class="n">dout</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">width</span> <span class="o">+</span> <span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="p">;</span>

<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">2000</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">size</span> <span class="o">=</span> <span class="n">width</span> <span class="o">*</span> <span class="n">width</span><span class="p">;</span>
  <span class="kt">int</span> <span class="o">*</span><span class="n">h_A</span> <span class="o">=</span> <span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">size</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
  <span class="kt">int</span> <span class="o">*</span><span class="n">h_B</span> <span class="o">=</span> <span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">size</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
  <span class="kt">int</span> <span class="o">*</span><span class="n">h_C</span> <span class="o">=</span> <span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">size</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>

  <span class="kt">int</span> <span class="o">*</span><span class="n">hc2</span> <span class="o">=</span> <span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">size</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>

  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">size</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span> <span class="n">h_A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">h_B</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="p">}</span>


      <span class="k">auto</span> <span class="n">start</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
  <span class="n">matmul_cuda_naive</span><span class="p">(</span><span class="n">h_A</span><span class="p">,</span> <span class="n">h_B</span><span class="p">,</span> <span class="n">h_C</span><span class="p">,</span> <span class="n">width</span><span class="p">);</span>
  <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
      <span class="k">auto</span> <span class="n">end</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
      <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration</span><span class="o">&lt;</span><span class="kt">double</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">milli</span><span class="o">&gt;</span> <span class="n">duration</span> <span class="o">=</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">;</span>
      <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"cuda Duration: "</span> <span class="o">&lt;&lt;</span> <span class="n">duration</span><span class="p">.</span><span class="n">count</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="s">" ms"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>


       <span class="n">start</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
  <span class="n">matrixMulTile</span><span class="p">(</span><span class="n">h_A</span><span class="p">,</span> <span class="n">h_B</span><span class="p">,</span> <span class="n">hc2</span><span class="p">,</span> <span class="n">width</span><span class="p">);</span>
  <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
       <span class="n">end</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
      <span class="n">duration</span> <span class="o">=</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">;</span>
      <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"cuda tile Duration: "</span> <span class="o">&lt;&lt;</span> <span class="n">duration</span><span class="p">.</span><span class="n">count</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="s">" ms"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>


  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span><span class="n">size</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">hc2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="n">h_C</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="p">{</span>
      <span class="n">printf</span><span class="p">(</span><span class="s">"check failed: %d, cuda naive: %d, cuda tile: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">i</span> <span class="p">,</span> <span class="n">h_C</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">hc2</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
      <span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="n">printf</span><span class="p">(</span><span class="s">"correctness check pass</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>


       <span class="n">start</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
      <span class="n">matmul_cpu</span><span class="p">(</span><span class="n">h_A</span><span class="p">,</span> <span class="n">h_B</span> <span class="p">,</span> <span class="n">hc2</span><span class="p">,</span> <span class="n">width</span><span class="p">);</span>
       <span class="n">end</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
       <span class="n">duration</span> <span class="o">=</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">;</span>
      <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"cpu Duration: "</span> <span class="o">&lt;&lt;</span> <span class="n">duration</span><span class="p">.</span><span class="n">count</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="s">" ms"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>



  <span class="n">free</span><span class="p">(</span><span class="n">h_A</span><span class="p">);</span> <span class="n">free</span><span class="p">(</span><span class="n">h_B</span><span class="p">);</span> <span class="n">free</span><span class="p">(</span><span class="n">h_C</span><span class="p">);</span>
<span class="p">}</span>

</code></pre></div></div> <p>Test matrix size is (2000, 2000) cuda naive reduce run time by 54x compared to cpu. cuda tiling reduce run time by 17x compared to cuda naive.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[nsccgz_qylin_1@ln102%tianhe2-K matmul]$ yhrun -p gpu_v100 ./matmul_cuda
cuda Duration: 432.435 ms
cuda tile Duration: 25.7345 ms
cpu Duration: 23042.4 ms
correctness check pass
</code></pre></div></div> <p>The benefit of tiling is that it reduces number of access to global shared memory.</p> <blockquote> <p>No, tiling not just replaces random accesses with sequential ones. It actually saves tons of bandwidth to global memory.</p> </blockquote> <blockquote> <p>Let’s say we multiply two large square matrices of size S×S, where S is a multiple of 32. Obviously, the result is also a square matrix of size S×S.</p> </blockquote> <blockquote> <p>With naïve algorithm, to compute each element of the result, we gonna need to fetch S elements from both matrices. The output matrix has S^2 elements, therefore the total count of loaded elements is 2*S^3.</p> </blockquote> <blockquote> <p>With 32×32 tiling, to compute each 32×32 tile of the result, we gonna need to fetch S/32 tiles from both matrices. The output size in tiles is (S/32)^2, the total count of loaded tiles is 2<em>(S/32)^3. Each 32×32 tile contains 32^2 elements, the total count of loaded elements is therefore (32^2)</em>2<em>(S/32)^3 = (2/32)</em>S^3. Therefore, the tiling reduced global memory bandwidth by the factor of 32, which is a huge performance win.</p> </blockquote> </body></html>