<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Speed up matrix multiplication 2 | Zhutao Zhuang </title> <meta name="author" content="Zhutao Zhuang"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://bilyz98.github.io/blog/2024/matrix-mul-comparison/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Zhutao</span> Zhuang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Speed up matrix multiplication 2</h1> <p class="post-meta"> Created in November 12, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a> Â  Â· Â  <a href="/blog/tag/ai"> <i class="fa-solid fa-hashtag fa-sm"></i> ai</a> Â  <a href="/blog/tag/ml"> <i class="fa-solid fa-hashtag fa-sm"></i> ml</a> Â  <a href="/blog/tag/matrix"> <i class="fa-solid fa-hashtag fa-sm"></i> matrix</a> Â  <a href="/blog/tag/multiplication"> <i class="fa-solid fa-hashtag fa-sm"></i> multiplication</a> Â  Â· Â  <a href="/blog/category/ml"> <i class="fa-solid fa-tag fa-sm"></i> ml</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h3 id="benefits-of-tiling">Benefits of Tiling</h3> <p>Reduced Global Memory Accesses:</p> <p>By loading tiles into shared memory, we reduce the number of global memory accesses, which are slower compared to shared memory accesses.</p> <p>Improved Cache Efficiency:</p> <p>Tiling improves cache efficiency by ensuring that data is reused within the shared memory, reducing the need to fetch data from global memory multiple times.</p> <p>Better Utilization of GPU Resources:</p> <p>Tiling allows for better utilization of the GPUâ€™s computational resources by dividing the work into smaller, manageable chunks that fit into the GPUâ€™s shared memory.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kt">void</span> <span class="nf">matrixMulTile</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="kt">int</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">size</span> <span class="o">=</span> <span class="n">width</span> <span class="o">*</span> <span class="n">width</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">);</span>
  <span class="kt">int</span> <span class="o">*</span><span class="n">dev_a</span><span class="p">,</span> <span class="o">*</span><span class="n">dev_b</span><span class="p">,</span> <span class="o">*</span><span class="n">dev_c</span><span class="p">;</span>

    <span class="c1">// Allocate device memory</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_b</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_c</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>

    <span class="c1">// Copy matrices to device memory</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">dev_b</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

  <span class="n">dim3</span> <span class="n">dimBlock</span><span class="p">(</span><span class="n">TILE_WIDTH</span><span class="p">,</span> <span class="n">TILE_WIDTH</span><span class="p">);</span>
  <span class="n">dim3</span> <span class="n">dimGrid</span><span class="p">((</span><span class="n">width</span> <span class="o">+</span> <span class="n">TILE_WIDTH</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span> <span class="n">TILE_WIDTH</span><span class="p">,</span> <span class="p">(</span><span class="n">width</span><span class="o">+</span><span class="n">TILE_WIDTH</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span> <span class="n">TILE_WIDTH</span><span class="p">);</span>
  <span class="n">matrixMulTileKernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">dimGrid</span><span class="p">,</span> <span class="n">dimBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">dev_b</span><span class="p">,</span> <span class="n">dev_c</span><span class="p">,</span> <span class="n">width</span><span class="p">);</span>
  <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>

  <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">dev_c</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>

  <span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_a</span><span class="p">);</span>
  <span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_b</span><span class="p">);</span>
  <span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_c</span><span class="p">);</span>


<span class="p">}</span>

<span class="cp">#define TILE_WIDTH 16
</span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">matrixMulTileKernel</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">da</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">db</span><span class="p">,</span> <span class="kt">int</span><span class="o">*</span><span class="n">dout</span><span class="p">,</span> <span class="kt">int</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">__shared__</span> <span class="kt">int</span> <span class="n">tile_A</span><span class="p">[</span><span class="n">TILE_WIDTH</span> <span class="p">][</span><span class="n">TILE_WIDTH</span><span class="p">];</span>
  <span class="n">__shared__</span> <span class="kt">int</span> <span class="n">tile_B</span><span class="p">[</span><span class="n">TILE_WIDTH</span><span class="p">][</span><span class="n">TILE_WIDTH</span><span class="p">];</span>

  <span class="kt">int</span> <span class="n">row</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">col</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

  <span class="kt">int</span> <span class="n">value</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">width</span><span class="o">+</span><span class="n">TILE_WIDTH</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">TILE_WIDTH</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span> <span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span><span class="p">(</span><span class="n">row</span> <span class="o">&lt;</span> <span class="n">width</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>

      <span class="n">tile_A</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">da</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">width</span> <span class="o">+</span> <span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">)];</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="n">tile_A</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">if</span><span class="p">(</span><span class="n">col</span> <span class="o">&lt;</span> <span class="n">width</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">tile_B</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">db</span><span class="p">[(</span><span class="n">i</span><span class="o">*</span><span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="n">col</span><span class="p">];</span>

    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="n">tile_B</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">__syncthreads</span><span class="p">();</span>

    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">TILE_WIDTH</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">value</span> <span class="o">+=</span> <span class="n">tile_A</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">tile_B</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
    <span class="p">}</span>
    <span class="n">__syncthreads</span><span class="p">();</span>


  <span class="p">}</span>

  <span class="n">dout</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">width</span> <span class="o">+</span> <span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="p">;</span>

<span class="p">}</span>
</code></pre></div></div> <p>This code means that we have one thread for each output element in output matrix.</p> <p>Each block of threads cooperatively loads chunks tiles of A and B into shared memory. This is done in a loop to cover all tiles that contribute to final result for the block.</p> <p><a href="https://penny-xu.github.io/blog/tiled-matrix-multiplication" rel="external nofollow noopener" target="_blank">Another post that talk about the tiling matrix multiplication</a></p> <h2 id="each-block-of-thread-would-load-matrix-elements-multiple-times">Each block of thread would load matrix elements multiple times</h2> <h3 id="how-it-works">How It Works</h3> <ol> <li> <strong>Tile Loading</strong>: <ul> <li>For each iteration of the loop (<code class="language-plaintext highlighter-rouge">for (int i = 0; i &lt; width / TILE_WIDTH; ++i)</code>), every block loads a new set of tiles from global memory into shared memory.</li> <li>This means that each block loads a tile of matrix <code class="language-plaintext highlighter-rouge">A</code> and a corresponding tile of matrix <code class="language-plaintext highlighter-rouge">B</code> multiple times, once for each tile that contributes to the blockâ€™s portion of the output matrix <code class="language-plaintext highlighter-rouge">C</code>.</li> </ul> </li> <li> <strong>Computing Partial Results</strong>: <ul> <li>Once the tiles are loaded into shared memory, the threads within the block use them to compute partial results.</li> <li>After computing the partial results, the tiles in shared memory are overwritten by the next set of tiles in the next iteration of the loop.</li> </ul> </li> <li> <strong>Accumulating Results</strong>: <ul> <li>The partial results are accumulated across all iterations to compute the final value for each element in the output matrix <code class="language-plaintext highlighter-rouge">C</code>.</li> </ul> </li> </ol> <h3 id="why-this-is-necessary">Why This is Necessary</h3> <ul> <li> <strong>Matrix Multiplication</strong>: Matrix multiplication requires summing the products of elements from entire rows of <code class="language-plaintext highlighter-rouge">A</code> and columns of <code class="language-plaintext highlighter-rouge">B</code>. Since the matrices are too large to fit entirely into shared memory, they must be processed in smaller chunks (tiles).</li> <li> <strong>Efficiency</strong>: Using tiles and shared memory helps improve the efficiency of these operations by minimizing the slower global memory accesses.</li> </ul> <h3 id="example">Example</h3> <p>For a simplified example, letâ€™s say <code class="language-plaintext highlighter-rouge">TILE_WIDTH</code> is 2 and our matrices are 4x4. Each block processes a 2x2 sub-matrix of the output matrix <code class="language-plaintext highlighter-rouge">C</code>. For each block, the loading process might look like this:</p> <ol> <li> <strong>First Iteration</strong>: <ul> <li>Load the first 2x2 tile of <code class="language-plaintext highlighter-rouge">A</code> and <code class="language-plaintext highlighter-rouge">B</code>.</li> <li>Compute partial results using this tile.</li> </ul> </li> <li> <strong>Second Iteration</strong>: <ul> <li>Load the next 2x2 tile of <code class="language-plaintext highlighter-rouge">A</code> and <code class="language-plaintext highlighter-rouge">B</code>.</li> <li>Add the products to the previously computed partial results.</li> </ul> </li> </ol> <p><img src="https://github.com/user-attachments/assets/a49597da-01cf-4ef3-ae0d-9d797b487b56" alt="tmm-59dd890f48435e692c47919d0df4a5e6"></p> <p>This process repeats until the entire matrices have been processed. So, each block loads and processes multiple tiles to compute the final output elements.</p> <h2 id="the-whole-matrix-is-loaded-multiple-times-by-all-blocks-of-threads">The whole matrix is loaded multiple times by all blocks of threads</h2> <p>Yes, youâ€™ve got it! The matrix elements are indeed loaded multiple times into shared memory by different blocks during the matrix multiplication process.</p> <h3 id="why-this-happens">Why This Happens</h3> <ul> <li> <strong>Tiling</strong>: The entire matrix cannot fit into the limited shared memory available on the GPU. Thus, the matrix is divided into smaller tiles.</li> <li> <strong>Multiple Blocks</strong>: Each block processes a portion of the matrix. Since the matrix multiplication operation requires data from different parts of the matrices, these tiles are loaded multiple times into shared memory by different blocks to complete the computation.</li> </ul> <h3 id="process-recap">Process Recap</h3> <ol> <li> <strong>Loading Tiles</strong>: Each block loads a tile (a small sub-matrix) of the matrices <code class="language-plaintext highlighter-rouge">A</code> and <code class="language-plaintext highlighter-rouge">B</code> into shared memory.</li> <li> <strong>Processing</strong>: The threads within the block process these tiles to compute partial results for the output matrix <code class="language-plaintext highlighter-rouge">C</code>.</li> <li> <strong>Repetition</strong>: This loading and processing is repeated for every required tile until the entire matrix multiplication is complete.</li> </ol> <p>By using tiling and shared memory, the code minimizes the number of slow global memory accesses and maximizes the speed of computations by taking advantage of the faster shared memory.</p> <p>This approach ensures efficient parallel processing, leading to a significant performance boost on the GPU.</p> <h2 id="why-dont-use-threadidxx-as-row-idx-">why donâ€™t use threadIdx.x as row idx ?</h2> <p>I see where youâ€™re coming from, and itâ€™s a valid question! Letâ€™s delve deeper into why <code class="language-plaintext highlighter-rouge">threadIdx.y</code> is used as the row index and not <code class="language-plaintext highlighter-rouge">threadIdx.x</code>.</p> <h3 id="memory-coalescing-and-access-patterns">Memory Coalescing and Access Patterns</h3> <ol> <li> <p><strong>Memory Coalescing</strong>: On GPUs, memory access patterns significantly impact performance. Coalescing refers to combining multiple memory accesses into a single transaction. When threads within a warp (32 threads in modern GPUs) access contiguous memory locations, those accesses can be coalesced.</p> </li> <li> <p><strong>Row-major Order</strong>: In C/C++, arrays are stored in row-major order, meaning the elements of each row are stored in contiguous memory locations. For instance, in a 2D array <code class="language-plaintext highlighter-rouge">A</code>:</p> <ul> <li> <code class="language-plaintext highlighter-rouge">A[0][0], A[0][1], A[0][2], ..., A[0][N-1]</code> are stored consecutively in memory.</li> </ul> </li> </ol> <h3 id="access-efficiency">Access Efficiency</h3> <p>When we use <code class="language-plaintext highlighter-rouge">threadIdx.y</code> as the row index and <code class="language-plaintext highlighter-rouge">threadIdx.x</code> as the column index, it ensures that all threads in the same row of a block access contiguous memory locations in the global memory.</p> <h3 id="example-1">Example</h3> <p>Consider a tile size of 4x4 for simplicity. When loading a tile from global memory to shared memory:</p> <ul> <li> <strong>Using <code class="language-plaintext highlighter-rouge">threadIdx.y</code> as row index</strong>: <div class="language-cpp highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="n">tile_A</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">d_A</span><span class="p">[</span><span class="n">row</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">)];</span>
</code></pre></div> </div> <p>Each row in <code class="language-plaintext highlighter-rouge">tile_A</code> is loaded by threads in a row of the block, accessing contiguous elements in the global memory:</p> <ul> <li>Thread (0,0) accesses <code class="language-plaintext highlighter-rouge">d_A[row * width + (i * TILE_WIDTH + 0)]</code> </li> <li>Thread (0,1) accesses <code class="language-plaintext highlighter-rouge">d_A[row * width + (i * TILE_WIDTH + 1)]</code> </li> <li>Thread (0,2) accesses <code class="language-plaintext highlighter-rouge">d_A[row * width + (i * TILE_WIDTH + 2)]</code> </li> <li>Thread (0,3) accesses <code class="language-plaintext highlighter-rouge">d_A[row * width + (i * TILE_WIDTH + 3)]</code> </li> </ul> <p>All these accesses can be coalesced into a single transaction.</p> </li> <li> <strong>Using <code class="language-plaintext highlighter-rouge">threadIdx.x</code> as row index</strong>: <div class="language-cpp highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="n">tile_A</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">]</span> <span class="o">=</span> <span class="n">d_A</span><span class="p">[</span><span class="n">row</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)];</span>
</code></pre></div> </div> <p>Now, each column in <code class="language-plaintext highlighter-rouge">tile_A</code> is loaded by threads in a column of the block, accessing non-contiguous elements in the global memory:</p> <ul> <li>Thread (0,0) accesses <code class="language-plaintext highlighter-rouge">d_A[row * width + (i * TILE_WIDTH + 0)]</code> </li> <li>Thread (1,0) accesses <code class="language-plaintext highlighter-rouge">d_A[row * width + (i * TILE_WIDTH + 0)] + width</code> </li> <li>Thread (2,0) accesses <code class="language-plaintext highlighter-rouge">d_A[row * width + (i * TILE_WIDTH + 0)] + 2 * width</code> </li> <li>Thread (3,0) accesses <code class="language-plaintext highlighter-rouge">d_A[row * width + (i * TILE_WIDTH + 0)] + 3 * width</code> </li> </ul> <p>These accesses are not contiguous and cannot be efficiently coalesced.</p> </li> </ul> <h3 id="summary">Summary</h3> <p>Using <code class="language-plaintext highlighter-rouge">threadIdx.y</code> as the row index and <code class="language-plaintext highlighter-rouge">threadIdx.x</code> as the column index ensures that threads within the same row of a block access contiguous memory locations. This pattern optimizes memory coalescing and significantly improves performance on GPUs.</p> <p>I hope this clarifies why the indices are arranged this way! If you have more questions or need further explanations, feel free to ask. ðŸ˜Š</p> <p>cuda has a limit on the number of threads per block, typically 1024. If width is larger than 32, kernel launch will fail. And we get this error</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[nsccgz_qylin_1@ln102%tianhe2-K matmul]$ yhrun -p gpu_v100 ./matmul_cuda
CUDA error: invalid configuration argument
cuda Duration: 345.838 ms
cuda tile Duration: 25.2786 ms
check failed: 0, cuda naive: 0, cuda tile: 2000
yhrun: error: gpu29: task 0: Exited with exit code 1
</code></pre></div></div> <p>Comparison between cpu, cuda native and cuda matrix multiplication with tiling.</p> <p>Code:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="cp">#define N 2 // Matrix size
#define BLOCK_SIZE 16 // Block size
</span>
<span class="kt">void</span> <span class="nf">matmul_cpu</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="kt">int</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">input_row_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">input_row_idx</span><span class="o">&lt;</span> <span class="n">width</span><span class="p">;</span> <span class="n">input_row_idx</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">output_col_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span>  <span class="n">output_col_idx</span> <span class="o">&lt;</span> <span class="n">width</span><span class="p">;</span> <span class="n">output_col_idx</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="kt">int</span> <span class="n">value</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
      <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">element_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">element_idx</span> <span class="o">&lt;</span> <span class="n">width</span><span class="p">;</span> <span class="n">element_idx</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
          <span class="c1">// value += a[input_row_idx][element_idx] * b[element_idx][output_col_idx];</span>
          <span class="n">value</span> <span class="o">+=</span> <span class="n">a</span><span class="p">[</span><span class="n">input_row_idx</span><span class="o">*</span><span class="n">width</span> <span class="o">+</span> <span class="n">element_idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">b</span><span class="p">[</span><span class="n">element_idx</span><span class="o">*</span><span class="n">width</span> <span class="o">+</span> <span class="n">output_col_idx</span><span class="p">];</span>

      <span class="p">}</span>
      <span class="n">c</span><span class="p">[</span><span class="n">input_row_idx</span><span class="o">*</span><span class="n">width</span><span class="o">+</span><span class="n">output_col_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="p">;</span>
      <span class="c1">// c[input_row_idx][output_col_idx] = value;</span>
    <span class="p">}</span>
  <span class="p">}</span>

<span class="p">}</span>

<span class="c1">// CUDA Kernel for Matrix Multiplication</span>
<span class="n">__global__</span> <span class="kt">void</span> <span class="nf">MatrixMul</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="kt">int</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">row</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">y</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">col</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

    <span class="k">if</span><span class="p">(</span><span class="n">row</span> <span class="o">&lt;</span> <span class="n">width</span> <span class="o">&amp;&amp;</span> <span class="n">col</span> <span class="o">&lt;</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">int</span> <span class="n">val</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">width</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">val</span> <span class="o">+=</span> <span class="n">a</span><span class="p">[</span><span class="n">row</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="n">col</span><span class="p">];</span>
        <span class="p">}</span>
        <span class="n">c</span><span class="p">[</span><span class="n">row</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>


<span class="kt">int</span> <span class="nf">matmul_cuda_naive</span><span class="p">(</span><span class="kt">int</span><span class="o">*</span> <span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="kt">int</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">size</span> <span class="o">=</span> <span class="n">width</span> <span class="o">*</span> <span class="n">width</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">);</span>
  <span class="kt">int</span> <span class="o">*</span><span class="n">dev_a</span><span class="p">,</span> <span class="o">*</span><span class="n">dev_b</span><span class="p">,</span> <span class="o">*</span><span class="n">dev_c</span><span class="p">;</span>

    <span class="c1">// Allocate device memory</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_b</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_c</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>

    <span class="c1">// Copy matrices to device memory</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">dev_b</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

    <span class="c1">// Launch kernel</span>

    <span class="n">dim3</span> <span class="n">threadsPerBlock</span><span class="p">(</span><span class="n">BLOCK_SIZE</span><span class="p">,</span> <span class="n">BLOCK_SIZE</span><span class="p">);</span>
    <span class="n">dim3</span> <span class="n">numBlocks</span><span class="p">((</span><span class="n">width</span> <span class="o">+</span> <span class="n">BLOCK_SIZE</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">BLOCK_SIZE</span><span class="p">,</span> <span class="p">(</span><span class="n">width</span> <span class="o">+</span> <span class="n">BLOCK_SIZE</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">BLOCK_SIZE</span><span class="p">);</span>
    <span class="c1">// dim3 dimBlock(width, width);</span>
    <span class="c1">// dim3 dimGrid(1, 1);</span>

    <span class="n">MatrixMul</span><span class="o">&lt;&lt;&lt;</span><span class="n">numBlocks</span><span class="p">,</span> <span class="n">threadsPerBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">dev_b</span><span class="p">,</span> <span class="n">dev_c</span><span class="p">,</span> <span class="n">width</span><span class="p">);</span>
    <span class="c1">// MatrixMul&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(dev_a, dev_b, dev_c, width);</span>

    <span class="c1">// Synchronize CPU and GPU</span>
    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>

    <span class="c1">// Check for errors</span>
    <span class="n">cudaError_t</span> <span class="n">error</span> <span class="o">=</span> <span class="n">cudaGetLastError</span><span class="p">();</span>
    <span class="k">if</span><span class="p">(</span><span class="n">error</span> <span class="o">!=</span> <span class="n">cudaSuccess</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"CUDA error: %s</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">cudaGetErrorString</span><span class="p">(</span><span class="n">error</span><span class="p">));</span>
        <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="c1">// Copy result back to host memory</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">dev_c</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>

    <span class="c1">// Print the result</span>
    <span class="c1">// for (int y = 0; y &lt; N; y++) {</span>
    <span class="c1">//     for (int x = 0; x &lt; N; x++) {</span>
    <span class="c1">//         printf("%d ", c[y][x]);</span>
    <span class="c1">//     }</span>
    <span class="c1">//     printf("\n");</span>
    <span class="c1">// }</span>

    <span class="c1">// Free device memory</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_a</span><span class="p">);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_b</span><span class="p">);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_c</span><span class="p">);</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>


<span class="p">}</span>


<span class="kt">void</span> <span class="nf">matrixMulTile</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">a</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">b</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">c</span><span class="p">,</span> <span class="kt">int</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">size</span> <span class="o">=</span> <span class="n">width</span> <span class="o">*</span> <span class="n">width</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">);</span>
  <span class="kt">int</span> <span class="o">*</span><span class="n">dev_a</span><span class="p">,</span> <span class="o">*</span><span class="n">dev_b</span><span class="p">,</span> <span class="o">*</span><span class="n">dev_c</span><span class="p">;</span>

    <span class="c1">// Allocate device memory</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_b</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dev_c</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>

    <span class="c1">// Copy matrices to device memory</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">dev_b</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

  <span class="n">dim3</span> <span class="n">dimBlock</span><span class="p">(</span><span class="n">TILE_WIDTH</span><span class="p">,</span> <span class="n">TILE_WIDTH</span><span class="p">);</span>
  <span class="n">dim3</span> <span class="n">dimGrid</span><span class="p">((</span><span class="n">width</span> <span class="o">+</span> <span class="n">TILE_WIDTH</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span> <span class="n">TILE_WIDTH</span><span class="p">,</span> <span class="p">(</span><span class="n">width</span><span class="o">+</span><span class="n">TILE_WIDTH</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span> <span class="n">TILE_WIDTH</span><span class="p">);</span>
  <span class="n">matrixMulTileKernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">dimGrid</span><span class="p">,</span> <span class="n">dimBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">dev_a</span><span class="p">,</span> <span class="n">dev_b</span><span class="p">,</span> <span class="n">dev_c</span><span class="p">,</span> <span class="n">width</span><span class="p">);</span>
  <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>

  <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">dev_c</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>

  <span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_a</span><span class="p">);</span>
  <span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_b</span><span class="p">);</span>
  <span class="n">cudaFree</span><span class="p">(</span><span class="n">dev_c</span><span class="p">);</span>


<span class="p">}</span>

<span class="cp">#define TILE_WIDTH 16
</span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">matrixMulTileKernel</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">da</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">db</span><span class="p">,</span> <span class="kt">int</span><span class="o">*</span><span class="n">dout</span><span class="p">,</span> <span class="kt">int</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">__shared__</span> <span class="kt">int</span> <span class="n">tile_A</span><span class="p">[</span><span class="n">TILE_WIDTH</span> <span class="p">][</span><span class="n">TILE_WIDTH</span><span class="p">];</span>
  <span class="n">__shared__</span> <span class="kt">int</span> <span class="n">tile_B</span><span class="p">[</span><span class="n">TILE_WIDTH</span><span class="p">][</span><span class="n">TILE_WIDTH</span><span class="p">];</span>

  <span class="kt">int</span> <span class="n">row</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">col</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

  <span class="kt">int</span> <span class="n">value</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">width</span><span class="o">+</span><span class="n">TILE_WIDTH</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">TILE_WIDTH</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span> <span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span><span class="p">(</span><span class="n">row</span> <span class="o">&lt;</span> <span class="n">width</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>

      <span class="n">tile_A</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">da</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">width</span> <span class="o">+</span> <span class="p">(</span><span class="n">i</span><span class="o">*</span><span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">)];</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="n">tile_A</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">if</span><span class="p">(</span><span class="n">col</span> <span class="o">&lt;</span> <span class="n">width</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">width</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">tile_B</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">db</span><span class="p">[(</span><span class="n">i</span><span class="o">*</span><span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="n">col</span><span class="p">];</span>

    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="n">tile_B</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">__syncthreads</span><span class="p">();</span>

    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">TILE_WIDTH</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">value</span> <span class="o">+=</span> <span class="n">tile_A</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">tile_B</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
    <span class="p">}</span>
    <span class="n">__syncthreads</span><span class="p">();</span>


  <span class="p">}</span>

  <span class="n">dout</span><span class="p">[</span><span class="n">row</span><span class="o">*</span><span class="n">width</span> <span class="o">+</span> <span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="p">;</span>

<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">width</span> <span class="o">=</span> <span class="mi">2000</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">size</span> <span class="o">=</span> <span class="n">width</span> <span class="o">*</span> <span class="n">width</span><span class="p">;</span>
  <span class="kt">int</span> <span class="o">*</span><span class="n">h_A</span> <span class="o">=</span> <span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">size</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
  <span class="kt">int</span> <span class="o">*</span><span class="n">h_B</span> <span class="o">=</span> <span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">size</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
  <span class="kt">int</span> <span class="o">*</span><span class="n">h_C</span> <span class="o">=</span> <span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">size</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>

  <span class="kt">int</span> <span class="o">*</span><span class="n">hc2</span> <span class="o">=</span> <span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">size</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>

  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">size</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span> <span class="n">h_A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">h_B</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="p">}</span>


      <span class="k">auto</span> <span class="n">start</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
  <span class="n">matmul_cuda_naive</span><span class="p">(</span><span class="n">h_A</span><span class="p">,</span> <span class="n">h_B</span><span class="p">,</span> <span class="n">h_C</span><span class="p">,</span> <span class="n">width</span><span class="p">);</span>
  <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
      <span class="k">auto</span> <span class="n">end</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
      <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration</span><span class="o">&lt;</span><span class="kt">double</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">milli</span><span class="o">&gt;</span> <span class="n">duration</span> <span class="o">=</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">;</span>
      <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"cuda Duration: "</span> <span class="o">&lt;&lt;</span> <span class="n">duration</span><span class="p">.</span><span class="n">count</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="s">" ms"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>


       <span class="n">start</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
  <span class="n">matrixMulTile</span><span class="p">(</span><span class="n">h_A</span><span class="p">,</span> <span class="n">h_B</span><span class="p">,</span> <span class="n">hc2</span><span class="p">,</span> <span class="n">width</span><span class="p">);</span>
  <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
       <span class="n">end</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
      <span class="n">duration</span> <span class="o">=</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">;</span>
      <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"cuda tile Duration: "</span> <span class="o">&lt;&lt;</span> <span class="n">duration</span><span class="p">.</span><span class="n">count</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="s">" ms"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>


  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span><span class="n">size</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">hc2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">!=</span> <span class="n">h_C</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="p">{</span>
      <span class="n">printf</span><span class="p">(</span><span class="s">"check failed: %d, cuda naive: %d, cuda tile: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">i</span> <span class="p">,</span> <span class="n">h_C</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">hc2</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
      <span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="n">printf</span><span class="p">(</span><span class="s">"correctness check pass</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>


       <span class="n">start</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
      <span class="n">matmul_cpu</span><span class="p">(</span><span class="n">h_A</span><span class="p">,</span> <span class="n">h_B</span> <span class="p">,</span> <span class="n">hc2</span><span class="p">,</span> <span class="n">width</span><span class="p">);</span>
       <span class="n">end</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
       <span class="n">duration</span> <span class="o">=</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">;</span>
      <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"cpu Duration: "</span> <span class="o">&lt;&lt;</span> <span class="n">duration</span><span class="p">.</span><span class="n">count</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="s">" ms"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>



  <span class="n">free</span><span class="p">(</span><span class="n">h_A</span><span class="p">);</span> <span class="n">free</span><span class="p">(</span><span class="n">h_B</span><span class="p">);</span> <span class="n">free</span><span class="p">(</span><span class="n">h_C</span><span class="p">);</span>
<span class="p">}</span>

</code></pre></div></div> <p>indexing for da and db in cuda kernal explanations</p> <p>The indexing of matrix elements in the <code class="language-plaintext highlighter-rouge">matrixMulTileKernel</code> function is designed to optimize memory access patterns and improve performance by leveraging shared memory. Letâ€™s break down the indexing for <code class="language-plaintext highlighter-rouge">da</code> and <code class="language-plaintext highlighter-rouge">db</code>:</p> <p>Simply speaking, <code class="language-plaintext highlighter-rouge">i</code> has different meaning for <code class="language-plaintext highlighter-rouge">da</code> and <code class="language-plaintext highlighter-rouge">db</code>, for <code class="language-plaintext highlighter-rouge">da</code> i loop for all columns in the same row. for <code class="language-plaintext highlighter-rouge">db</code> i loops all rows in the same column.</p> <h3 id="indexing-for-da-matrix-a">Indexing for <code class="language-plaintext highlighter-rouge">da</code> (Matrix A)</h3> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tile_A</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">da</span><span class="p">[</span><span class="n">row</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">)];</span>
</code></pre></div></div> <ul> <li> <strong>Row Calculation</strong>: <code class="language-plaintext highlighter-rouge">row = blockIdx.y * TILE_WIDTH + threadIdx.y</code> <ul> <li> <code class="language-plaintext highlighter-rouge">blockIdx.y * TILE_WIDTH</code> gives the starting row index for the block.</li> <li> <code class="language-plaintext highlighter-rouge">threadIdx.y</code> gives the row index within the block.</li> </ul> </li> <li> <strong>Column Calculation</strong>: <code class="language-plaintext highlighter-rouge">(i * TILE_WIDTH + threadIdx.x)</code> <ul> <li> <code class="language-plaintext highlighter-rouge">i * TILE_WIDTH</code> shifts the column index by the tile width for each iteration.</li> <li> <code class="language-plaintext highlighter-rouge">threadIdx.x</code> gives the column index within the block.</li> </ul> </li> </ul> <h3 id="indexing-for-db-matrix-b">Indexing for <code class="language-plaintext highlighter-rouge">db</code> (Matrix B)</h3> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tile_B</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">][</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">db</span><span class="p">[(</span><span class="n">i</span> <span class="o">*</span> <span class="n">TILE_WIDTH</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">width</span> <span class="o">+</span> <span class="n">col</span><span class="p">];</span>
</code></pre></div></div> <ul> <li> <strong>Row Calculation</strong>: <code class="language-plaintext highlighter-rouge">(i * TILE_WIDTH + threadIdx.y)</code> <ul> <li> <code class="language-plaintext highlighter-rouge">i * TILE_WIDTH</code> shifts the row index by the tile width for each iteration.</li> <li> <code class="language-plaintext highlighter-rouge">threadIdx.y</code> gives the row index within the block.</li> </ul> </li> <li> <strong>Column Calculation</strong>: <code class="language-plaintext highlighter-rouge">col = blockIdx.x * TILE_WIDTH + threadIdx.x</code> <ul> <li> <code class="language-plaintext highlighter-rouge">blockIdx.x * TILE_WIDTH</code> gives the starting column index for the block.</li> <li> <code class="language-plaintext highlighter-rouge">threadIdx.x</code> gives the column index within the block.</li> </ul> </li> </ul> <h3 id="why-this-indexing">Why This Indexing?</h3> <ul> <li> <strong>Memory Coalescing</strong>: Using <code class="language-plaintext highlighter-rouge">threadIdx.x</code> for columns and <code class="language-plaintext highlighter-rouge">threadIdx.y</code> for rows ensures that threads within a warp access contiguous memory locations. This pattern optimizes memory coalescing, which combines multiple memory accesses into a single transaction, significantly improving performance.</li> <li> <strong>Efficient Tiling</strong>: By dividing the matrices into smaller tiles that fit into shared memory, the kernel reduces the number of global memory accesses. Each tile is loaded multiple times, but the overall number of accesses to global memory is minimized, leading to better performance.</li> </ul> <p>Test matrix size is (2000, 2000) cuda naive reduce run time by 54x compared to cpu. cuda tiling reduce run time by 17x compared to cuda naive.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[nsccgz_qylin_1@ln102%tianhe2-K matmul]$ yhrun -p gpu_v100 ./matmul_cuda
cuda Duration: 432.435 ms
cuda tile Duration: 25.7345 ms
cpu Duration: 23042.4 ms
correctness check pass
</code></pre></div></div> <p>The benefit of tiling is that it reduces number of access to global shared memory.</p> <blockquote> <p>No, tiling not just replaces random accesses with sequential ones. It actually saves tons of bandwidth to global memory.</p> </blockquote> <blockquote> <p>Letâ€™s say we multiply two large square matrices of size SÃ—S, where S is a multiple of 32. Obviously, the result is also a square matrix of size SÃ—S.</p> </blockquote> <blockquote> <p>With naÃ¯ve algorithm, to compute each element of the result, we gonna need to fetch S elements from both matrices. The output matrix has S^2 elements, therefore the total count of loaded elements is 2*S^3.</p> </blockquote> <blockquote> <p>With 32Ã—32 tiling, to compute each 32Ã—32 tile of the result, we gonna need to fetch S/32 tiles from both matrices. The output size in tiles is (S/32)^2, the total count of loaded tiles is 2<em>(S/32)^3. Each 32Ã—32 tile contains 32^2 elements, the total count of loaded elements is therefore (32^2)</em>2<em>(S/32)^3 = (2/32)</em>S^3. Therefore, the tiling reduced global memory bandwidth by the factor of 32, which is a huge performance win.</p> </blockquote> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/learning-based-memory-allocation-for-c-server-workloads-summary/">Learning-based memory allocation for C++ server workloads summary</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/my-question/">my question:</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/binary-search-algorithm-variant/">Binary search algorithm variant</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/docker-rocksdb-build/">Docker Rocksdb build</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/difference-between-dockerfile-and-docker-compose/">Difference between Dockerfile and Docker Compose</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2024 Zhutao Zhuang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: December 04, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let theme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===theme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"post-autodiff-implementation",title:"Autodiff implementation",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/uw-sysml-assign/"}},{id:"post-palindrome-substring-partition",title:"palindrome substring partition",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/palindrome-substring-partition/"}},{id:"post-stf-cs149-flash-attention",title:"Stf CS149 flash attention",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/cs149gpt/"}},{id:"post-speed-up-matrix-multiplication-2",title:"Speed up matrix multiplication 2",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/matrix-mul-comparison/"}},{id:"post-elf-loading",title:"Elf Loading",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/elf-loading/"}},{id:"post-stf-cs149-parallel-programming-assign3",title:"Stf CS149 Parallel Programming - Assign3",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/cs149-assign3/"}},{id:"post-stf-cs149-parallel-programming-lecture11-cache-coherence",title:"Stf CS149 Parallel Programming - Lecture11 - Cache coherence",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/cs149-lecture11-cache-coherence/"}},{id:"post-stf-cs149-parallel-programming-lecture-7-cuda-programming-model",title:"Stf CS149 Parallel Programming - Lecture 7 - Cuda programming model",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/cs149-lecture7-cuda/"}},{id:"post-stf-cs149-parallel-programming-assign2",title:"Stf CS149 Parallel Programming - Assign2",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/cs149-assign2/"}},{id:"post-stf-cs149-parallel-programming-lecture-5-amp-6-performance-optimization",title:"Stf CS149 Parallel Programming - Lecture 5&amp;6 - Performance optimization",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/stf-cs149-lecture-takeaway/"}},{id:"post-stf-cs149-parallel-programming-assign1",title:"Stf CS149 Parallel Programming - Assign1",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/stf-cs149-assign1/"}},{id:"post-ssh-display-image-on-local-server",title:"ssh display image on local server",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/ssh-display-img/"}},{id:"post-c-compiler-single-letter-local-variable",title:"C compiler - single letter local variable",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/chibicc-single-letter-ident/"}},{id:"post-c-compiler-parse-example-walkthrough",title:"C compiler - parse example walkthrough",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/statement-and-comparison/"}},{id:"post-linux-get-cpu-time-and-wall-clock-time",title:"Linux get cpu time and wall clock time",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/get-function-cpu-time/"}},{id:"post-simple-c-compiler-unary",title:"Simple c compiler unary",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/chibicc-unary/"}},{id:"post-simple-c-compiler-gen-expr",title:"Simple c compiler gen expr",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/chibicc-gen-expr/"}},{id:"post-python-pyplot-trick",title:"Python pyplot trick",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/python-plot-trick/"}},{id:"post-simple-lru-cache-cpp-implementation",title:"Simple lru cache cpp implementation",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/lru-cache/"}},{id:"post-python-capture-function-print-output",title:"Python capture function print output",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/capture-output-python/"}},{id:"post-simple-c-compiler",title:"Simple c compiler",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/chibicc-compiler/"}},{id:"post-calloc-and-malloc",title:"calloc and malloc",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/calloc/"}},{id:"post-lightgbm-dataset",title:"LightGBM dataset",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/lightgbm-dataset/"}},{id:"post-difference-between-deep-copy-and-shallow-copy-in-python",title:"Difference between deep copy and shallow copy in python",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/python-deep-copy/"}},{id:"post-python-package-path",title:"Python Package Path",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/python-package-path/"}},{id:"post-micrograd",title:"micrograd",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/micrograd/"}},{id:"post-cpp-thread-local",title:"cpp thread local",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/cpp-thread-local/"}},{id:"post-cpp-async",title:"cpp async",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/cpp-async/"}},{id:"post-python-dataframe-drop-row",title:"python dataframe drop row",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/df-drop-row/"}},{id:"post-git-merge-file-from-another-branch",title:"Git merge file from another branch",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/git-merge-file-from-another-branch/"}},{id:"post-efficiency-tips",title:"Efficiency tips",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/efficiency-tips/"}},{id:"post-speed-up-matrix-multiplication",title:"Speed up matrix multiplication",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/matrix-multiplication/"}},{id:"post-how-to-write-research-paper",title:"How to write research paper",description:"How to write research paper",section:"Posts",handler:()=>{window.location.href="/blog/2024/how-to-write-research-paper/"}},{id:"post-fast-nano-gpt-training",title:"Fast nano-gpt training",description:"llm",section:"Posts",handler:()=>{window.location.href="/blog/2024/gpt-fast/"}},{id:"post-system-for-machine-learning-papers",title:"System for machine learning papers",description:"sysml papers",section:"Posts",handler:()=>{window.location.href="/blog/2024/sysml-papers/"}},{id:"post-nano-gpt-and-transformer",title:"nano-gpt and Transformer",description:"llm",section:"Posts",handler:()=>{window.location.href="/blog/2024/transformer/"}},{id:"post-pytorch-tensor-to",title:"pytorch tensor.to",description:"pytorch",section:"Posts",handler:()=>{window.location.href="/blog/2024/pytorch/"}},{id:"post-install-neovim-with-old-glibc",title:"Install neovim with old glibc",description:"vim",section:"Posts",handler:()=>{window.location.href="/blog/2024/install-neovim/"}},{id:"post-llm-c",title:"llm.c",description:"llm minikune",section:"Posts",handler:()=>{window.location.href="/blog/2024/llm-c/"}},{id:"post-basic-digital-electronic",title:"Basic digital electronic",description:"transistor",section:"Posts",handler:()=>{window.location.href="/blog/2024/digital-electronic/"}},{id:"post-k8s-advance",title:"K8s Advance",description:"k8s minikune",section:"Posts",handler:()=>{window.location.href="/blog/2024/k8s-advance/"}},{id:"post-difference-between-dockerfile-and-docker-compose",title:"Difference between Dockerfile and Docker Compose",description:"",section:"Posts",handler:()=>{window.open("https://bilyz.medium.com/difference-between-dockerfile-and-docker-compose-d6ebdc687785?source=rss-da1663a42461------2","_blank")}},{id:"post-docker-rocksdb-build",title:"Docker Rocksdb build",description:"",section:"Posts",handler:()=>{window.open("https://bilyz.medium.com/docker-rocksdb-build-18a0bf0e0bb0?source=rss-da1663a42461------2","_blank")}},{id:"post-k3s-beginner",title:"K3s beginner",description:"k3s",section:"Posts",handler:()=>{window.location.href="/blog/2024/k3s/"}},{id:"post-docker-rocksdb",title:"Docker RocksDB",description:"cloud",section:"Posts",handler:()=>{window.location.href="/blog/2024/docker-rocksdb/"}},{id:"post-docker-beginner",title:"Docker beginner",description:"cloud",section:"Posts",handler:()=>{window.location.href="/blog/2024/docker-file-compose-diff/"}},{id:"post-git",title:"Git",description:"git",section:"Posts",handler:()=>{window.location.href="/blog/2024/git/"}},{id:"post-lightgbm-usage-and-implementation",title:"LightGBM usage and implementation",description:"Artificial Intelligence",section:"Posts",handler:()=>{window.location.href="/blog/2024/lightgbm-usage/"}},{id:"post-backpropogation-c-implementation",title:"Backpropogation C++ Implementation",description:"Artificial Intelligence",section:"Posts",handler:()=>{window.location.href="/blog/2024/back-propagation/"}},{id:"post-conda-usage",title:"Conda usage",description:"Artificial Intelligence",section:"Posts",handler:()=>{window.location.href="/blog/2024/conda/"}},{id:"post-install-k8s-cluster-with-3-ubuntu-nodes",title:"Install K8s cluster with 3 ubuntu nodes",description:"cloud",section:"Posts",handler:()=>{window.location.href="/blog/2024/cloud/"}},{id:"post-convert-svg-figures-to-pdf-latex-before-submitting-to-arxiv",title:"Convert SVG figures to pdf_latex before submitting to arxiv",description:"Convert SVG figures to pdf_latex before submitting to arxiv",section:"Posts",handler:()=>{window.location.href="/blog/2024/arxiv-cleaner/"}},{id:"post-binary-search-algorithm-variant",title:"Binary search algorithm variant",description:"",section:"Posts",handler:()=>{window.open("https://bilyz.medium.com/binary-search-algorithm-variant-9b5310473471?source=rss-da1663a42461------2","_blank")}},{id:"post-my-question",title:"my question:",description:"",section:"Posts",handler:()=>{window.open("https://bilyz.medium.com/my-question-a69930f167f0?source=rss-da1663a42461------2","_blank")}},{id:"post-learning-based-memory-allocation-for-c-server-workloads-summary",title:"Learning-based memory allocation for C++ server workloads summary",description:"",section:"Posts",handler:()=>{window.open("https://bilyz.medium.com/learning-based-memory-allocation-for-c-server-workloads-summary-479e9cd6d6f6?source=rss-da1663a42461------2","_blank")}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march &amp; april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%7A%68%75%61%6E%67%7A%68%75%74%61%6F@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/BilyZ98","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>