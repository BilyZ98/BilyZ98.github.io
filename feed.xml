<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://bilyz98.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://bilyz98.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-06-12T13:26:59+00:00</updated><id>https://bilyz98.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">LightGBM usage and implementation</title><link href="https://bilyz98.github.io/blog/2024/lightgbm-usage/" rel="alternate" type="text/html" title="LightGBM usage and implementation"/><published>2024-06-08T11:59:00+00:00</published><updated>2024-06-08T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/lightgbm-usage</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/lightgbm-usage/"><![CDATA[<h1 id="lightgbm">LightGBM</h1> <h2 id="lightgbm-pay-more-attention-minority-class">LightGBM pay more attention minority class</h2> <p>In LightGBM, there are several ways to handle imbalanced data and pay more attention to the minority class:</p> <p>is_unbalance parameter: You can set the is_unbalance parameter to true when training the LightGBM model. This will automatically adjust the weights of the classes to be inversely proportional to their frequencies1. scale_pos_weight parameter: This parameter can provide better control of the weights of the minority and majority classes1. It allows you to set a configurable weight for the minority class1. class_weight parameter: This parameter is available in the LGBMClassifier and can be used to directly handle imbalanced data2. Customized metric or sample weights: You can also use a customized metric or apply weights to your samples3. Remember, when dealing with imbalanced data, accuracy is not the best metric. Instead, consider using metrics such as recall, precision, F1 score, or AUC4. You can also use ‘weighted’ or ‘micro’ averaging methods4.</p> <p>Here’s a simple example of how you might use the is_unbalance parameter in the C API:</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;LightGBM/c_api.h&gt;</span><span class="cp">
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">param</span> <span class="o">=</span> <span class="s">"objective=binary is_unbalance=true"</span><span class="p">;</span>
    <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">train_data_filename</span> <span class="o">=</span> <span class="s">"train.txt"</span><span class="p">;</span>
    <span class="n">DatasetHandle</span> <span class="n">train_data</span><span class="p">;</span>
    <span class="n">BoosterHandle</span> <span class="n">booster</span><span class="p">;</span>

    <span class="c1">// Load training data</span>
    <span class="n">LGBM_DatasetCreateFromFile</span><span class="p">(</span><span class="n">train_data_filename</span><span class="p">,</span> <span class="n">param</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">train_data</span><span class="p">);</span>

    <span class="c1">// Create booster</span>
    <span class="n">LGBM_BoosterCreate</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">param</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">booster</span><span class="p">);</span>

    <span class="c1">// Train model</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">100</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">LGBM_BoosterUpdateOneIter</span><span class="p">(</span><span class="n">booster</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="c1">// Save model</span>
    <span class="n">LGBM_BoosterSaveModel</span><span class="p">(</span><span class="n">booster</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s">"LightGBM_model.txt"</span><span class="p">);</span>

    <span class="c1">// Free resources</span>
    <span class="n">LGBM_BoosterFree</span><span class="p">(</span><span class="n">booster</span><span class="p">);</span>
</code></pre></div></div> <h2 id="id3-algorithm-that-trains-decision-tree">ID3 algorithm that trains decision tree</h2> <p>The training process of a decision tree involves building the tree and determining the split points of the features that most effectively separate the data. Here’s a simplified example of how a decision tree might be trained using the ID3 algorithm:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">ID3</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">original_data</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">target_attribute_name</span><span class="o">=</span><span class="sh">"</span><span class="s">class</span><span class="sh">"</span><span class="p">,</span> <span class="n">parent_node_class</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="c1"># If all target_values have the same value, return this value
</span>    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">target_attribute_name</span><span class="p">]))</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">target_attribute_name</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># If the dataset is empty, return the mode target feature value in the original dataset
</span>    <span class="k">elif</span> <span class="nf">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">original_data</span><span class="p">[</span><span class="n">target_attribute_name</span><span class="p">])[</span><span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">original_data</span><span class="p">[</span><span class="n">target_attribute_name</span><span class="p">],</span> <span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">])]</span>

    <span class="c1"># If the feature space is empty, return the mode target feature value of the direct parent node
</span>    <span class="k">elif</span> <span class="nf">len</span><span class="p">(</span><span class="n">features</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">parent_node_class</span>

    <span class="c1"># If none of the above holds true, grow the tree!
</span>    <span class="k">else</span><span class="p">:</span>
        <span class="n">parent_node_class</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">target_attribute_name</span><span class="p">])[</span><span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">target_attribute_name</span><span class="p">],</span> <span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">])]</span>

        <span class="c1"># Select the feature which best splits the dataset
</span>        <span class="n">item_values</span> <span class="o">=</span> <span class="p">[</span><span class="nc">InfoGain</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">feature</span><span class="p">,</span> <span class="n">target_attribute_name</span><span class="p">)</span> <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">features</span><span class="p">]</span>
        <span class="n">best_feature_index</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">item_values</span><span class="p">)</span>
        <span class="n">best_feature</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">best_feature_index</span><span class="p">]</span>

        <span class="c1"># Create the tree structure
</span>        <span class="n">tree</span> <span class="o">=</span> <span class="p">{</span><span class="n">best_feature</span><span class="p">:</span> <span class="p">{}}</span>

        <span class="c1"># Remove the feature with the best info gain from the feature space
</span>        <span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">features</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">best_feature</span><span class="p">]</span>

        <span class="c1"># Grow a branch under the root node for each possible value of the root node feature
</span>        <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">best_feature</span><span class="p">]):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">value</span>
            <span class="n">sub_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">best_feature</span><span class="p">]</span> <span class="o">==</span> <span class="n">value</span><span class="p">).</span><span class="nf">dropna</span><span class="p">()</span>

            <span class="c1"># Call the ID3 algorithm for each of those sub_datasets with the new parameters
</span>            <span class="n">subtree</span> <span class="o">=</span> <span class="nc">ID3</span><span class="p">(</span><span class="n">sub_data</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">target_attribute_name</span><span class="p">,</span> <span class="n">parent_node_class</span><span class="p">)</span>

            <span class="c1"># Add the sub tree, grown from the sub_dataset to the tree under the root node
</span>            <span class="n">tree</span><span class="p">[</span><span class="n">best_feature</span><span class="p">][</span><span class="n">value</span><span class="p">]</span> <span class="o">=</span> <span class="n">subtree</span>

        <span class="k">return</span> <span class="n">tree</span>
</code></pre></div></div> <p>In this code, the ID3 function is a recursive function that builds a decision tree using the ID3 algorithm. The function takes as input a dataset, a list of features to consider for splitting, and the name of the target attribute. It also takes an optional argument parent_node_class that is used to determine the class label for a node when no further splitting can be done.</p> <p>The function works by first checking for the base cases that would terminate the recursion: all instances having the same class, no more instances left, no more features left, or no more value left for the feature to split upon. If none of these cases are met, it calculates the information gain of the features and selects the feature with the highest information gain to split upon. It then creates a new tree node for this feature and calls the ID3 function recursively on the sub-datasets to build the subtrees.</p> <p>Please note that this is a simplified example. Real-world decision tree learning algorithms like those used in scikit-learn or LightGBM are more complex and optimized. They also handle more cases, like missing values and different types of features (continuous, categorical, etc.). They also use different criteria for splitting, like Gini impurity or information gain ratio. The ID3 algorithm is one of the simplest decision tree learning algorithms and is a good starting point for understanding the basics.</p> <h2 id="code-example-of-calling-lgbm_boosterpredictforcsrsinglerowfast">Code example of calling LGBM_BoosterPredictForCSRSingleRowFast</h2> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;lightgbm/c_api.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;stdlib.h&gt;</span><span class="cp">
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="c1">// Assume we have a trained model and a FastConfigHandle</span>
    <span class="n">FastConfigHandle</span> <span class="n">fastConfig_handle</span><span class="p">;</span>

    <span class="c1">// Define a single row of data in CSR format</span>
    <span class="kt">int</span> <span class="n">indptr_type</span> <span class="o">=</span> <span class="n">C_API_DTYPE_INT32</span><span class="p">;</span>
    <span class="kt">int64_t</span> <span class="n">nindptr</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">int64_t</span> <span class="n">nelem</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

    <span class="kt">int</span><span class="o">*</span> <span class="n">indptr</span> <span class="o">=</span> <span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">nindptr</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
    <span class="n">indptr</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="n">indptr</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">nelem</span><span class="p">;</span>

    <span class="kt">int32_t</span><span class="o">*</span> <span class="n">indices</span> <span class="o">=</span> <span class="p">(</span><span class="kt">int32_t</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">nelem</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int32_t</span><span class="p">));</span>
    <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="n">indices</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="n">indices</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>

    <span class="kt">double</span><span class="o">*</span> <span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="kt">double</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">nelem</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">double</span><span class="p">));</span>
    <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">.</span><span class="mi">0</span><span class="p">;</span>
    <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">3</span><span class="p">.</span><span class="mi">0</span><span class="p">;</span>
    <span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">5</span><span class="p">.</span><span class="mi">0</span><span class="p">;</span>

    <span class="c1">// Output variables</span>
    <span class="kt">int64_t</span> <span class="n">out_len</span><span class="p">;</span>
    <span class="kt">double</span><span class="o">*</span> <span class="n">out_result</span> <span class="o">=</span> <span class="p">(</span><span class="kt">double</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">double</span><span class="p">));</span>

    <span class="c1">// Call the function</span>
    <span class="kt">int</span> <span class="n">result</span> <span class="o">=</span> <span class="n">LGBM_BoosterPredictForCSRSingleRowFast</span><span class="p">(</span><span class="n">fastConfig_handle</span><span class="p">,</span> <span class="n">indptr</span><span class="p">,</span> <span class="n">indptr_type</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">nindptr</span><span class="p">,</span> <span class="n">nelem</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">out_len</span><span class="p">,</span> <span class="n">out_result</span><span class="p">);</span>

    <span class="c1">// Check the result</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">result</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"Prediction successful, output length: %lld</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">out_len</span><span class="p">);</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"Prediction failed, error code: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">result</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="c1">// Free allocated memory</span>
    <span class="n">free</span><span class="p">(</span><span class="n">indptr</span><span class="p">);</span>
    <span class="n">free</span><span class="p">(</span><span class="n">indices</span><span class="p">);</span>
    <span class="n">free</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>
    <span class="n">free</span><span class="p">(</span><span class="n">out_result</span><span class="p">);</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>In this example, we’re creating a single row of data with three non-zero elements. The <code class="language-plaintext highlighter-rouge">indptr</code> array defines the start and end of the row in the <code class="language-plaintext highlighter-rouge">indices</code> and <code class="language-plaintext highlighter-rouge">data</code> arrays. The <code class="language-plaintext highlighter-rouge">indices</code> array contains the column indices of the non-zero elements, and the <code class="language-plaintext highlighter-rouge">data</code> array contains the values of the non-zero elements.</p> <p>Please replace the placeholders with your actual data and handle. Also, make sure to handle the memory correctly, especially for the <code class="language-plaintext highlighter-rouge">out_result</code> pointer. This is just a basic example and does not include error checking or memory management. You should add those in your actual code.</p> <p>Remember to link against the LightGBM library when compiling this code. If you’re using gcc, you can do this with <code class="language-plaintext highlighter-rouge">-lLightGBM</code>. If you’re using Visual Studio, you’ll need to add the LightGBM library to your project settings.</p> <h2 id="source-code-of-gbdt-train">Source code of GBDT train()</h2> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">class</span> <span class="n">ObjectiveFunction</span> <span class="p">{</span>
 <span class="nl">public:</span>
  <span class="cm">/*! \brief virtual destructor */</span>
  <span class="k">virtual</span> <span class="o">~</span><span class="n">ObjectiveFunction</span><span class="p">()</span> <span class="p">{}</span>

  <span class="cm">/*!
  * \brief Initialize
  * \param metadata Label data
  * \param num_data Number of data
  */</span>
  <span class="k">virtual</span> <span class="kt">void</span> <span class="n">Init</span><span class="p">(</span><span class="k">const</span> <span class="n">Metadata</span><span class="o">&amp;</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">data_size_t</span> <span class="n">num_data</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

  <span class="cm">/*!
  * \brief calculating first order derivative of loss function
  * \param score prediction score in this round
  * \gradients Output gradients
  * \hessians Output hessians
  */</span>
  <span class="k">virtual</span> <span class="kt">void</span> <span class="n">GetGradients</span><span class="p">(</span><span class="k">const</span> <span class="kt">double</span><span class="o">*</span> <span class="n">score</span><span class="p">,</span>
    <span class="n">score_t</span><span class="o">*</span> <span class="n">gradients</span><span class="p">,</span> <span class="n">score_t</span><span class="o">*</span> <span class="n">hessians</span><span class="p">)</span> <span class="k">const</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>


</code></pre></div></div> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="n">GBDT</span><span class="o">::</span><span class="n">Train</span><span class="p">(</span><span class="kt">int</span> <span class="n">snapshot_freq</span><span class="p">,</span> <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span> <span class="n">model_output_path</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">Common</span><span class="o">::</span><span class="n">FunctionTimer</span> <span class="n">fun_timer</span><span class="p">(</span><span class="s">"GBDT::Train"</span><span class="p">,</span> <span class="n">global_timer</span><span class="p">);</span>
  <span class="n">bool</span> <span class="n">is_finished</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
  <span class="k">auto</span> <span class="n">start_time</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">steady_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">iter</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">iter</span> <span class="o">&lt;</span> <span class="n">config_</span><span class="o">-&gt;</span><span class="n">num_iterations</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">is_finished</span><span class="p">;</span> <span class="o">++</span><span class="n">iter</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">is_finished</span> <span class="o">=</span> <span class="n">TrainOneIter</span><span class="p">(</span><span class="n">nullptr</span><span class="p">,</span> <span class="n">nullptr</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">is_finished</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">is_finished</span> <span class="o">=</span> <span class="n">EvalAndCheckEarlyStopping</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="k">auto</span> <span class="n">end_time</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">steady_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
    <span class="c1">// output used time per iteration</span>
    <span class="n">Log</span><span class="o">::</span><span class="n">Info</span><span class="p">(</span><span class="s">"%f seconds elapsed, finished iteration %d"</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration</span><span class="o">&lt;</span><span class="kt">double</span><span class="p">,</span>
              <span class="n">std</span><span class="o">::</span><span class="n">milli</span><span class="o">&gt;</span><span class="p">(</span><span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="n">iter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">snapshot_freq</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">iter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">snapshot_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">snapshot_out</span> <span class="o">=</span> <span class="n">model_output_path</span> <span class="o">+</span> <span class="s">".snapshot_iter_"</span> <span class="o">+</span> <span class="n">std</span><span class="o">::</span><span class="n">to_string</span><span class="p">(</span><span class="n">iter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">);</span>
      <span class="n">SaveModelToFile</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">config_</span><span class="o">-&gt;</span><span class="n">saved_feature_importance_type</span><span class="p">,</span> <span class="n">snapshot_out</span><span class="p">.</span><span class="n">c_str</span><span class="p">());</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
    <span class="n">bool</span> <span class="n">GBDT</span><span class="o">::</span><span class="n">TrainOneIter</span><span class="p">(</span><span class="k">const</span> <span class="n">score_t</span><span class="o">*</span> <span class="n">gradients</span><span class="p">,</span> <span class="k">const</span> <span class="n">score_t</span><span class="o">*</span> <span class="n">hessians</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">Common</span><span class="o">::</span><span class="n">FunctionTimer</span> <span class="n">fun_timer</span><span class="p">(</span><span class="s">"GBDT::TrainOneIter"</span><span class="p">,</span> <span class="n">global_timer</span><span class="p">);</span>
      <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">init_scores</span><span class="p">(</span><span class="n">num_tree_per_iteration_</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">);</span>
      <span class="c1">// boosting first</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">gradients</span> <span class="o">==</span> <span class="n">nullptr</span> <span class="o">||</span> <span class="n">hessians</span> <span class="o">==</span> <span class="n">nullptr</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">cur_tree_id</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">cur_tree_id</span> <span class="o">&lt;</span> <span class="n">num_tree_per_iteration_</span><span class="p">;</span> <span class="o">++</span><span class="n">cur_tree_id</span><span class="p">)</span> <span class="p">{</span>
          <span class="n">init_scores</span><span class="p">[</span><span class="n">cur_tree_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">BoostFromAverage</span><span class="p">(</span><span class="n">cur_tree_id</span><span class="p">,</span> <span class="nb">true</span><span class="p">);</span>
        <span class="p">}</span>
        <span class="n">Boosting</span><span class="p">();</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">gradients_pointer_</span><span class="p">;</span>
        <span class="n">hessians</span> <span class="o">=</span> <span class="n">hessians_pointer_</span><span class="p">;</span>
      <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="c1">// use customized objective function</span>
        <span class="n">CHECK</span><span class="p">(</span><span class="n">objective_function_</span> <span class="o">==</span> <span class="n">nullptr</span><span class="p">);</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">data_sample_strategy_</span><span class="o">-&gt;</span><span class="n">IsHessianChange</span><span class="p">())</span> <span class="p">{</span>
          <span class="c1">// need to copy customized gradients when using GOSS</span>
          <span class="kt">int64_t</span> <span class="n">total_size</span> <span class="o">=</span> <span class="n">static_cast</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">num_data_</span><span class="p">)</span> <span class="o">*</span> <span class="n">num_tree_per_iteration_</span><span class="p">;</span>
          <span class="cp">#pragma omp parallel for schedule(static)
</span>          <span class="k">for</span> <span class="p">(</span><span class="kt">int64_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">total_size</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">gradients_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
            <span class="n">hessians_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">hessians</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
          <span class="p">}</span>
          <span class="n">CHECK_EQ</span><span class="p">(</span><span class="n">gradients_pointer_</span><span class="p">,</span> <span class="n">gradients_</span><span class="p">.</span><span class="n">data</span><span class="p">());</span>
          <span class="n">CHECK_EQ</span><span class="p">(</span><span class="n">hessians_pointer_</span><span class="p">,</span> <span class="n">hessians_</span><span class="p">.</span><span class="n">data</span><span class="p">());</span>
          <span class="n">gradients</span> <span class="o">=</span> <span class="n">gradients_pointer_</span><span class="p">;</span>
          <span class="n">hessians</span> <span class="o">=</span> <span class="n">hessians_pointer_</span><span class="p">;</span>
        <span class="p">}</span>
      <span class="p">}</span>

            <span class="kt">void</span> <span class="n">GBDT</span><span class="o">::</span><span class="n">Boosting</span><span class="p">()</span> <span class="p">{</span>
              <span class="n">Common</span><span class="o">::</span><span class="n">FunctionTimer</span> <span class="n">fun_timer</span><span class="p">(</span><span class="s">"GBDT::Boosting"</span><span class="p">,</span> <span class="n">global_timer</span><span class="p">);</span>
              <span class="k">if</span> <span class="p">(</span><span class="n">objective_function_</span> <span class="o">==</span> <span class="n">nullptr</span><span class="p">)</span> <span class="p">{</span>
                <span class="n">Log</span><span class="o">::</span><span class="n">Fatal</span><span class="p">(</span><span class="s">"No objective function provided"</span><span class="p">);</span>
              <span class="p">}</span>
              <span class="c1">// objective function will calculate gradients and hessians</span>
              <span class="kt">int64_t</span> <span class="n">num_score</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
              <span class="n">objective_function_</span><span class="o">-&gt;</span>
                <span class="n">GetGradients</span><span class="p">(</span><span class="n">GetTrainingScore</span><span class="p">(</span><span class="o">&amp;</span><span class="n">num_score</span><span class="p">),</span> <span class="n">gradients_pointer_</span><span class="p">,</span> <span class="n">hessians_pointer_</span><span class="p">);</span>
            <span class="p">}</span>
              <span class="kt">void</span> <span class="n">GetGradients</span><span class="p">(</span><span class="k">const</span> <span class="kt">double</span><span class="o">*</span> <span class="n">score</span><span class="p">,</span> <span class="n">score_t</span><span class="o">*</span> <span class="n">gradients</span><span class="p">,</span> <span class="n">score_t</span><span class="o">*</span> <span class="n">hessians</span><span class="p">)</span> <span class="k">const</span> <span class="n">override</span> <span class="p">{</span>
                <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">need_train_</span><span class="p">)</span> <span class="p">{</span>
                  <span class="k">return</span><span class="p">;</span>
                <span class="p">}</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">weights_</span> <span class="o">==</span> <span class="n">nullptr</span><span class="p">)</span> <span class="p">{</span>
                  <span class="cp">#pragma omp parallel for schedule(static)
</span>                  <span class="k">for</span> <span class="p">(</span><span class="n">data_size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_data_</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
                    <span class="c1">// get label and label weights</span>
                    <span class="k">const</span> <span class="kt">int</span> <span class="n">is_pos</span> <span class="o">=</span> <span class="n">is_pos_</span><span class="p">(</span><span class="n">label_</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
                    <span class="k">const</span> <span class="kt">int</span> <span class="n">label</span> <span class="o">=</span> <span class="n">label_val_</span><span class="p">[</span><span class="n">is_pos</span><span class="p">];</span>
                    <span class="k">const</span> <span class="kt">double</span> <span class="n">label_weight</span> <span class="o">=</span> <span class="n">label_weights_</span><span class="p">[</span><span class="n">is_pos</span><span class="p">];</span>
                    <span class="c1">// calculate gradients and hessians</span>
                    <span class="k">const</span> <span class="kt">double</span> <span class="n">response</span> <span class="o">=</span> <span class="o">-</span><span class="n">label</span> <span class="o">*</span> <span class="n">sigmoid_</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span> <span class="o">+</span> <span class="n">std</span><span class="o">::</span><span class="n">exp</span><span class="p">(</span><span class="n">label</span> <span class="o">*</span> <span class="n">sigmoid_</span> <span class="o">*</span> <span class="n">score</span><span class="p">[</span><span class="n">i</span><span class="p">]));</span>
                    <span class="k">const</span> <span class="kt">double</span> <span class="n">abs_response</span> <span class="o">=</span> <span class="n">fabs</span><span class="p">(</span><span class="n">response</span><span class="p">);</span>
                    <span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">static_cast</span><span class="o">&lt;</span><span class="n">score_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">response</span> <span class="o">*</span> <span class="n">label_weight</span><span class="p">);</span>
                    <span class="n">hessians</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">static_cast</span><span class="o">&lt;</span><span class="n">score_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">abs_response</span> <span class="o">*</span> <span class="p">(</span><span class="n">sigmoid_</span> <span class="o">-</span> <span class="n">abs_response</span><span class="p">)</span> <span class="o">*</span> <span class="n">label_weight</span><span class="p">);</span>
                  <span class="p">}</span>
                <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>

</code></pre></div></div> <h2 id="training-code-snipet">Training code snipet</h2> <p>python</p> <p>c</p> <h2 id="csrcompressed-sparsed-row-format">CSR(Compressed Sparsed Row) format</h2> <p>It uses three one dimensional arrays to store non-zero values. This is efficient for sparse matrixes where most of the elements are zero.</p> <p>In the context of a Compressed Sparse Row (CSR) matrix, <code class="language-plaintext highlighter-rouge">indptr</code> and <code class="language-plaintext highlighter-rouge">indices</code> are arrays used to represent sparse data. Here’s what they mean:</p> <ul> <li> <p><code class="language-plaintext highlighter-rouge">indptr</code>: This is short for “index pointer”. It is an integer array of length <code class="language-plaintext highlighter-rouge">n_rows + 1</code> where <code class="language-plaintext highlighter-rouge">n_rows</code> is the number of rows in your matrix. The <code class="language-plaintext highlighter-rouge">indptr</code> array defines the index ranges for rows of the matrix. If <code class="language-plaintext highlighter-rouge">indptr[i] = x</code> and <code class="language-plaintext highlighter-rouge">indptr[i+1] = y</code>, this means that the data for row <code class="language-plaintext highlighter-rouge">i</code> in the matrix is stored in <code class="language-plaintext highlighter-rouge">indices[x:y]</code> and <code class="language-plaintext highlighter-rouge">data[x:y]</code>.</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">indices</code>: This is an integer array that contains column indices of non-zero elements. The column indices for row <code class="language-plaintext highlighter-rouge">i</code> are stored in <code class="language-plaintext highlighter-rouge">indices[indptr[i]:indptr[i+1]]</code>.</p> </li> </ul> <p>Here’s a simple example:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">scipy.sparse</span> <span class="kn">import</span> <span class="n">csr_matrix</span>

<span class="c1"># Create a CSR matrix
</span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">indptr</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">csr</span> <span class="o">=</span> <span class="nf">csr_matrix</span><span class="p">((</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">indptr</span><span class="p">),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="nf">print</span><span class="p">(</span><span class="n">csr</span><span class="p">.</span><span class="nf">toarray</span><span class="p">())</span>
</code></pre></div></div> <p>This will output:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[[</span><span class="mi">1</span> <span class="mi">0</span> <span class="mi">2</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">3</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">4</span> <span class="mi">5</span> <span class="mi">6</span><span class="p">]]</span>
</code></pre></div></div> <p>In this matrix, the non-zero elements of the first row are <code class="language-plaintext highlighter-rouge">1</code> (at column <code class="language-plaintext highlighter-rouge">0</code>) and <code class="language-plaintext highlighter-rouge">2</code> (at column <code class="language-plaintext highlighter-rouge">2</code>), which corresponds to <code class="language-plaintext highlighter-rouge">indices[0:2]</code> and <code class="language-plaintext highlighter-rouge">data[0:2]</code>. The non-zero elements of the second row are <code class="language-plaintext highlighter-rouge">3</code> (at column <code class="language-plaintext highlighter-rouge">2</code>), which corresponds to <code class="language-plaintext highlighter-rouge">indices[2:3]</code> and <code class="language-plaintext highlighter-rouge">data[2:3]</code>. The non-zero elements of the third row are <code class="language-plaintext highlighter-rouge">4</code> (at column <code class="language-plaintext highlighter-rouge">0</code>), <code class="language-plaintext highlighter-rouge">5</code> (at column <code class="language-plaintext highlighter-rouge">1</code>), and <code class="language-plaintext highlighter-rouge">6</code> (at column <code class="language-plaintext highlighter-rouge">2</code>), which corresponds to <code class="language-plaintext highlighter-rouge">indices[3:6]</code> and <code class="language-plaintext highlighter-rouge">data[3:6]</code>.</p>]]></content><author><name></name></author><category term="ai"/><category term="ai"/><category term="ml"/><summary type="html"><![CDATA[Artificial Intelligence]]></summary></entry><entry><title type="html">Artificial Intelligence</title><link href="https://bilyz98.github.io/blog/2024/ai/" rel="alternate" type="text/html" title="Artificial Intelligence"/><published>2024-06-06T11:59:00+00:00</published><updated>2024-06-06T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/ai</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/ai/"><![CDATA[<h1 id="artificial-intelligence">Artificial Intelligence</h1> <h2 id="difference-between-cuda-core-and-cpu-core">Difference between CUDA core and CPU core?</h2> <h2 id="mlsys-seminars-and-resources">MLSys seminars and resources</h2> <ul> <li><a href="https://mlsys-sg.org/about/">https://mlsys-sg.org/about/</a></li> <li><a href="https://www.youtube.com/@StanfordMLSysSeminars">Stanford MLSys seminar</a></li> <li><a href="https://www.youtube.com/@MITHANLab/videos">MIT HAN Lab</a></li> </ul> <h2 id="system-for-llm-papers">System for LLM papers</h2> <ul> <li><a href="https://arxiv.org/pdf/2001.08361.pdf">Scaling Laws for Neural Language Models</a></li> </ul> <h2 id="conda">Conda</h2> <p>What is conda? Conda is a package version management system for python project. For example you can set python running version to 3.7 while running oaas and then set python version to 3.11 in anohter env while running another python project.</p> <p>Install specific version of packge The reason we need to do this is that some whl files requires specific version of python to work.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda install python=3.7
</code></pre></div></div> <p>Create conda workspace for one project</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda create --name &lt;my-env&gt; python=&lt;version&gt;
</code></pre></div></div> <p>Activate conda env</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda activate &lt;my-env&gt;
</code></pre></div></div>]]></content><author><name></name></author><category term="ai"/><category term="ai"/><category term="ml"/><summary type="html"><![CDATA[Artificial Intelligence]]></summary></entry><entry><title type="html">Backpropogation C++ Implementation</title><link href="https://bilyz98.github.io/blog/2024/back-propagation/" rel="alternate" type="text/html" title="Backpropogation C++ Implementation"/><published>2024-06-06T11:59:00+00:00</published><updated>2024-06-06T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/back-propagation</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/back-propagation/"><![CDATA[<h2 id="backpropagation-code-example">Backpropagation code example</h2> <p><a href="https://alexgl-github.github.io/github/jekyll/2021/04/16/Dense_layer.html">Deep learning models from scratch using C++ and Python</a></p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;cstdio&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;vector&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;algorithm&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;cassert&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;numeric&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;array&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;chrono&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;string&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;functional&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;array&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;iterator&gt;</span><span class="cp">
</span>

<span class="k">using</span> <span class="k">namespace</span> <span class="n">std</span><span class="p">;</span>
<span class="k">using</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">high_resolution_clock</span><span class="p">;</span>
<span class="k">using</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration_cast</span><span class="p">;</span>
<span class="k">using</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">microseconds</span><span class="p">;</span>

<span class="k">static</span> <span class="k">auto</span> <span class="n">ones_initializer</span> <span class="o">=</span> <span class="p">[]()</span> <span class="o">-&gt;</span> <span class="kt">float</span> <span class="p">{</span>
  <span class="k">return</span> <span class="mf">1.0</span><span class="p">;</span>
<span class="p">};</span>

<span class="k">template</span><span class="o">&lt;</span><span class="kt">size_t</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="k">typename</span> <span class="nc">T</span> <span class="o">=</span> <span class="kt">float</span><span class="p">,</span> <span class="k">typename</span> <span class="nc">Initializer</span> <span class="o">=</span> <span class="k">decltype</span><span class="p">(</span><span class="n">ones_initializer</span><span class="p">)&gt;</span>
<span class="k">class</span> <span class="nc">Network</span> <span class="p">{</span>
<span class="nl">public:</span>
  <span class="n">Network</span><span class="p">(</span><span class="n">Initializer</span> <span class="n">initializer</span> <span class="o">=</span> <span class="n">ones_initializer</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_outputs</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">num_inputs</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">weights_</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">initializer</span><span class="p">();</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">&gt;</span> <span class="n">Forward</span><span class="p">(</span><span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="n">num_inputs</span><span class="o">&gt;&amp;</span> <span class="n">inputs</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">&gt;</span> <span class="n">outputs</span><span class="p">;</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_outputs</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">outputs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">inner_product</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">begin</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">std</span><span class="o">::</span><span class="n">end</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">std</span><span class="o">::</span><span class="n">begin</span><span class="p">(</span><span class="n">weights_</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="n">T</span><span class="p">{</span><span class="mi">0</span><span class="p">});</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">outputs</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="kt">void</span> <span class="nf">PrintWeights</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_outputs</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">num_inputs</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">weights_</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="s">" "</span><span class="p">;</span>
      <span class="p">}</span>
      <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
    <span class="p">}</span>
  <span class="p">}</span>


  <span class="kt">void</span> <span class="nf">Backward</span><span class="p">(</span><span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="n">num_inputs</span><span class="o">&gt;&amp;</span> <span class="n">inputs</span><span class="p">,</span> <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">&gt;&amp;</span> <span class="n">dloss_dy</span><span class="p">,</span> <span class="n">T</span> <span class="n">learning_rate</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_outputs</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">num_inputs</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">weights_</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dloss_dy</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">inputs</span><span class="p">[</span><span class="n">j</span><span class="p">];</span>
      <span class="p">}</span>
    <span class="p">}</span>
  
  <span class="p">}</span>
<span class="k">private</span><span class="o">:</span>
  <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="n">num_inputs</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">&gt;</span> <span class="n">weights_</span><span class="p">;</span>
<span class="p">};</span>

<span class="k">template</span><span class="o">&lt;</span><span class="kt">size_t</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="k">typename</span> <span class="nc">T</span> <span class="o">=</span> <span class="kt">float</span><span class="p">&gt;</span>
<span class="k">class</span> <span class="nc">MSE</span> <span class="p">{</span>
<span class="nl">public:</span>
  <span class="n">T</span> <span class="k">operator</span><span class="p">()(</span><span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="n">num_inputs</span><span class="o">&gt;&amp;</span> <span class="n">outputs</span><span class="p">,</span> <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="n">num_inputs</span><span class="o">&gt;&amp;</span> <span class="n">targets</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">T</span> <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_inputs</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">sum</span> <span class="o">+=</span> <span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">targets</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">*</span> <span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">targets</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">sum</span> <span class="o">/</span> <span class="n">num_inputs</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="n">num_inputs</span><span class="o">&gt;</span> <span class="n">Gradient</span><span class="p">(</span><span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="n">num_inputs</span><span class="o">&gt;&amp;</span> <span class="n">outputs</span><span class="p">,</span> <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="n">num_inputs</span><span class="o">&gt;&amp;</span> <span class="n">targets</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="n">T</span><span class="p">,</span> <span class="n">num_inputs</span><span class="o">&gt;</span> <span class="n">gradient</span><span class="p">;</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_inputs</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">gradient</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">targets</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">gradient</span><span class="p">;</span>
  <span class="p">}</span> 
<span class="p">};</span>


<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="n">Network</span><span class="o">&lt;</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="o">&gt;</span> <span class="n">network</span><span class="p">;</span>
  <span class="k">const</span> <span class="kt">int</span> <span class="n">num_iterators</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>
  <span class="n">network</span><span class="p">.</span><span class="n">PrintWeights</span><span class="p">();</span>

  <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">3</span><span class="o">&gt;</span> <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">};</span>
  <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">2</span><span class="o">&gt;</span> <span class="n">targets</span> <span class="o">=</span> <span class="p">{</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">};</span>
  <span class="n">MSE</span><span class="o">&lt;</span><span class="mi">2</span><span class="o">&gt;</span> <span class="n">mse</span><span class="p">;</span>

  <span class="k">for</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_iterators</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span> <span class="p">)</span> <span class="p">{</span>
    <span class="k">auto</span> <span class="n">start</span> <span class="o">=</span> <span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
    <span class="k">auto</span> <span class="n">yhat</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="n">Forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">);</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Loss: "</span> <span class="o">&lt;&lt;</span> <span class="n">mse</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Gradient: "</span> <span class="o">&lt;&lt;</span> <span class="n">mse</span><span class="p">.</span><span class="n">Gradient</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span> <span class="n">targets</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"yhat:"</span> <span class="o">&lt;&lt;</span>  <span class="n">yhat</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="s">" "</span> <span class="o">&lt;&lt;</span> <span class="n">yhat</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
    <span class="k">auto</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span> <span class="n">targets</span><span class="p">);</span>
    <span class="k">auto</span> <span class="n">dloss_dy</span> <span class="o">=</span> <span class="n">mse</span><span class="p">.</span><span class="n">Gradient</span><span class="p">(</span><span class="n">yhat</span><span class="p">,</span> <span class="n">targets</span><span class="p">);</span>
    <span class="n">network</span><span class="p">.</span><span class="n">Backward</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">dloss_dy</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">);</span>
    <span class="k">auto</span> <span class="n">end</span> <span class="o">=</span> <span class="n">high_resolution_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
    <span class="k">auto</span> <span class="n">duration</span> <span class="o">=</span> <span class="n">duration_cast</span><span class="o">&lt;</span><span class="n">microseconds</span><span class="o">&gt;</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">);</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Time: "</span> <span class="o">&lt;&lt;</span> <span class="n">duration</span><span class="p">.</span><span class="n">count</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="s">" microseconds"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
    <span class="n">yhat</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><span class="n">Forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">);</span> 
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"yhat"</span> <span class="o">&lt;&lt;</span> <span class="n">yhat</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="s">" "</span> <span class="o">&lt;&lt;</span> <span class="n">yhat</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
    <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"----------------"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>


  <span class="p">}</span>

  <span class="c1">// for (int i = 0; i &lt; 1000; ++i) {</span>
  <span class="c1">//   auto outputs = network.Forward(inputs);</span>
  <span class="c1">//   network.Backward(inputs, outputs, targets, 0.1);</span>
  <span class="c1">// }</span>

  <span class="n">network</span><span class="p">.</span><span class="n">PrintWeights</span><span class="p">();</span>
  <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="ai"/><category term="ai"/><category term="ml"/><summary type="html"><![CDATA[Artificial Intelligence]]></summary></entry><entry><title type="html">Install K8s cluster with 3 ubuntu nodes</title><link href="https://bilyz98.github.io/blog/2024/cloud/" rel="alternate" type="text/html" title="Install K8s cluster with 3 ubuntu nodes"/><published>2024-06-05T11:59:00+00:00</published><updated>2024-06-05T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/cloud</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/cloud/"><![CDATA[<h1 id="install-k8s-cluster-with-3-ubuntu-nodes">Install k8s cluster with 3 ubuntu nodes</h1> <h2 id="background">Background</h2> <p>Recently I encountered a computation issue where there is no enough amount of memory to process 100GB of data in memory with pandas. So I think if I can speed up computation with dask on top of k8s cluster. So then I follow k8s installation tutorial to set up 3 nodes k8s cluster. I write down this k8s installation process to help people encoutering GFW issue during k8s installtion.</p> <p><a href="https://www.cherryservers.com/blog/install-kubernetes-on-ubuntu">Follow this doc to install k8s.</a></p> <p>Things to pay attention to if you are in China and deals with GFW.</p> <ol> <li>http_proxy and https_proxy Please unset your http_proxy and https_proxy environtment vairable with following command in bash so that kubectl command can works as expected. Becuse kubectl calls curl to get information from master nodes and curl will go through proxy if if find http_proxy no empty. <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>unset http_proxy
unset https_proxy
unset HTTP_PROXY
unset HTTPS_PROXY
</code></pre></div> </div> </li> <li>image_repository in kubeadm kubeadm needs to pull image from k8s repo which might be blocked because of GFW. You can set image_repository option to pull image from aliyun in kubeadm init command <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo kubeadm init --kubernetes-version v1.28.2 \
--cri-socket=unix:///run/containerd/containerd.sock \
--apiserver-advertise-address=$(hostname -i) \
--control-plane-endpoint=$(hostname -i) \
--apiserver-cert-extra-sans=$(hostname -i) \
--image-repository=registry.aliyuncs.com/google_containers
</code></pre></div> </div> </li> <li>containerd image image_repository What is containerd ? This is what bing chat says. <strong>Containerd</strong> is an industry-standard container runtime with an emphasis on simplicity, robustness, and portability¹². It is available as a daemon for Linux and Windows¹².</li> </ol> <p>Here are some of its key features:</p> <ul> <li>Manages the complete container lifecycle of its host system, from image transfer and storage to container execution and supervision to low-level storage to network attachments and beyond¹².</li> <li>Supports OCI Image Spec and OCI Runtime Spec¹.</li> <li>It is multi-tenant and OCI-compliant¹.</li> </ul> <p>Please follow this doc to update containerd config in before you start containerd service.</p> <p><a href="https://www.cnblogs.com/wod-Y/p/17043985.html">https://www.cnblogs.com/wod-Y/p/17043985.html</a></p>]]></content><author><name></name></author><category term="cloud"/><category term="k8s"/><category term="cloud"/><summary type="html"><![CDATA[cloud]]></summary></entry><entry><title type="html">Convert SVG figures to pdf_latex before submitting to arxiv</title><link href="https://bilyz98.github.io/blog/2024/arxiv-cleaner/" rel="alternate" type="text/html" title="Convert SVG figures to pdf_latex before submitting to arxiv"/><published>2024-06-04T11:59:00+00:00</published><updated>2024-06-04T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/arxiv-cleaner</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/arxiv-cleaner/"><![CDATA[<h1 id="convert-svg-figures-to-pdf_latex-before-submitting-to-arxiv">Convert SVG figures to pdf_latex before submitting to arxiv</h1> <p>Problem: arxiv does not accept SVG figures. So I have to update code from</p> <div class="language-latex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">\includesvg</span><span class="na">[test.svg]</span>
</code></pre></div></div> <p>to</p> <div class="language-latex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">\includegraphics</span><span class="na">[width=0.5\textwidth]</span><span class="p">{</span>test.png<span class="p">}</span>
</code></pre></div></div> <p>or I can update code like this</p> <div class="language-latex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">\includeinkscape</span><span class="na">[width=0.5\textwidth]</span><span class="p">{</span>test.pdf<span class="p">_</span>latex<span class="p">}</span>
</code></pre></div></div> <p>This svg to pdf_latex conversion is done by inkscape package if you run this compilation</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pdflatex -shell-escape test.tex
</code></pre></div></div> <p>pdf_latex figures are stored in directories <code class="language-plaintext highlighter-rouge">svg_inkscape</code></p> <p>And you can use arxiv-latex-cleaner to convert</p> <div class="language-latex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">\includesvg</span><span class="na">[test.svg]</span>
</code></pre></div></div> <p>to</p> <div class="language-latex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">\includeinkscape</span><span class="na">[width=0.5\textwidth]</span><span class="p">{</span>test<span class="p">_</span>svg.pdf<span class="p">_</span>latex<span class="p">}</span>
</code></pre></div></div> <p>for you.</p> <p>This can help you save your time manually updating source code which is very handy.</p> <p><a href="https://github.com/google-research/arxiv-latex-cleaner">https://github.com/google-research/arxiv-latex-cleaner</a></p>]]></content><author><name></name></author><category term="latex"/><category term="latex"/><summary type="html"><![CDATA[Convert SVG figures to pdf_latex before submitting to arxiv]]></summary></entry><entry><title type="html">Binary search algorithm variant</title><link href="https://bilyz98.github.io/blog/2021/binary-search-algorithm-variant/" rel="alternate" type="text/html" title="Binary search algorithm variant"/><published>2021-01-12T07:00:30+00:00</published><updated>2021-01-12T07:00:30+00:00</updated><id>https://bilyz98.github.io/blog/2021/binary-search-algorithm-variant</id><content type="html" xml:base="https://bilyz98.github.io/blog/2021/binary-search-algorithm-variant/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">my question:</title><link href="https://bilyz98.github.io/blog/2020/my-question/" rel="alternate" type="text/html" title="my question:"/><published>2020-11-05T03:14:33+00:00</published><updated>2020-11-05T03:14:33+00:00</updated><id>https://bilyz98.github.io/blog/2020/my-question</id><content type="html" xml:base="https://bilyz98.github.io/blog/2020/my-question/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">Learning-based memory allocation for C++ server workloads summary</title><link href="https://bilyz98.github.io/blog/2020/learning-based-memory-allocation-for-c-server-workloads-summary/" rel="alternate" type="text/html" title="Learning-based memory allocation for C++ server workloads summary"/><published>2020-10-13T12:48:17+00:00</published><updated>2020-10-13T12:48:17+00:00</updated><id>https://bilyz98.github.io/blog/2020/learning-based-memory-allocation-for-c-server-workloads-summary</id><content type="html" xml:base="https://bilyz98.github.io/blog/2020/learning-based-memory-allocation-for-c-server-workloads-summary/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">a post with formatting and links</title><link href="https://bilyz98.github.io/blog/2015/formatting-and-links/" rel="alternate" type="text/html" title="a post with formatting and links"/><published>2015-03-15T16:40:16+00:00</published><updated>2015-03-15T16:40:16+00:00</updated><id>https://bilyz98.github.io/blog/2015/formatting-and-links</id><content type="html" xml:base="https://bilyz98.github.io/blog/2015/formatting-and-links/"><![CDATA[<p>Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. <a href="https://www.pinterest.com">Pinterest</a> DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade <a href="https://en.wikipedia.org/wiki/Cold-pressed_juice">cold-pressed</a> meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.</p> <h4 id="hipster-list">Hipster list</h4> <ul> <li>brunch</li> <li>fixie</li> <li>raybans</li> <li>messenger bag</li> </ul> <h4 id="check-list">Check List</h4> <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Brush Teeth</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Put on socks <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Put on left sock</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Put on right sock</li> </ul> </li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked"/>Go to school</li> </ul> <p>Hoodie Thundercats retro, tote bag 8-bit Godard craft beer gastropub. Truffaut Tumblr taxidermy, raw denim Kickstarter sartorial dreamcatcher. Quinoa chambray slow-carb salvia readymade, bicycle rights 90’s yr typewriter selfies letterpress cardigan vegan.</p> <hr/> <p>Pug heirloom High Life vinyl swag, single-origin coffee four dollar toast taxidermy reprehenderit fap distillery master cleanse locavore. Est anim sapiente leggings Brooklyn ea. Thundercats locavore excepteur veniam eiusmod. Raw denim Truffaut Schlitz, migas sapiente Portland VHS twee Bushwick Marfa typewriter retro id keytar.</p> <blockquote> <p>We do not grow absolutely, chronologically. We grow sometimes in one dimension, and not in another, unevenly. We grow partially. We are relative. We are mature in one realm, childish in another. —Anais Nin</p> </blockquote> <p>Fap aliqua qui, scenester pug Echo Park polaroid irony shabby chic ex cardigan church-key Odd Future accusamus. Blog stumptown sartorial squid, gastropub duis aesthetic Truffaut vero. Pinterest tilde twee, odio mumblecore jean shorts lumbersexual.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="links"/><summary type="html"><![CDATA[march & april, looking forward to summer]]></summary></entry></feed>