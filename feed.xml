<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://bilyz98.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://bilyz98.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-11-13T10:57:40+00:00</updated><id>https://bilyz98.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Elf Loading</title><link href="https://bilyz98.github.io/blog/2024/elf-loading/" rel="alternate" type="text/html" title="Elf Loading"/><published>2024-11-07T00:00:00+00:00</published><updated>2024-11-07T00:00:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/elf-loading</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/elf-loading/"><![CDATA[<p><a href="https://www.youtube.com/watch?v=IY1FwkFu44E">ELF loading video</a></p> <ul> <li>Compile-time linking</li> <li>Runtime-time linking(dynamic linking)</li> </ul> <p>Output of compiler: object file.</p> <p>This object file includes code, data symbol table, and more</p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Stf CS149 Parallel Programming - Assign3</title><link href="https://bilyz98.github.io/blog/2024/cs149-assign3/" rel="alternate" type="text/html" title="Stf CS149 Parallel Programming - Assign3"/><published>2024-11-03T11:59:00+00:00</published><updated>2024-11-03T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/cs149-assign3</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/cs149-assign3/"><![CDATA[<h2 id="part1">Part1</h2> <p>Code:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code></code></pre></div></div> <p>saxpy serial cpu output from assign1 prog5:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) ➜  prog5_saxpy git:(master) ✗ ./saxpy
[saxpy serial]:         [20.605] ms     [14.464] GB/s   [1.941] GFLOPS
[saxpy ispc]:           [17.866] ms     [16.681] GB/s   [2.239] GFLOPS
[saxpy task ispc]:      [3.122] ms      [95.446] GB/s   [12.810] GFLOPS                                                                                                                                                           (5.72x speedup from use of tasks)
</code></pre></div></div> <p>saxpy gpu cuda output</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Found 4 CUDA devices
Device 0: Tesla V100-SXM2-16GB
   SMs:        80
   Global mem: 16160 MB
   CUDA Cap:   7.0
Device 1: Tesla V100-SXM2-16GB
   SMs:        80
   Global mem: 16160 MB
   CUDA Cap:   7.0
Device 2: Tesla V100-SXM2-16GB
   SMs:        80
   Global mem: 16160 MB
   CUDA Cap:   7.0
Device 3: Tesla V100-SXM2-16GB
   SMs:        80
   Global mem: 16160 MB
   CUDA Cap:   7.0
---------------------------------------------------------
Running 3 timing tests:
Effective BW by CUDA saxpy: 225.263 ms          [4.961 GB/s]
kernel execution time: 1.503ms
Effective BW by CUDA saxpy: 247.816 ms          [4.510 GB/s]
kernel execution time: 1.504ms
Effective BW by CUDA saxpy: 245.998 ms          [4.543 GB/s]
kernel execution time: 1.506ms
</code></pre></div></div> <p>Looks like gpu bandwidth is lower than cpu</p> <p>kernel execution time is super short and all the time is taken for memory copy.</p> <p>I am a little bit confused about the two bandwidths listed in this doc https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-t4/t4-tensor-core-datasheet-951643.pdf</p> <p>gpu memory bandwidth is 300GB/sec and interconnect bandwidth is 32 GB/sec.</p> <p>I guess gpu memory bandwidth is the bandwidth that is used in internal SMs in gpu</p> <p>And interconnect bandwidth is the bandwidth during transfer data between cpu and gp</p> <p>command to run when on A800</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./cudaSaxpy: error while loading shared libraries: libcudart.so.12: cannot open shared object file: No such file or directory

[nsccgz_qylin_1@gpu72%tianhe2-K saxpy]$ echo $LD_LIBRARY_PATH | grep dart
[nsccgz_qylin_1@gpu72%tianhe2-K saxpy]$ export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
[nsccgz_qylin_1@gpu72%tianhe2-K saxpy]$ export LD_LIBRARY_PATH=/usr/local/cuda-12.0/lib64:$LD_LIBRARY_PATH
</code></pre></div></div> <h2 id="part2-parallel-prefix-sum">Part2: parallel prefix sum</h2> <p>Get this libstd lib version issue when running execution binary</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[nsccgz_qylin_1@gpu72%tianhe2-K scan]$ ./cudaScan ./cudaScan: /usr/lib64/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by ./cudaScan) ./cudaScan: /usr/lib64/libstdc++.so.6: version `CXXABI_1.3.9' not found (required by ./cudaScan) ./cudaScan: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by ./cudaScan)
</code></pre></div></div> <p>Solution: Use conda to install libstdcxx and include it in <code class="language-plaintext highlighter-rouge">LD_LIBRARY_PATH</code></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda activate myenv
conda install -c conda-forge libstdcxx-ng
find $CONDA_PREFIX -name "libstdc++.so.6"

 export LD_LIBRARY_PATH=$CONDA_PREFIX/lib:$LD_LIBRARY_PATH
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Found 4 CUDA devices
Device 0: NVIDIA A800 80GB PCIe
   SMs:        108
   Global mem: 81229 MB
   CUDA Cap:   8.0
Device 1: NVIDIA A800 80GB PCIe
   SMs:        108
   Global mem: 81229 MB
   CUDA Cap:   8.0
Device 2: NVIDIA A800 80GB PCIe
   SMs:        108
   Global mem: 81229 MB
   CUDA Cap:   8.0
Device 3: NVIDIA A800 80GB PCIe
   SMs:        108
   Global mem: 81229 MB
   CUDA Cap:   8.0
---------------------------------------------------------
Array size: 64
Student GPU time: 0.069 ms
Scan outputs are correct!
</code></pre></div></div> <h3 id="round-input-length-power-of-2-for-cudascan">Round input length power of 2 for cudaScan</h3> <h3 id="find-repeats">find repeats</h3> <p>I did not know why find repeats could be parallelized and how it can be done until I read code from others.</p> <p>The idea is that the return result of find repeats is the indices of <code class="language-plaintext highlighter-rouge">A[i]==A[i+1]</code></p> <p>This find repeats process can be parallelized with exclusive scan but we first need to generate a intermetidate representation of input arr.</p> <p>So basically we first generate a indices array which runs on cuda that can be parallelized. The output indices array is that <code class="language-plaintext highlighter-rouge">arr[i] = 1 if A[i]==A[i+1] else = 0</code>.</p> <p>This flags array is then passed to cudascan function for parallel exclusive scan to get a new array flags_sum_arr where <code class="language-plaintext highlighter-rouge">flags_sum_arr[i]</code> indicates how many repeated elements are accumulated so far.</p> <p>And then this <code class="language-plaintext highlighter-rouge">flags_sum_arr</code> is passed to another cuda kernel which is also parallelized to generated the final indices array <code class="language-plaintext highlighter-rouge">indices[i]</code>.</p> <p>This is the fun part that shows the core of parallel programming which is that each subtask has not dependency on each other. The output writing is totally independent.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// cuda kernal code</span>
<span class="k">if</span><span class="p">(</span><span class="n">flags_sum_arr</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">flags_sum_arr</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span> <span class="p">{</span>
    <span class="c1">// this indicates this is a repeated element in input array</span>
    <span class="c1">// The position of output value we need to write is flags_sum_arr[i]</span>
    <span class="c1">// The repeated element index is i.</span>
    <span class="n">indices</span><span class="p">[</span><span class="n">flags_sum_arr</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">i</span><span class="p">;</span> 
<span class="p">}</span>
</code></pre></div></div> <p>Problem:</p> <p>Input array in cpu and input array in gpu is not the same</p> <p>Why is that?</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>input arr
0:1 1:1 2:1 3:1 4:1 5:1 6:1 7:1
input arr
0:1 1:1 2:337500088 3:10935 4:0 5:0 6:0 7:0
flags arr
0:1 1:1 2:337500088 3:10935 4:0 5:0 6:0 7:0
</code></pre></div></div> <p>This is because I did not copy all bytes of intput element</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> cudaMemcpy(arr, device_input, length*sizeof(int), cudaMemcpyDeviceToHost);
</code></pre></div></div> <p>and</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
cudaMemcpy(arr, device_input, length, cudaMemcpyDeviceToHost);
</code></pre></div></div> <p>Need to copy length of <code class="language-plaintext highlighter-rouge">length*sizeof(int)</code> instead of <code class="language-plaintext highlighter-rouge">length</code></p> <p>memcpy copies number of bytes specified.</p> <p>Code:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">__global__</span> <span class="kt">void</span> 
<span class="nf">flag_repeats_kernel</span><span class="p">(</span><span class="kt">int</span><span class="o">*</span> <span class="n">input</span><span class="p">,</span> <span class="kt">int</span><span class="o">*</span> <span class="n">output</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">index</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
  <span class="k">if</span><span class="p">(</span><span class="n">index</span> <span class="o">&lt;</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span> <span class="o">&amp;&amp;</span> <span class="n">input</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">==</span> <span class="n">input</span><span class="p">[</span><span class="n">index</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span> <span class="p">{</span>
    <span class="n">output</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
  <span class="p">}</span>


<span class="p">}</span>

<span class="n">__global__</span> <span class="kt">void</span> 
<span class="nf">flags_extract_indices</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">input</span><span class="p">,</span> <span class="kt">int</span><span class="o">*</span> <span class="n">output</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span> <span class="p">)</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">index</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
  <span class="k">if</span><span class="p">(</span><span class="n">index</span> <span class="o">&lt;</span> <span class="n">N</span><span class="o">-</span><span class="mi">1</span> <span class="o">&amp;&amp;</span> <span class="n">input</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">input</span><span class="p">[</span><span class="n">index</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span> <span class="p">{</span>
    <span class="n">output</span><span class="p">[</span><span class="n">input</span><span class="p">[</span><span class="n">index</span><span class="p">]]</span> <span class="o">=</span> <span class="n">index</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="c1">// find_repeats --</span>
<span class="c1">//</span>
<span class="c1">// Given an array of integers `device_input`, returns an array of all</span>
<span class="c1">// indices `i` for which `device_input[i] == device_input[i+1]`.</span>
<span class="c1">//</span>
<span class="c1">// Returns the total number of pairs found</span>
<span class="kt">int</span> <span class="nf">find_repeats</span><span class="p">(</span><span class="kt">int</span><span class="o">*</span> <span class="n">device_input</span><span class="p">,</span> <span class="kt">int</span> <span class="n">length</span><span class="p">,</span> <span class="kt">int</span><span class="o">*</span> <span class="n">device_output</span><span class="p">)</span> <span class="p">{</span>

    <span class="c1">// CS149 TODO:</span>
    <span class="c1">//</span>
    <span class="c1">// Implement this function. You will probably want to</span>
    <span class="c1">// make use of one or more calls to exclusive_scan(), as well as</span>
    <span class="c1">// additional CUDA kernel launches.</span>
    <span class="c1">//    </span>
    <span class="c1">// Note: As in the scan code, the calling code ensures that</span>
    <span class="c1">// allocated arrays are a power of 2 in size, so you can use your</span>
    <span class="c1">// exclusive_scan function with them. However, your implementation</span>
    <span class="c1">// must ensure that the results of find_repeats are correct given</span>
    <span class="c1">// the actual array length.</span>
  <span class="kt">int</span> <span class="o">*</span><span class="n">flags_arr</span><span class="p">;</span>
  <span class="kt">int</span> <span class="o">*</span><span class="n">flags_sum_arr</span><span class="p">;</span>

  <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">flags_arr</span><span class="p">,</span> <span class="n">length</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
  <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">flags_sum_arr</span><span class="p">,</span> <span class="n">length</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>

  <span class="k">const</span> <span class="kt">int</span> <span class="n">threadsPerBlock</span> <span class="o">=</span> <span class="mi">512</span><span class="p">;</span>
  <span class="k">const</span> <span class="kt">int</span> <span class="n">blocks</span> <span class="o">=</span> <span class="p">(</span><span class="n">length</span> <span class="o">+</span> <span class="n">threadsPerBlock</span> <span class="o">-</span><span class="mi">1</span> <span class="p">)</span> <span class="o">/</span> <span class="n">threadsPerBlock</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">repeat_indices_count</span><span class="p">;</span>
  <span class="kt">int</span> <span class="o">*</span><span class="n">arr</span> <span class="o">=</span> <span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">length</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
  <span class="c1">// cudaMemcpy(arr, device_input, length*sizeof(int), cudaMemcpyDeviceToHost);</span>
  <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
  <span class="c1">// printf("input arr2\n");</span>
  <span class="c1">// print_arr(arr, length);</span>
  <span class="n">flag_repeats_kernel</span><span class="o">&lt;&lt;&lt;</span><span class="n">blocks</span><span class="p">,</span> <span class="n">threadsPerBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">device_input</span><span class="p">,</span> <span class="n">flags_arr</span><span class="p">,</span> <span class="n">length</span><span class="p">);</span>
  <span class="c1">// cudaMemcpy(arr, flags_arr, length*sizeof(int), cudaMemcpyDeviceToHost);</span>
  <span class="c1">// printf("flags arr\n");</span>
  <span class="c1">// print_arr(arr, length);</span>
  <span class="n">cudaScan</span><span class="p">(</span><span class="n">flags_arr</span><span class="p">,</span> <span class="n">flags_arr</span><span class="o">+</span><span class="n">length</span><span class="p">,</span> <span class="n">flags_sum_arr</span><span class="p">)</span> <span class="p">;</span>
  <span class="n">flags_extract_indices</span><span class="o">&lt;&lt;&lt;</span><span class="n">blocks</span><span class="p">,</span> <span class="n">threadsPerBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">flags_sum_arr</span><span class="p">,</span> <span class="n">device_output</span><span class="p">,</span> <span class="n">length</span><span class="p">);</span>
  <span class="n">cudaMemcpy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">repeat_indices_count</span><span class="p">,</span> <span class="n">flags_sum_arr</span><span class="o">+</span><span class="n">length</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>
  <span class="n">free</span><span class="p">(</span><span class="n">arr</span><span class="p">);</span>

  <span class="k">return</span> <span class="n">repeat_indices_count</span><span class="p">;</span> 

<span class="p">}</span>


<span class="c1">//</span>
<span class="c1">// cudaFindRepeats --</span>
<span class="c1">//</span>
<span class="c1">// Timing wrapper around find_repeats. You should not modify this function.</span>
<span class="kt">double</span> <span class="nf">cudaFindRepeats</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">input</span><span class="p">,</span> <span class="kt">int</span> <span class="n">length</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">output</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">output_length</span><span class="p">)</span> <span class="p">{</span>

    <span class="kt">int</span> <span class="o">*</span><span class="n">device_input</span><span class="p">;</span>
    <span class="kt">int</span> <span class="o">*</span><span class="n">device_output</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">rounded_length</span> <span class="o">=</span> <span class="n">nextPow2</span><span class="p">(</span><span class="n">length</span><span class="p">);</span>
    
    <span class="c1">// printf("input arr1\n");</span>
    <span class="c1">// print_arr(input, length);  </span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span> <span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">device_input</span><span class="p">,</span> <span class="n">rounded_length</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span> <span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">device_output</span><span class="p">,</span> <span class="n">rounded_length</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">device_input</span><span class="p">,</span> <span class="n">input</span><span class="p">,</span> <span class="n">length</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="kt">double</span> <span class="n">startTime</span> <span class="o">=</span> <span class="n">CycleTimer</span><span class="o">::</span><span class="n">currentSeconds</span><span class="p">();</span>
    
    <span class="kt">int</span> <span class="n">result</span> <span class="o">=</span> <span class="n">find_repeats</span><span class="p">(</span><span class="n">device_input</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">device_output</span><span class="p">);</span>

    <span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="kt">double</span> <span class="n">endTime</span> <span class="o">=</span> <span class="n">CycleTimer</span><span class="o">::</span><span class="n">currentSeconds</span><span class="p">();</span>

    <span class="c1">// set output count and results array</span>
    <span class="o">*</span><span class="n">output_length</span> <span class="o">=</span> <span class="n">result</span><span class="p">;</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">device_output</span><span class="p">,</span> <span class="n">length</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>

    <span class="c1">// printf("output length:%d\n", *output_length);</span>
    <span class="c1">// printf("output indices\n");</span>
    <span class="c1">// print_arr(output, length);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">device_input</span><span class="p">);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">device_output</span><span class="p">);</span>

    <span class="kt">float</span> <span class="n">duration</span> <span class="o">=</span> <span class="n">endTime</span> <span class="o">-</span> <span class="n">startTime</span><span class="p">;</span> 
    <span class="k">return</span> <span class="n">duration</span><span class="p">;</span>
<span class="p">}</span>

</code></pre></div></div> <p>Output:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ yhrun -p gpu_v100 ./cudaScan -m find_repeats -n 8  -i ones
---------------------------------------------------------
Found 4 CUDA devices
Device 0: Tesla V100-SXM2-16GB
   SMs:        80
   Global mem: 16160 MB
   CUDA Cap:   7.0
Device 1: Tesla V100-SXM2-16GB
   SMs:        80
   Global mem: 16160 MB
   CUDA Cap:   7.0
Device 2: Tesla V100-SXM2-16GB
   SMs:        80
   Global mem: 16160 MB
   CUDA Cap:   7.0
Device 3: Tesla V100-SXM2-16GB
   SMs:        80
   Global mem: 16160 MB
   CUDA Cap:   7.0
---------------------------------------------------------
Array size: 8
flags arr
0:1 1:1 2:1 3:1 4:1 5:1 6:1 7:0
output length:7
output indices
0:0 1:1 2:2 3:3 4:4 5:5 6:6 7:0
flags arr
0:1 1:1 2:1 3:1 4:1 5:1 6:1 7:0
output length:7
output indices
0:0 1:1 2:2 3:3 4:4 5:5 6:6 7:0
flags arr
0:1 1:1 2:1 3:1 4:1 5:1 6:1 7:0
output length:7
output indices
0:0 1:1 2:2 3:3 4:4 5:5 6:6 7:0
Student GPU time: 0.199 ms
Find_repeats outputs are correct!
</code></pre></div></div> <h2 id="part-3-renderer">Part 3: renderer</h2> <p>Install opengl library before compile the project</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda install -c anaconda pyopengl
conda install -c anaconda freeglut
</code></pre></div></div> <p>Install opengl library using conda and then compile c code that use opengl library with Makefile</p> <p>The thing to note about is that we need to include conda library path in CFLAGS and LDFLAGS</p> <h3 id="step-by-step-guide">Step-by-Step Guide</h3> <ol> <li><strong>Install OpenGL using conda</strong>: <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda create <span class="nt">--name</span> opengl_env
conda activate opengl_env
conda <span class="nb">install</span> <span class="nt">-c</span> anaconda pyopengl
conda <span class="nb">install</span> <span class="nt">-c</span> anaconda freeglut
</code></pre></div> </div> </li> <li><strong>Write Your C Code</strong>: <ul> <li>Create a file named <code class="language-plaintext highlighter-rouge">main.c</code> with the following content: <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;GL/glut.h&gt;</span><span class="cp">
</span>
<span class="kt">void</span> <span class="nf">display</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">glClear</span><span class="p">(</span><span class="n">GL_COLOR_BUFFER_BIT</span><span class="p">);</span>
    <span class="n">glBegin</span><span class="p">(</span><span class="n">GL_TRIANGLES</span><span class="p">);</span>
    <span class="n">glVertex2f</span><span class="p">(</span><span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">);</span>
    <span class="n">glVertex2f</span><span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">);</span>
    <span class="n">glVertex2f</span><span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">);</span>
    <span class="n">glEnd</span><span class="p">();</span>
    <span class="n">glFlush</span><span class="p">();</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span><span class="o">**</span> <span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">glutInit</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="n">argv</span><span class="p">);</span>
    <span class="n">glutCreateWindow</span><span class="p">(</span><span class="s">"OpenGL Setup Test"</span><span class="p">);</span>
    <span class="n">glutDisplayFunc</span><span class="p">(</span><span class="n">display</span><span class="p">);</span>
    <span class="n">glutMainLoop</span><span class="p">();</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div> </div> </li> </ul> </li> <li><strong>Create a Makefile</strong>: <ul> <li>Create a file named <code class="language-plaintext highlighter-rouge">Makefile</code> with the following content: <div class="language-makefile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">CC</span> <span class="o">=</span> gcc
<span class="nv">CFLAGS</span> <span class="o">=</span> <span class="nt">-I</span><span class="p">$(</span>CONDA_PREFIX<span class="p">)</span>/include
<span class="nv">LDFLAGS</span> <span class="o">=</span> <span class="nt">-L</span><span class="p">$(</span>CONDA_PREFIX<span class="p">)</span>/lib <span class="nt">-lGL</span> <span class="nt">-lGLU</span> <span class="nt">-lglut</span>

<span class="nl">all</span><span class="o">:</span> <span class="nf">main</span>

<span class="nl">main</span><span class="o">:</span> <span class="nf">main.o</span>
    <span class="err">$(CC)</span> <span class="err">-o</span> <span class="err">main</span> <span class="err">main.o</span> <span class="err">$(LDFLAGS)</span>

<span class="nl">main.o</span><span class="o">:</span> <span class="nf">main.c</span>
    <span class="err">$(CC)</span> <span class="err">-c</span> <span class="err">main.c</span> <span class="err">$(CFLAGS)</span>

<span class="nl">clean</span><span class="o">:</span>
    <span class="err">rm</span> <span class="err">-f</span> <span class="err">main</span> <span class="err">main.o</span>
</code></pre></div> </div> </li> </ul> </li> <li><strong>Compile and Run Your Code</strong>: <ul> <li>Run the following commands in your terminal: <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>make
./main
</code></pre></div> </div> </li> </ul> </li> </ol> <h3 id="explanation">Explanation</h3> <ul> <li><strong>CC</strong>: Specifies the compiler to use (gcc in this case).</li> <li><strong>CFLAGS</strong>: Specifies the include directory for the OpenGL headers.</li> <li><strong>LDFLAGS</strong>: Specifies the library directory and the libraries to link against (<code class="language-plaintext highlighter-rouge">-lGL</code>, <code class="language-plaintext highlighter-rouge">-lGLU</code>, <code class="language-plaintext highlighter-rouge">-lglut</code>).</li> <li><strong>all</strong>: The default target that builds the <code class="language-plaintext highlighter-rouge">main</code> executable.</li> <li><strong>main</strong>: The target that links the object file to create the executable.</li> <li><strong>main.o</strong>: The target that compiles the source file into an object file.</li> <li><strong>clean</strong>: A target to clean up the compiled files.</li> </ul> <p>This Makefile ensures that the compiler and linker use the correct paths for the OpenGL headers and libraries installed via conda.</p> <p>One problem is that how to get orders of drawing a same pixel when multiple circles overlap at the same pixel.</p> <p>The hints say that I can use prefix sum to help with this assignment but I don’t know how to do that.</p> <p>I know that once we have caculation order array for each pixel then we can parallize the image drawing for eall pixels in parallel.</p> <p>Take a look at shadePixel</p> <p>Run pixel rendering in parallel instead of rendering circles in parllel. <a href="https://github.com/ClaudiaRaffaelli/CUDA-Renderer/blob/master/cudaRenderer.cu">Ref repo</a></p> <p>The naive solution is slow because for each pixel thread it has to iterate all circles to see if each circle contributes to current pixel.</p> <p>The good news is that we don’t need to worry about the order issue and the correctness is guaranteed.</p>]]></content><author><name></name></author><category term="parallel"/><category term="programming"/><category term="parallel"/><category term="programming"/><summary type="html"><![CDATA[Part1 Code: saxpy serial cpu output from assign1 prog5: (base) ➜ prog5_saxpy git:(master) ✗ ./saxpy [saxpy serial]: [20.605] ms [14.464] GB/s [1.941] GFLOPS [saxpy ispc]: [17.866] ms [16.681] GB/s [2.239] GFLOPS [saxpy task ispc]: [3.122] ms [95.446] GB/s [12.810] GFLOPS (5.72x speedup from use of tasks)]]></summary></entry><entry><title type="html">Stf CS149 Parallel Programming - Lecture11 - Cache coherence</title><link href="https://bilyz98.github.io/blog/2024/cs149-lecture11-cache-coherence/" rel="alternate" type="text/html" title="Stf CS149 Parallel Programming - Lecture11 - Cache coherence"/><published>2024-11-01T11:59:00+00:00</published><updated>2024-11-01T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/cs149-lecture11-cache-coherence</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/cs149-lecture11-cache-coherence/"><![CDATA[<h2 id="lecture-11-cache-coherence">Lecture 11: Cache coherence</h2> <p>Cache takes large amount of area in the chip</p> <p>Cache bring performance boosting.</p> <p>Two locality of data access pattern so that cache can help with performance.</p> <ol> <li>Spatial locality</li> <li>Temporal locality</li> </ol> <p>Cache and cacheline in cpu. Usually a single cacheline contains multiple cache bytes(64bytes which can store 8 int for example ).</p> <p>What is the problem with a shared cache processor design?</p> <p>The scalability is the problem.</p> <p>The cache bus has bandwidth limit..</p> <p>A shared cache avoid the cache coherence problem but each write to a memory address will be broadcasted to other cores which waste bandwidth of bus.</p> <p>Shared cache contention example:</p> <p>Imagine you have a multi-core processor where two cores, Core 0 and Core 1, share the same Last Level Cache (LLC). If both cores are running different applications that frequently access and modify data stored in the shared cache, they will compete for the cache’s resources. This competition can lead to contention.</p> <p>For instance, consider two applications, App A and App B, running on Core 0 and Core 1, respectively. Both applications need to access large datasets that do not fit entirely in the cache. As App A accesses its data, it loads cache lines into the LLC, potentially evicting cache lines that App B needs. When App B tries to access its data, it may find that the required cache lines have been evicted by App A, causing cache misses and forcing App B to fetch the data from the slower main memory¹.</p> <p>This back-and-forth eviction and reloading of cache lines between the two applications degrade their performance compared to a scenario where each application has its own private cache¹.</p> <p>(2) 250P: Computer Systems Architecture Lecture 10: Caches - University of Utah. https://users.cs.utah.edu/~aburtsev/250P/2019fall/lectures/lecture10-caches/lecture10-caches.pdf.</p> <h3 id="constructive-and-destructive-interference">constructive and destructive interference</h3> <p>In the context of CPU caches, <strong>constructive interference</strong> and <strong>destructive interference</strong> refer to the effects of multiple processors accessing shared cache lines.</p> <h3 id="constructive-interference">Constructive Interference</h3> <p>Constructive interference occurs when multiple processors access the same data in a shared cache, leading to improved performance. For example, if one processor loads data into the shared cache that another processor also needs, the second processor can access this data quickly without having to fetch it from the slower main memory. This reduces cache misses and improves overall efficiency².</p> <h3 id="destructive-interference">Destructive Interference</h3> <p>Destructive interference, on the other hand, happens when multiple processors access different data that map to the same cache line, causing conflicts. This can lead to frequent cache line invalidations and reloads, increasing the number of cache misses and degrading performance. For instance, if two processors continuously overwrite each other’s data in the same cache line, they will experience higher latency due to the constant need to fetch data from the main memory².</p> <p>These concepts are crucial in designing efficient cache systems for multi-core processors, as they highlight the trade-offs between shared and private caches and the importance of cache coherence protocols.</p>]]></content><author><name></name></author><category term="parallel"/><category term="programming"/><category term="parallel"/><category term="programming"/><summary type="html"><![CDATA[Lecture 11: Cache coherence]]></summary></entry><entry><title type="html">Stf CS149 Parallel Programming - Lecture 5&amp;amp;6 - Performance optimization</title><link href="https://bilyz98.github.io/blog/2024/stf-cs149-lecture-takeaway/" rel="alternate" type="text/html" title="Stf CS149 Parallel Programming - Lecture 5&amp;amp;6 - Performance optimization"/><published>2024-10-26T11:59:00+00:00</published><updated>2024-10-26T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/stf-cs149-lecture-takeaway</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/stf-cs149-lecture-takeaway/"><![CDATA[<h2 id="lecture-5">Lecture 5</h2> <p><a href="https://youtu.be/mmO2Ri_dJkk?si=CCG3Tf9dDYZiExq6">Video</a> Deciding granularity is important for dynamic scheduling in parallel programming.</p> <p>Small granularity leads to better workload distribution but comes with higher synchronization overhead.</p> <h2 id="lecture-6">Lecture 6</h2> <p>Performance optimization: locality, communication and contention.</p> <p>Reduce costs of communication between:</p> <ol> <li>processors.</li> <li>between processors and memory.</li> </ol> <p>Shared memory communication. Numa: non-uniform memory access</p> <p>Message passing blocking send and non-blocking send</p> <p>Reduce communication is important to achieve max utilization of cpu. Just to keep cpu busy</p> <p>Roofline model: <img src="https://github.com/user-attachments/assets/da01cc6b-a009-4b49-a306-c72940b89eaf" alt="image"/></p> <p>To achieve maximum computation throughput GFLOPS/s of cpu or gpus one has to have algorithm that has high operation intensity -&gt; high flops/bytes.</p> <p>Need to has many computation per byte access unit.</p>]]></content><author><name></name></author><category term="parallel"/><category term="programming"/><category term="parallel"/><category term="programming"/><summary type="html"><![CDATA[Lecture 5 Video Deciding granularity is important for dynamic scheduling in parallel programming.]]></summary></entry><entry><title type="html">Stf CS149 Parallel Programming - Assign2</title><link href="https://bilyz98.github.io/blog/2024/cs149-assign2/" rel="alternate" type="text/html" title="Stf CS149 Parallel Programming - Assign2"/><published>2024-10-26T11:59:00+00:00</published><updated>2024-10-26T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/cs149-assign2</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/cs149-assign2/"><![CDATA[<h1 id="thread-pool-for-task-scheduling">Thread pool for task scheduling</h1> <h2 id="step1--parallel-thread-spawn">Step1 : parallel thread spawn</h2> <p>First implementaion that spawns new thread for each task:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="n">TaskSystemParallelSpawn</span><span class="o">::</span><span class="n">run</span><span class="p">(</span><span class="n">IRunnable</span><span class="o">*</span> <span class="n">runnable</span><span class="p">,</span> <span class="kt">int</span> <span class="n">num_total_tasks</span><span class="p">)</span> <span class="p">{</span>


    <span class="c1">//</span>
    <span class="c1">// TODO: CS149 students will modify the implementation of this</span>
    <span class="c1">// method in Part A.  The implementation provided below runs all</span>
    <span class="c1">// tasks sequentially on the calling thread.</span>
    <span class="c1">//</span>

    <span class="c1">// for (int i = 0; i &lt; num_total_tasks; i++) {</span>
    <span class="c1">//     runnable-&gt;runTask(i, num_total_tasks);</span>
    <span class="c1">// }</span>

  <span class="n">std</span><span class="o">::</span><span class="kr">thread</span> <span class="n">workers</span><span class="p">[</span><span class="n">num_threads_</span><span class="p">];</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span> <span class="n">num_total_tasks</span><span class="p">;</span> <span class="n">i</span><span class="o">+=</span> <span class="n">num_threads_</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">cur_end</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="n">num_threads_</span> <span class="o">&lt;</span> <span class="n">num_total_tasks</span><span class="p">)</span> <span class="o">?</span> <span class="n">i</span><span class="o">+</span><span class="n">num_threads_</span> <span class="o">:</span> <span class="n">num_total_tasks</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">cur_begin</span> <span class="o">=</span> <span class="n">i</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">t_idx</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">j</span><span class="o">=</span><span class="n">cur_begin</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">cur_end</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">,</span> <span class="n">t_idx</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
       <span class="n">workers</span><span class="p">[</span><span class="n">t_idx</span><span class="p">]</span><span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="kr">thread</span><span class="p">(</span><span class="n">runTask</span><span class="p">,</span> <span class="n">runnable</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">num_total_tasks</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="n">t_idx</span> <span class="o">=</span><span class="mi">0</span><span class="p">;</span>
    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">j</span><span class="o">=</span><span class="n">cur_begin</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">cur_end</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">,</span> <span class="n">t_idx</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">workers</span><span class="p">[</span><span class="n">t_idx</span><span class="p">].</span><span class="n">join</span><span class="p">();</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>Result: Not good. Very slow. I think this is because of frequent thread spawn overhead.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) ➜  part_a git:(master) ✗ python3 ../tests/run_test_harness.py -n 8 -t  super_light super_super_light
runtasks_ref
Linux x86_64
================================================================================
Running task system grading harness... (2 total tests)
  - Detected CPU with 40 execution contexts
  - Task system configured to use at most 8 threads
================================================================================
================================================================================
Executing test: super_super_light...
Reference binary: ./runtasks_ref_linux
Results for: super_super_light
                                        STUDENT   REFERENCE   PERF?
[Serial]                                12.239    12.216      1.00  (OK)
[Parallel + Always Spawn]               444.19    53.469      8.31  (NOT OK)
[Parallel + Thread Pool + Spin]         12.121    25.723      0.47  (OK)
[Parallel + Thread Pool + Sleep]        12.106    24.976      0.48  (OK)
================================================================================
</code></pre></div></div> <p>Solution 2 : Created <code class="language-plaintext highlighter-rouge">num_threads</code> at the beginning of <code class="language-plaintext highlighter-rouge">run</code> call and reuse all of them. Use atomic counter to asggub unique id to each runnalbe call.</p> <p>Code :</p> <p>Notice that that we have to set <code class="language-plaintext highlighter-rouge">my_counter_=0</code> at the beginning of each run call.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="n">TaskSystemParallelSpawn</span><span class="o">::</span><span class="n">run</span><span class="p">(</span><span class="n">IRunnable</span><span class="o">*</span> <span class="n">runnable</span><span class="p">,</span> <span class="kt">int</span> <span class="n">num_total_tasks</span><span class="p">)</span> <span class="p">{</span> 
  <span class="n">my_counter_</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="kr">thread</span><span class="o">&gt;</span> <span class="n">workers</span><span class="p">;</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span> <span class="n">num_threads_</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">workers</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">([</span><span class="k">this</span><span class="p">,</span> <span class="n">runnable</span><span class="p">,</span> <span class="n">num_total_tasks</span><span class="p">]</span> <span class="p">{</span>
      <span class="k">this</span><span class="o">-&gt;</span><span class="n">threadTask</span><span class="p">(</span><span class="n">runnable</span><span class="p">,</span> <span class="n">num_total_tasks</span><span class="p">);</span>
    <span class="p">});</span>

  <span class="p">}</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_threads_</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">workers</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">join</span><span class="p">();</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>===================================================================================
(base) ➜  part_a git:(master) ✗ python3 ../tests/run_test_harness.py -n 8 -t  super_light super_super_light
runtasks_ref
Linux x86_64
================================================================================
Running task system grading harness... (2 total tests)
  - Detected CPU with 40 execution contexts
  - Task system configured to use at most 8 threads
================================================================================
================================================================================
Executing test: super_super_light...
Reference binary: ./runtasks_ref_linux
Results for: super_super_light
                                        STUDENT   REFERENCE   PERF?
[Serial]                                8.562     12.451      0.69  (OK)
[Parallel + Always Spawn]               56.804    54.287      1.05  (OK)
[Parallel + Thread Pool + Spin]         8.532     25.417      0.34  (OK)
[Parallel + Thread Pool + Sleep]        8.456     24.996      0.34  (OK)
================================================================================
Executing test: super_light...
Reference binary: ./runtasks_ref_linux
Results for: super_light
                                        STUDENT   REFERENCE   PERF?
[Serial]                                81.044    95.194      0.85  (OK)
[Parallel + Always Spawn]               55.138    83.604      0.66  (OK)
[Parallel + Thread Pool + Spin]         80.753    27.388      2.95  (NOT OK)
[Parallel + Thread Pool + Sleep]        80.646    33.46       2.41  (NOT OK)
================================================================================
Overall performance results
[Serial]                                : All passed Perf
[Parallel + Always Spawn]               : All passed Perf
[Parallel + Thread Pool + Spin]         : Perf did not pass all tests
[Parallel + Thread Pool + Sleep]        : Perf did not pass all tests
</code></pre></div></div> <h2 id="step2--threadpool--spinning-waiting">Step2 : threadpool + spinning waiting</h2> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>void TaskSystemParallelThreadPoolSpinning::threadTask() {
      // bool done = done_.load();
  while(!done_.load()) {
    // printf("id: %d\n", id);
    mutex_.lock();
    threadArg arg;
    if(!task_queue_.empty()) {
      arg = task_queue_.front();
      task_queue_.pop_front();
    }
    mutex_.unlock();
    if(arg.runnable) {
      arg.runnable-&gt;runTask( arg.task_id, arg.num_total_tasks);
      finished_tasks_.fetch_add(1);
    }
  }

}
TaskSystemParallelThreadPoolSpinning::TaskSystemParallelThreadPoolSpinning(int num_threads): ITaskSystem(num_threads) {
    //
    // TODO: CS149 student implementations may decide to perform setup
    // operations (such as thread pool construction) here.
    // Implementations are free to add new class member variables
    // (requiring changes to tasksys.h).
    //
  done_ = false;
  num_threads_ = num_threads;
  for(int i=0; i &lt; num_threads_; i++) {
    workers_.emplace_back([this ]{
      this-&gt;threadTask();
    });
  }

}

TaskSystemParallelThreadPoolSpinning::~TaskSystemParallelThreadPoolSpinning() {
  done_.store(true);
  for(int i=0; i&lt; num_threads_; i++) {
    workers_[i].join();
  }
}

void TaskSystemParallelThreadPoolSpinning::run(IRunnable* runnable, int num_total_tasks) {


    //
    // TODO: CS149 students will modify the implementation of this
    // method in Part A.  The implementation provided below runs all
    // tasks sequentially on the calling thread.
    //

  finished_tasks_ = 0;
  {
  const std::lock_guard&lt;std::mutex&gt; lock(mutex_);
  for(int i=0; i &lt; num_total_tasks; i++) {
      threadArg arg(i, num_total_tasks, runnable);
    task_queue_.emplace_back(arg);
  }
  }
  
  while(finished_tasks_.load() != num_total_tasks) {

  }

}
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) ➜  part_a git:(master) ✗ python3 ../tests/run_test_harness.py -n 8
runtasks_ref
Linux x86_64
================================================================================                              Running task system grading harness... (11 total tests)
- Detected CPU with 40 execution contexts
  - Task system configured to use at most 8 threads
================================================================================
================================================================================                                                                             Executing test: super_super_light...
Reference binary: ./runtasks_ref_linux
Results for: super_super_light
                                        STUDENT   REFERENCE   PERF?
[Serial]                                8.574     12.343      0.69  (OK)
[Parallel + Always Spawn]               56.938    54.949      1.04  (OK)
[Parallel + Thread Pool + Spin]         21.404    25.716      0.83  (OK)
[Parallel + Thread Pool + Sleep]        8.704     17.781      0.49  (OK)
================================================================================
Executing test: super_light...
Reference binary: ./runtasks_ref_linux
Results for: super_light
                                        STUDENT   REFERENCE   PERF?
[Serial]                                80.252    94.107      0.85  (OK)
[Parallel + Always Spawn]               73.338    83.35       0.88  (OK)
[Parallel + Thread Pool + Spin]         27.698    36.119      0.77  (OK)
[Parallel + Thread Pool + Sleep]        80.795    34.28       2.36  (NOT OK)
================================================================================
Executing test: ping_pong_equal...
Reference binary: ./runtasks_ref_linux
Results for: ping_pong_equal
                                        STUDENT   REFERENCE   PERF?
[Serial]                                1297.763  1553.482    0.84  (OK)
[Parallel + Always Spawn]               574.729   649.785     0.88  (OK)
[Parallel + Thread Pool + Spin]         187.65    232.88      0.81  (OK)
[Parallel + Thread Pool + Sleep]        1294.887  226.363     5.72  (NOT OK)
================================================================================
Executing test: ping_pong_unequal...
Reference binary: ./runtasks_ref_linux
Results for: ping_pong_unequal
                                        STUDENT   REFERENCE   PERF?
[Serial]                                2405.604  2401.768    1.00  (OK)
[Parallel + Always Spawn]               969.55    1021.323    0.95  (OK)
[Parallel + Thread Pool + Spin]         336.518   332.326     1.01  (OK)
[Parallel + Thread Pool + Sleep]        2396.002  338.008     7.09  (NOT OK)
================================================================================
Executing test: recursive_fibonacci...
Reference binary: ./runtasks_ref_linux
Results for: recursive_fibonacci
                                        STUDENT   REFERENCE   PERF?
[Serial]                                1578.621  1938.967    0.81  (OK)
[Parallel + Always Spawn]               482.274   548.912     0.88  (OK)
[Parallel + Thread Pool + Spin]         222.252   266.043     0.84  (OK)
[Parallel + Thread Pool + Sleep]        1583.164  266.454     5.94  (NOT OK)
================================================================================
Executing test: math_operations_in_tight_for_loop...
Reference binary: ./runtasks_ref_linux
Results for: math_operations_in_tight_for_loop
                                        STUDENT   REFERENCE   PERF?
[Serial]                                808.052   833.969     0.97  (OK)
[Parallel + Always Spawn]               651.691   705.552     0.92  (OK)
[Parallel + Thread Pool + Spin]         139.645   154.966     0.90  (OK)
[Parallel + Thread Pool + Sleep]        802.654   157.355     5.10  (NOT OK)
================================================================================
================================================================================
Executing test: math_operations_in_tight_for_loop_fewer_tasks...
Reference binary: ./runtasks_ref_linux
Results for: math_operations_in_tight_for_loop_fewer_tasks
                                        STUDENT   REFERENCE   PERF?
[Serial]                                806.914   839.226     0.96  (OK)
[Parallel + Always Spawn]               809.429   810.212     1.00  (OK)
[Parallel + Thread Pool + Spin]         215.631   238.903     0.90  (OK)
[Parallel + Thread Pool + Sleep]        805.115   244.607     3.29  (NOT OK)
================================================================================
Executing test: math_operations_in_tight_for_loop_fan_in...
Reference binary: ./runtasks_ref_linux
Results for: math_operations_in_tight_for_loop_fan_in
                                        STUDENT   REFERENCE   PERF?
[Serial]                                416.313   428.492     0.97  (OK)
[Parallel + Always Spawn]               133.057   160.116     0.83  (OK)
[Parallel + Thread Pool + Spin]         71.286    74.03       0.96  (OK)
[Parallel + Thread Pool + Sleep]        412.149   81.239      5.07  (NOT OK)
================================================================================
Executing test: math_operations_in_tight_for_loop_reduction_tree...
Reference binary: ./runtasks_ref_linux
Results for: math_operations_in_tight_for_loop_reduction_tree
                                        STUDENT   REFERENCE   PERF?
[Serial]                                415.842   428.485     0.97  (OK)
[Parallel + Always Spawn]               142.34    191.563     0.74  (OK)
[Parallel + Thread Pool + Spin]         70.203    65.066      1.08  (OK)
[Parallel + Thread Pool + Sleep]        411.849   67.231      6.13  (NOT OK)
================================================================================
Executing test: spin_between_run_calls...
Reference binary: ./runtasks_ref_linux
Results for: spin_between_run_calls
                                        STUDENT   REFERENCE   PERF?
[Serial]                                540.34    687.538     0.79  (OK)
[Parallel + Always Spawn]               290.111   364.247     0.80  (OK)
[Parallel + Thread Pool + Spin]         295.734   373.543     0.79  (OK)
[Parallel + Thread Pool + Sleep]        538.037   364.643     1.48  (NOT OK)
================================================================================
Executing test: mandelbrot_chunked...
Reference binary: ./runtasks_ref_linux
Results for: mandelbrot_chunked
                                        STUDENT   REFERENCE   PERF?
[Serial]                                526.695   537.581     0.98  (OK)
[Parallel + Always Spawn]               79.414    78.909      1.01  (OK)
[Parallel + Thread Pool + Spin]         83.16     77.74       1.07  (OK)
[Parallel + Thread Pool + Sleep]        530.464   85.143      6.23  (NOT OK)
================================================================================
Overall performance results
[Serial]                                : All passed Perf
[Parallel + Always Spawn]               : All passed Perf
[Parallel + Thread Pool + Spin]         : All passed Perf
[Parallel + Thread Pool + Sleep]        : Perf did not pass all tests
</code></pre></div></div> <h2 id="step3-threadpool--put-threads-to-sleep-when-there-is-nothing-to-do">Step3: Threadpool + put threads to sleep when there is nothing to do</h2> <p>Implementation :</p> <p>Notice that we have to test if each thread is joinable and call <code class="language-plaintext highlighter-rouge">join()</code> at the destructor of the class.</p> <p>Because each thread might have already exited when <code class="language-plaintext highlighter-rouge">done_</code> is set to <code class="language-plaintext highlighter-rouge">true</code></p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="n">TaskSystemParallelThreadPoolSleeping</span><span class="o">::</span><span class="n">threadTask</span><span class="p">(</span> <span class="p">)</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">num_task</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="k">while</span><span class="p">(</span><span class="o">!</span><span class="n">done_</span><span class="p">.</span><span class="n">load</span><span class="p">())</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">unique_lock</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">mutex</span><span class="o">&gt;</span> <span class="n">lock</span><span class="p">(</span><span class="n">mutex_</span><span class="p">);</span>
    <span class="n">threadArg</span> <span class="n">arg</span> <span class="p">;</span> 
    <span class="kt">bool</span> <span class="n">get_task</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
    <span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="n">task_queue_</span><span class="p">.</span><span class="n">empty</span><span class="p">())</span> <span class="p">{</span>
      <span class="n">arg</span> <span class="o">=</span> <span class="n">task_queue_</span><span class="p">.</span><span class="n">front</span><span class="p">();</span>
      <span class="n">task_queue_</span><span class="p">.</span><span class="n">pop_front</span><span class="p">();</span>
      <span class="n">get_task</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>
      <span class="c1">// printf("get task\n");</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="n">cv_</span><span class="p">.</span><span class="n">wait</span><span class="p">(</span><span class="n">lock</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="n">lock</span><span class="p">.</span><span class="n">unlock</span><span class="p">();</span>
    <span class="k">if</span><span class="p">(</span><span class="n">get_task</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">arg</span><span class="p">.</span><span class="n">runnable</span><span class="o">-&gt;</span><span class="n">runTask</span><span class="p">(</span><span class="n">arg</span><span class="p">.</span><span class="n">task_id</span><span class="p">,</span> <span class="n">arg</span><span class="p">.</span><span class="n">num_total_tasks</span><span class="p">);</span>
      <span class="n">num_task</span> <span class="o">=</span> <span class="n">arg</span><span class="p">.</span><span class="n">num_total_tasks</span><span class="p">;</span>
      <span class="n">finished_tasks_</span><span class="p">.</span><span class="n">fetch_add</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
      <span class="k">if</span><span class="p">(</span><span class="n">finished_tasks_</span><span class="p">.</span><span class="n">load</span><span class="p">()</span> <span class="o">==</span> <span class="n">num_task</span><span class="p">)</span>  <span class="p">{</span>
        <span class="c1">// printf("send notify\n");</span>
        <span class="n">cv_</span><span class="p">.</span><span class="n">notify_all</span><span class="p">();</span>
      <span class="p">}</span>
    <span class="p">}</span>
 
  <span class="p">}</span>
<span class="p">}</span>
<span class="n">TaskSystemParallelThreadPoolSleeping</span><span class="o">::</span><span class="n">TaskSystemParallelThreadPoolSleeping</span><span class="p">(</span><span class="kt">int</span> <span class="n">num_threads</span><span class="p">)</span><span class="o">:</span> <span class="n">ITaskSystem</span><span class="p">(</span><span class="n">num_threads</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">//</span>
    <span class="c1">// TODO: CS149 student implementations may decide to perform setup</span>
    <span class="c1">// operations (such as thread pool construction) here.</span>
    <span class="c1">// Implementations are free to add new class member variables</span>
    <span class="c1">// (requiring changes to tasksys.h).</span>
    <span class="c1">//</span>
  <span class="n">num_threads_</span> <span class="o">=</span> <span class="n">num_threads</span><span class="p">;</span>
  <span class="n">done_</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span> <span class="n">num_threads_</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">){</span>
    <span class="n">workers_</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">([</span><span class="k">this</span><span class="p">]{</span>
      <span class="k">this</span><span class="o">-&gt;</span><span class="n">threadTask</span><span class="p">();</span>
    <span class="p">});</span>
  <span class="p">}</span>

<span class="p">}</span>

<span class="n">TaskSystemParallelThreadPoolSleeping</span><span class="o">::~</span><span class="n">TaskSystemParallelThreadPoolSleeping</span><span class="p">()</span> <span class="p">{</span>
    <span class="c1">//</span>
    <span class="c1">// TODO: CS149 student implementations may decide to perform cleanup</span>
    <span class="c1">// operations (such as thread pool shutdown construction) here.</span>
    <span class="c1">// Implementations are free to add new class member variables</span>
    <span class="c1">// (requiring changes to tasksys.h).</span>
    <span class="c1">//</span>
  <span class="n">done_</span><span class="p">.</span><span class="n">store</span><span class="p">(</span><span class="nb">true</span><span class="p">);</span>
  <span class="n">cv_</span><span class="p">.</span><span class="n">notify_all</span><span class="p">();</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_threads_</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span><span class="p">(</span><span class="n">workers_</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">joinable</span><span class="p">())</span> <span class="p">{</span>
      <span class="n">workers_</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">join</span><span class="p">();</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="n">TaskSystemParallelThreadPoolSleeping</span><span class="o">::</span><span class="n">run</span><span class="p">(</span><span class="n">IRunnable</span><span class="o">*</span> <span class="n">runnable</span><span class="p">,</span> <span class="kt">int</span> <span class="n">num_total_tasks</span><span class="p">)</span> <span class="p">{</span>


    <span class="c1">//</span>
    <span class="c1">// TODO: CS149 students will modify the implementation of this</span>
    <span class="c1">// method in Parts A and B.  The implementation provided below runs all</span>
    <span class="c1">// tasks sequentially on the calling thread.</span>
    <span class="c1">//</span>

  <span class="n">std</span><span class="o">::</span><span class="n">unique_lock</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">mutex</span><span class="o">&gt;</span> <span class="n">lock</span><span class="p">(</span><span class="n">mutex_</span><span class="p">);</span>
  <span class="n">finished_tasks_</span><span class="p">.</span><span class="n">store</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="p">;</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_total_tasks</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">threadArg</span> <span class="n">arg</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">num_total_tasks</span><span class="p">,</span> <span class="n">runnable</span><span class="p">);</span>
    <span class="n">task_queue_</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">arg</span><span class="p">);</span>
  <span class="p">}</span>
  <span class="c1">// printf("before notify all\n");</span>
  <span class="n">lock</span><span class="p">.</span><span class="n">unlock</span><span class="p">();</span>
  <span class="n">cv_</span><span class="p">.</span><span class="n">notify_all</span><span class="p">();</span>
  <span class="n">lock</span><span class="p">.</span><span class="n">lock</span><span class="p">();</span>

  
  <span class="k">while</span><span class="p">(</span><span class="n">finished_tasks_</span><span class="p">.</span><span class="n">load</span><span class="p">()</span> <span class="o">!=</span> <span class="n">num_total_tasks</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">cv_</span><span class="p">.</span><span class="n">wait</span><span class="p">(</span><span class="n">lock</span><span class="p">);</span>
  <span class="p">}</span>

  <span class="c1">// printf("finished_tasks_:%d\n", finished_tasks_.load());</span>

<span class="p">}</span>
</code></pre></div></div> <h2 id="part-b-threadpoll--async-call-w">Part B: threadpoll + async call w</h2> <p>This line of code is important.</p> <p>We have two conditions to check for <code class="language-plaintext highlighter-rouge">cv_.wait()</code>. <code class="language-plaintext highlighter-rouge">cv_.wait()</code> will check the condition each time it wakes up and it would stop waiting when the condition is true.</p> <p>This can help save time for further unncessary condition checking in the while loop.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>      cv_.wait(lock, [this]{return !ready_queue_.empty() || done_ ;});
</code></pre></div></div> <p>Another change I make compared to previous version of code is that I use <code class="language-plaintext highlighter-rouge">bool</code> intead of <code class="language-plaintext highlighter-rouge">std::atomic&lt;bool&gt;</code> to store <code class="language-plaintext highlighter-rouge">done_</code> variable which indicates whether the class is destructed.</p> <p><code class="language-plaintext highlighter-rouge">done_</code> variable is set to true without lock protection in destructor if its type is <code class="language-plaintext highlighter-rouge">std::atomic&lt;bool&gt;</code> which means that thread might miss the <code class="language-plaintext highlighter-rouge">notify_all()</code> call from destructor and those worker threads would never be woke up and exit .</p> <p>After change <code class="language-plaintext highlighter-rouge">done_</code> to type <code class="language-plaintext highlighter-rouge">bool</code>, we are guaranteed that all threads would receive the <code class="language-plaintext highlighter-rouge">notify_all()</code> call because the destructor holds the lock first and then set <code class="language-plaintext highlighter-rouge">done_</code> to <code class="language-plaintext highlighter-rouge">true</code> and then notify_all();</p> <p>The guarantees the order of instructions.</p> <p>Issue: Test can not pass with 4 threads.</p> <p>Investigation is ongoing.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">TaskSystemParallelThreadPoolSleeping</span><span class="o">::~</span><span class="n">TaskSystemParallelThreadPoolSleeping</span><span class="p">()</span> <span class="p">{</span>
    <span class="c1">//</span>
    <span class="c1">// TODO: CS149 student implementations may decide to perform cleanup</span>
    <span class="c1">// operations (such as thread pool shutdown construction) here.</span>
    <span class="c1">// Implementations are free to add new class member variables</span>
    <span class="c1">// (requiring changes to tasksys.h).</span>
    <span class="c1">//</span>
  <span class="n">std</span><span class="o">::</span><span class="n">unique_lock</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">mutex</span><span class="o">&gt;</span> <span class="n">lock</span><span class="p">(</span><span class="n">mutex_</span><span class="p">);</span>
  <span class="n">done_</span><span class="o">=</span><span class="nb">true</span><span class="p">;</span>
  <span class="n">lock</span><span class="p">.</span><span class="n">unlock</span><span class="p">();</span>
  <span class="n">cv_</span><span class="p">.</span><span class="n">notify_all</span><span class="p">();</span>
  <span class="n">printf</span><span class="p">(</span><span class="s">"destructor</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">workers_</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// cv_.notify_all();</span>
    <span class="k">if</span><span class="p">(</span><span class="n">workers_</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">joinable</span><span class="p">())</span> <span class="p">{</span>
      <span class="n">workers_</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">join</span><span class="p">();</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="n">printf</span><span class="p">(</span><span class="s">"exit</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div> <p>Worker code:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">TaskID</span> <span class="n">TaskSystemParallelThreadPoolSleeping</span><span class="o">::</span><span class="n">runAsyncWithDeps</span><span class="p">(</span><span class="n">IRunnable</span><span class="o">*</span> <span class="n">runnable</span><span class="p">,</span> <span class="kt">int</span> <span class="n">num_total_tasks</span><span class="p">,</span>
                                                    <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">TaskID</span><span class="o">&gt;&amp;</span> <span class="n">deps</span><span class="p">)</span> <span class="p">{</span>

    <span class="c1">//</span>
    <span class="c1">// TODO: CS149 students will implement this method in Part B.</span>
    <span class="c1">//</span>

  <span class="n">TaskID</span> <span class="n">new_task</span> <span class="o">=</span> <span class="n">task_dep_</span><span class="p">.</span><span class="n">GetNewTaskID</span><span class="p">();</span>
  <span class="n">mutex_</span><span class="p">.</span><span class="n">lock</span><span class="p">();</span>
   <span class="n">taskid_remain_work_count_map_</span><span class="p">[</span><span class="n">new_task</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_total_tasks</span><span class="p">;</span>
   <span class="k">for</span><span class="p">(</span><span class="n">TaskID</span> <span class="n">parent_task_id</span><span class="o">:</span> <span class="n">deps</span><span class="p">)</span> <span class="p">{</span>
     <span class="n">dependent_children_</span><span class="p">[</span><span class="n">parent_task_id</span><span class="p">].</span><span class="n">insert</span><span class="p">(</span><span class="n">new_task</span><span class="p">);</span>
   <span class="p">}</span>
   <span class="n">TaskArg</span> <span class="nf">task_arg</span><span class="p">(</span><span class="n">new_task</span><span class="p">,</span> <span class="n">runnable</span><span class="p">,</span> <span class="n">num_total_tasks</span><span class="p">,</span>  <span class="n">deps</span><span class="p">.</span><span class="n">size</span><span class="p">());</span>
  <span class="n">printf</span><span class="p">(</span><span class="s">"task: %d dep count: %ld</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">new_task</span><span class="p">,</span> <span class="n">deps</span><span class="p">.</span><span class="n">size</span><span class="p">());</span>
   <span class="n">task_id_remaining_dependent_parents_count_</span><span class="p">[</span><span class="n">new_task</span><span class="p">]</span> <span class="o">=</span> <span class="n">task_arg</span><span class="p">;</span>
  <span class="n">CheckAndNotify</span><span class="p">(</span><span class="n">new_task</span><span class="p">);</span>
  <span class="n">mutex_</span><span class="p">.</span><span class="n">unlock</span><span class="p">();</span>


  <span class="k">return</span> <span class="n">new_task</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="n">TaskSystemParallelThreadPoolSleeping</span><span class="o">::</span><span class="n">threadTask</span><span class="p">(</span> <span class="p">)</span> <span class="p">{</span>
  <span class="n">std</span><span class="o">::</span><span class="n">unique_lock</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">mutex</span><span class="o">&gt;</span> <span class="n">lock</span><span class="p">(</span><span class="n">mutex_</span><span class="p">);</span>
  <span class="k">while</span><span class="p">(</span><span class="o">!</span><span class="n">done_</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">threadArg</span> <span class="n">arg</span> <span class="p">;</span> 
    <span class="kt">bool</span> <span class="n">get_task</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
    <span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="n">ready_queue_</span><span class="p">.</span><span class="n">empty</span><span class="p">())</span> <span class="p">{</span>
      <span class="n">arg</span> <span class="o">=</span> <span class="n">ready_queue_</span><span class="p">.</span><span class="n">front</span><span class="p">();</span>
      <span class="n">ready_queue_</span><span class="p">.</span><span class="n">pop_front</span><span class="p">();</span>
      <span class="n">get_task</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>
      <span class="n">printf</span><span class="p">(</span><span class="s">"get task</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="n">printf</span><span class="p">(</span><span class="s">"wait task</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
      <span class="n">cv_</span><span class="p">.</span><span class="n">wait</span><span class="p">(</span><span class="n">lock</span><span class="p">);</span>
      <span class="c1">// cv_.wait(lock, [this]{return !ready_queue_.empty() || done_ ;});</span>
      <span class="k">continue</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">lock</span><span class="p">.</span><span class="n">unlock</span><span class="p">();</span>
    <span class="k">if</span><span class="p">(</span><span class="n">get_task</span><span class="p">)</span> <span class="p">{</span>
      <span class="kt">int</span> <span class="n">task_thread_id</span> <span class="o">=</span> <span class="n">arg</span><span class="p">.</span><span class="n">task_thread_id</span><span class="p">;</span>
      <span class="kt">int</span> <span class="n">task_id</span> <span class="o">=</span> <span class="n">arg</span><span class="p">.</span><span class="n">task_id</span><span class="p">;</span>
      <span class="n">arg</span><span class="p">.</span><span class="n">runnable</span><span class="o">-&gt;</span><span class="n">runTask</span><span class="p">(</span><span class="n">task_thread_id</span><span class="p">,</span> <span class="n">arg</span><span class="p">.</span><span class="n">num_total_tasks</span><span class="p">);</span>
      <span class="kt">bool</span> <span class="n">cur_task_finished</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
      <span class="p">{</span>
        <span class="n">std</span><span class="o">::</span><span class="n">unique_lock</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">mutex</span><span class="o">&gt;</span> <span class="n">inner_lock</span><span class="p">(</span><span class="n">mutex_</span><span class="p">);</span>
        <span class="kt">int</span> <span class="n">task_remain_work_count</span> <span class="o">=</span> <span class="o">--</span><span class="n">taskid_remain_work_count_map_</span><span class="p">[</span><span class="n">task_id</span><span class="p">];</span>
        <span class="k">if</span><span class="p">(</span><span class="n">task_remain_work_count</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
          <span class="n">printf</span><span class="p">(</span><span class="s">"task:%d finished</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">task_id</span><span class="p">);</span>
          <span class="n">cur_task_finished</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>
          <span class="k">const</span> <span class="k">auto</span><span class="o">&amp;</span> <span class="n">children_task_ids</span> <span class="o">=</span> <span class="n">dependent_children_</span><span class="p">[</span><span class="n">task_id</span><span class="p">];</span>
          <span class="k">for</span><span class="p">(</span><span class="n">TaskID</span> <span class="n">child_task_id</span><span class="o">:</span> <span class="n">children_task_ids</span> <span class="p">)</span> <span class="p">{</span>
            <span class="n">task_id_remaining_dependent_parents_count_</span><span class="p">[</span><span class="n">child_task_id</span><span class="p">].</span><span class="n">remain_dep_parent_task_count</span><span class="o">--</span><span class="p">;</span>
            <span class="n">CheckAndMoveTaskToReadyQueue</span><span class="p">(</span><span class="n">child_task_id</span><span class="p">);</span>
          <span class="p">}</span>

        <span class="p">}</span>
      <span class="p">}</span>
      <span class="k">if</span><span class="p">(</span><span class="n">cur_task_finished</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">finished_tasks_</span><span class="p">.</span><span class="n">fetch_add</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
        <span class="c1">// extra notify all here for sync()</span>
        <span class="n">cv_</span><span class="p">.</span><span class="n">notify_all</span><span class="p">();</span>

      <span class="p">}</span>
    <span class="p">}</span>
    <span class="n">lock</span><span class="p">.</span><span class="n">lock</span><span class="p">();</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>Add another condition to notify_all() threads.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>      if(cur_task_finished || moved_to_ready_queue) {
        finished_tasks_.fetch_add(1);
        // extra notify all here for sync()
        cv_.notify_all();

      }

</code></pre></div></div> <p>Task 1 is not moved to ready_queue</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>destructor
exit
wait task
wait task
task:0 moved to ready_queue
get task
get task
get task
wait task
task:0 finished
wait task
</code></pre></div></div> <p>Another issue: the deps parent task might have been finished when the new child task is pushed. Need to deal with this situation.</p> <p>So we should not use this structure for task schedule</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   std::unordered_map&lt;TaskID, std::unordered_set&lt;TaskID&gt;&gt; dependent_children_;
</code></pre></div></div> <p>This class structure is not right.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>class TaskSystemParallelThreadPoolSleeping: public ITaskSystem {
    public:
        TaskSystemParallelThreadPoolSleeping(int num_threads);
        ~TaskSystemParallelThreadPoolSleeping();
        const char* name();
        void run(IRunnable* runnable, int num_total_tasks);
        TaskID runAsyncWithDeps(IRunnable* runnable, int num_total_tasks,
                                const std::vector&lt;TaskID&gt;&amp; deps);
        void sync();

private:
  void threadTask( );
  bool CheckAndMoveTaskToReadyQueue(TaskID child_task_id);
  void CheckAndNotify(TaskID child_task_id);
  std::vector&lt;std::thread&gt; workers_;
  int num_threads_;
  bool done_;
  std::mutex mutex_;
  std::condition_variable cv_;
  std::atomic&lt;TaskID&gt; task_id_;
  std::unordered_map&lt;TaskID, std::unordered_set&lt;TaskID&gt;&gt; dependent_children_;
  std::unordered_map&lt;TaskID, TaskArg&gt; task_id_remaining_dependent_parents_count_;
  std::deque&lt;threadArg&gt; ready_queue_;
  std::unordered_map&lt;TaskID, int&gt; taskid_remain_work_count_map_;
  std::atomic&lt;int&gt; finished_tasks_;
 

};
</code></pre></div></div> <h3 id="correct-implementaion">Correct implementaion</h3> <p>Code :</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="n">TaskSystemParallelThreadPoolSleeping</span><span class="o">::</span><span class="n">threadTask</span><span class="p">(</span> <span class="p">)</span> <span class="p">{</span>
  <span class="n">std</span><span class="o">::</span><span class="n">unique_lock</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">mutex</span><span class="o">&gt;</span> <span class="n">lock</span><span class="p">(</span><span class="n">mutex_</span><span class="p">);</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">TaskID</span><span class="o">&gt;</span> <span class="n">tasks</span><span class="p">;</span>
  <span class="kt">bool</span> <span class="n">get_new_tasks_to_run</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
  <span class="c1">// get_new_tasks_to_run = task_dep_.CheckAndGetRunnableTasks(tasks);</span>
  <span class="c1">// for(TaskID task_id : tasks){</span>
  <span class="c1">//   ScheduleTaskToReadyQueue(task_id);</span>
  <span class="c1">// }</span>
  <span class="c1">// tasks.clear();</span>

  <span class="k">while</span><span class="p">(</span><span class="o">!</span><span class="n">done_</span> <span class="o">||</span> <span class="o">!</span><span class="n">ready_queue_</span><span class="p">.</span><span class="n">empty</span><span class="p">()</span> <span class="o">||</span> <span class="n">task_dep_</span><span class="p">.</span><span class="n">HasTaskToSchedule</span><span class="p">())</span> <span class="p">{</span>
    <span class="n">get_new_tasks_to_run</span> <span class="o">=</span> <span class="n">task_dep_</span><span class="p">.</span><span class="n">CheckAndGetRunnableTasks</span><span class="p">(</span><span class="n">tasks</span><span class="p">);</span>
    <span class="k">for</span><span class="p">(</span><span class="n">TaskID</span> <span class="n">task_id</span><span class="o">:</span> <span class="n">tasks</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">ScheduleTaskToReadyQueue</span><span class="p">(</span><span class="n">task_id</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="n">tasks</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
    <span class="n">threadArg</span> <span class="n">arg</span> <span class="p">;</span> 
    <span class="kt">bool</span> <span class="n">get_task</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
    <span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="n">ready_queue_</span><span class="p">.</span><span class="n">empty</span><span class="p">())</span> <span class="p">{</span>
      <span class="n">arg</span> <span class="o">=</span> <span class="n">ready_queue_</span><span class="p">.</span><span class="n">front</span><span class="p">();</span>
      <span class="n">ready_queue_</span><span class="p">.</span><span class="n">pop_front</span><span class="p">();</span>
      <span class="n">get_task</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>
      <span class="c1">// printf("get task\n");</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="c1">// printf("wait task\n");</span>
      <span class="n">cv_</span><span class="p">.</span><span class="n">wait</span><span class="p">(</span><span class="n">lock</span><span class="p">);</span>
      <span class="c1">// cv_.wait(lock, [this]{return !ready_queue_.empty() || done_ ;});</span>
    <span class="p">}</span>
    <span class="n">lock</span><span class="p">.</span><span class="n">unlock</span><span class="p">();</span>
    <span class="k">if</span><span class="p">(</span><span class="n">get_task</span><span class="p">)</span> <span class="p">{</span>
      <span class="kt">int</span> <span class="n">task_thread_id</span> <span class="o">=</span> <span class="n">arg</span><span class="p">.</span><span class="n">task_thread_id</span><span class="p">;</span>
      <span class="kt">int</span> <span class="n">task_id</span> <span class="o">=</span> <span class="n">arg</span><span class="p">.</span><span class="n">task_id</span><span class="p">;</span>
      <span class="n">arg</span><span class="p">.</span><span class="n">runnable</span><span class="o">-&gt;</span><span class="n">runTask</span><span class="p">(</span><span class="n">task_thread_id</span><span class="p">,</span> <span class="n">arg</span><span class="p">.</span><span class="n">num_total_tasks</span><span class="p">);</span>
      <span class="p">{</span>
        <span class="n">std</span><span class="o">::</span><span class="n">unique_lock</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">mutex</span><span class="o">&gt;</span> <span class="n">inner_lock</span><span class="p">(</span><span class="n">mutex_</span><span class="p">);</span>
        <span class="c1">// printf("taskid: %d, thread_id: %d finished\n", task_id, task_thread_id);</span>
        <span class="n">FinishOneSubTask</span><span class="p">(</span><span class="n">task_id</span><span class="p">);</span>
      <span class="p">}</span>
      <span class="c1">// Move notify_all out of mutex scope so that </span>
      <span class="c1">// other threads can wake up and do some work</span>
      <span class="c1">// if(cur_task_finished || has_moved_to_ready_queue) {</span>
      <span class="c1">//   cv_.notify_all();</span>
      <span class="c1">// }</span>
    <span class="n">cv_</span><span class="p">.</span><span class="n">notify_all</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="n">lock</span><span class="p">.</span><span class="n">lock</span><span class="p">();</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="c1">// Prerequisite: mutex_ is held</span>
<span class="kt">void</span>  <span class="n">TaskSystemParallelThreadPoolSleeping</span><span class="o">::</span><span class="n">ScheduleTaskToReadyQueue</span><span class="p">(</span><span class="n">TaskID</span> <span class="n">task_id</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">TaskArg</span> <span class="n">task_arg</span><span class="p">;</span>
  <span class="n">task_dep_</span><span class="p">.</span><span class="n">GetTaskArg</span><span class="p">(</span><span class="n">task_id</span><span class="p">,</span> <span class="n">task_arg</span><span class="p">);</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">task_arg</span><span class="p">.</span><span class="n">num_total_tasks</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">threadArg</span> <span class="n">ta</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">task_arg</span><span class="p">.</span><span class="n">num_total_tasks</span><span class="p">,</span> <span class="n">task_arg</span><span class="p">.</span><span class="n">runnable</span><span class="p">,</span> <span class="n">task_id</span><span class="p">);</span>
    <span class="n">taskid_remain_work_count_map_</span><span class="p">[</span><span class="n">task_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">task_arg</span><span class="p">.</span><span class="n">num_total_tasks</span><span class="p">;</span>
    <span class="n">ready_queue_</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">ta</span><span class="p">);</span>
  <span class="p">}</span>

<span class="p">}</span>
<span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">TaskSystemParallelThreadPoolSleeping</span><span class="o">::</span><span class="n">name</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">return</span> <span class="s">"Parallel + Thread Pool + Sleep"</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">TaskSystemParallelThreadPoolSleeping</span><span class="o">::</span><span class="n">TaskSystemParallelThreadPoolSleeping</span><span class="p">(</span><span class="kt">int</span> <span class="n">num_threads</span><span class="p">)</span><span class="o">:</span> <span class="n">ITaskSystem</span><span class="p">(</span><span class="n">num_threads</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">//</span>
    <span class="c1">// TODO: CS149 student implementations may decide to perform setup</span>
    <span class="c1">// operations (such as thread pool construction) here.</span>
    <span class="c1">// Implementations are free to add new class member variables</span>
    <span class="c1">// (requiring changes to tasksys.h).</span>
    <span class="c1">//</span>
  <span class="n">done_</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
  <span class="c1">// task_id_ = 0;</span>
  <span class="n">num_threads_</span> <span class="o">=</span> <span class="n">num_threads</span><span class="p">;</span>
  <span class="c1">// finished_tasks_ = 0;</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_threads_</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">workers_</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">([</span><span class="k">this</span><span class="p">]{</span>
      <span class="k">this</span><span class="o">-&gt;</span><span class="n">threadTask</span><span class="p">();</span>
    <span class="p">});</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="n">TaskSystemParallelThreadPoolSleeping</span><span class="o">::~</span><span class="n">TaskSystemParallelThreadPoolSleeping</span><span class="p">()</span> <span class="p">{</span>
    <span class="c1">//</span>
    <span class="c1">// TODO: CS149 student implementations may decide to perform cleanup</span>
    <span class="c1">// operations (such as thread pool shutdown construction) here.</span>
    <span class="c1">// Implementations are free to add new class member variables</span>
    <span class="c1">// (requiring changes to tasksys.h).</span>
    <span class="c1">//</span>
  <span class="n">std</span><span class="o">::</span><span class="n">unique_lock</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">mutex</span><span class="o">&gt;</span> <span class="n">lock</span><span class="p">(</span><span class="n">mutex_</span><span class="p">);</span>
  <span class="n">done_</span><span class="o">=</span><span class="nb">true</span><span class="p">;</span>
  <span class="n">lock</span><span class="p">.</span><span class="n">unlock</span><span class="p">();</span>
  <span class="n">cv_</span><span class="p">.</span><span class="n">notify_all</span><span class="p">();</span>
  <span class="c1">// printf("destructor\n");</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">workers_</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// cv_.notify_all();</span>
    <span class="k">if</span><span class="p">(</span><span class="n">workers_</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">joinable</span><span class="p">())</span> <span class="p">{</span>
      <span class="n">workers_</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">join</span><span class="p">();</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="c1">// printf("exit\n");</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="n">TaskSystemParallelThreadPoolSleeping</span><span class="o">::</span><span class="n">run</span><span class="p">(</span><span class="n">IRunnable</span><span class="o">*</span> <span class="n">runnable</span><span class="p">,</span> <span class="kt">int</span> <span class="n">num_total_tasks</span><span class="p">)</span> <span class="p">{</span>


    <span class="c1">//</span>
    <span class="c1">// TODO: CS149 students will modify the implementation of this</span>
    <span class="c1">// method in Parts A and B.  The implementation provided below runs all</span>
    <span class="c1">// tasks sequentially on the calling thread.</span>
    <span class="c1">//</span>

    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_total_tasks</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">runnable</span><span class="o">-&gt;</span><span class="n">runTask</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">num_total_tasks</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1">// Two places to shcedule tasks and put tasks to ready_queue_ directly </span>
<span class="c1">// or move tasks in task_queue_ to ready_queue_ at the start of runAsyncWithDeps call</span>
<span class="c1">// or at threadTask where each TaskID is done</span>
<span class="n">TaskID</span> <span class="n">TaskSystemParallelThreadPoolSleeping</span><span class="o">::</span><span class="n">runAsyncWithDeps</span><span class="p">(</span><span class="n">IRunnable</span><span class="o">*</span> <span class="n">runnable</span><span class="p">,</span> <span class="kt">int</span> <span class="n">num_total_tasks</span><span class="p">,</span>
                                                    <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">TaskID</span><span class="o">&gt;&amp;</span> <span class="n">deps</span><span class="p">)</span> <span class="p">{</span>

    <span class="c1">//</span>
    <span class="c1">// TODO: CS149 students will implement this method in Part B.</span>
    <span class="c1">//</span>

  <span class="n">mutex_</span><span class="p">.</span><span class="n">lock</span><span class="p">();</span>
  <span class="n">TaskID</span> <span class="n">new_task</span> <span class="o">=</span> <span class="n">task_dep_</span><span class="p">.</span><span class="n">GetNewTaskID</span><span class="p">();</span>
  <span class="n">task_dep_</span><span class="p">.</span><span class="n">AddTaskDep</span><span class="p">(</span><span class="n">new_task</span><span class="p">,</span> <span class="n">deps</span><span class="p">,</span> <span class="n">runnable</span><span class="p">,</span> <span class="n">num_total_tasks</span><span class="p">);</span>
  <span class="c1">// printf("task: %d dep count: %ld\n", new_task, deps.size());</span>
  <span class="n">mutex_</span><span class="p">.</span><span class="n">unlock</span><span class="p">();</span>
  <span class="n">cv_</span><span class="p">.</span><span class="n">notify_all</span><span class="p">();</span>


  <span class="k">return</span> <span class="n">new_task</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="n">TaskSystemParallelThreadPoolSleeping</span><span class="o">::</span><span class="n">sync</span><span class="p">()</span> <span class="p">{</span>

    <span class="c1">//</span>
    <span class="c1">// TODO: CS149 students will modify the implementation of this method in Part B.</span>
    <span class="c1">//</span>
  <span class="n">std</span><span class="o">::</span><span class="n">unique_lock</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">mutex</span><span class="o">&gt;</span> <span class="n">lock</span><span class="p">(</span><span class="n">mutex_</span><span class="p">);</span>
  <span class="c1">// In case all threads atre put to sleep</span>


  <span class="k">while</span><span class="p">(</span><span class="o">!</span><span class="n">ready_queue_</span><span class="p">.</span><span class="n">empty</span><span class="p">()</span> <span class="o">||</span> <span class="n">task_dep_</span><span class="p">.</span><span class="n">GetFinishedTaskCount</span><span class="p">()</span> <span class="o">!=</span> <span class="n">task_dep_</span><span class="p">.</span><span class="n">GetTotalTaskCount</span><span class="p">()</span>  <span class="p">)</span> <span class="p">{</span>
    <span class="c1">// printf("finished task count:%d, task_id:%d\n", finished_tasks_.load(), task_id_.load());</span>
    <span class="n">cv_</span><span class="p">.</span><span class="n">wait</span><span class="p">(</span><span class="n">lock</span><span class="p">);</span>
    <span class="c1">// printf("finished task count:%d, task_id:%d\n", finished_tasks_.load(), task_id_.load());</span>
  <span class="p">}</span>
    <span class="k">return</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">TaskDep</span><span class="o">::</span><span class="n">TaskDep</span><span class="p">()</span> <span class="p">{</span>
  <span class="n">task_id_</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="n">finished_tasks_</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">TaskID</span> <span class="n">TaskDep</span><span class="o">::</span><span class="n">GetNewTaskID</span><span class="p">()</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">task_id_</span><span class="p">.</span><span class="n">fetch_add</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>

<span class="p">}</span>

<span class="kt">int</span> <span class="n">TaskDep</span><span class="o">::</span><span class="n">GetFinishedTaskCount</span><span class="p">()</span> <span class="k">const</span>  <span class="p">{</span>
  <span class="k">return</span> <span class="n">finished_tasks_</span><span class="p">.</span><span class="n">load</span><span class="p">();</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="n">TaskDep</span><span class="o">::</span><span class="n">FinishTask</span><span class="p">(</span><span class="n">TaskID</span> <span class="n">task_id</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">finished_task_ids_</span><span class="p">.</span><span class="n">insert</span><span class="p">(</span><span class="n">task_id</span><span class="p">);</span>
  <span class="n">finished_tasks_</span><span class="p">.</span><span class="n">fetch_add</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
<span class="p">}</span>
<span class="kt">void</span> <span class="n">TaskSystemParallelThreadPoolSleeping</span><span class="o">::</span><span class="n">FinishOneSubTask</span><span class="p">(</span><span class="n">TaskID</span> <span class="n">task_id</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">if</span><span class="p">(</span><span class="o">--</span><span class="n">taskid_remain_work_count_map_</span><span class="p">[</span><span class="n">task_id</span><span class="p">]</span> <span class="o">==</span><span class="mi">0</span> <span class="p">)</span> <span class="p">{</span>
    <span class="c1">// printf("task:%d finished\n", task_id);</span>
    <span class="n">task_dep_</span><span class="p">.</span><span class="n">FinishTask</span><span class="p">(</span><span class="n">task_id</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="kt">bool</span> <span class="n">TaskDep</span><span class="o">::</span><span class="n">CheckAndGetRunnableTasks</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">TaskID</span><span class="o">&gt;&amp;</span> <span class="n">tasks</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">TaskID</span><span class="o">&gt;</span> <span class="n">to_erase</span><span class="p">;</span>
  <span class="k">for</span><span class="p">(</span><span class="k">auto</span> <span class="o">&amp;</span><span class="n">iter</span><span class="o">:</span> <span class="n">dependent_parents_</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">TaskID</span> <span class="n">child_task_id</span> <span class="o">=</span> <span class="n">iter</span><span class="p">.</span><span class="n">first</span><span class="p">;</span>
    <span class="c1">// printf("child task id:%d\n", child_task_id  );</span>
    <span class="k">for</span><span class="p">(</span><span class="k">auto</span> <span class="n">parent_it</span><span class="o">=</span><span class="n">iter</span><span class="p">.</span><span class="n">second</span><span class="p">.</span><span class="n">begin</span><span class="p">();</span> <span class="n">parent_it</span><span class="o">!=</span><span class="n">iter</span><span class="p">.</span><span class="n">second</span><span class="p">.</span><span class="n">end</span><span class="p">();){</span>
      <span class="c1">// printf("   parent: %d, finished:%d\n", *parent_it, CheckTaskFinished(*parent_it));</span>
      <span class="k">if</span><span class="p">(</span> <span class="n">CheckTaskFinished</span><span class="p">(</span><span class="o">*</span><span class="n">parent_it</span><span class="p">)){</span>
        <span class="n">parent_it</span> <span class="o">=</span> <span class="n">iter</span><span class="p">.</span><span class="n">second</span><span class="p">.</span><span class="n">erase</span><span class="p">(</span><span class="n">parent_it</span><span class="p">);</span>
      <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="n">parent_it</span><span class="o">++</span><span class="p">;</span>  
      <span class="p">}</span>
    <span class="p">}</span>
    <span class="kt">bool</span> <span class="n">not_scheduled</span> <span class="o">=</span> <span class="n">scheduled_task_ids_</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">child_task_id</span><span class="p">)</span> <span class="o">==</span> <span class="n">scheduled_task_ids_</span><span class="p">.</span><span class="n">end</span><span class="p">()</span> <span class="p">;</span>
    <span class="kt">bool</span> <span class="n">parents_empty</span> <span class="o">=</span><span class="n">dependent_parents_</span><span class="p">[</span><span class="n">child_task_id</span><span class="p">].</span><span class="n">empty</span><span class="p">();</span> 
    <span class="k">if</span><span class="p">(</span><span class="n">not_scheduled</span> <span class="o">&amp;&amp;</span> <span class="n">parents_empty</span><span class="p">){</span>
      <span class="n">scheduled_task_ids_</span><span class="p">.</span><span class="n">insert</span><span class="p">(</span><span class="n">child_task_id</span><span class="p">);</span>
      <span class="c1">// printf("new task schedule:%d\n", child_task_id);</span>
      <span class="n">tasks</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">child_task_id</span><span class="p">);</span>
      <span class="n">to_erase</span><span class="p">.</span><span class="n">emplace_back</span><span class="p">(</span><span class="n">child_task_id</span><span class="p">);</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="k">for</span><span class="p">(</span><span class="n">TaskID</span> <span class="n">erase_id</span><span class="o">:</span> <span class="n">to_erase</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">dependent_parents_</span><span class="p">.</span><span class="n">erase</span><span class="p">(</span><span class="n">erase_id</span><span class="p">);</span>
  <span class="p">}</span>
  <span class="k">return</span> <span class="o">!</span><span class="n">tasks</span><span class="p">.</span><span class="n">empty</span><span class="p">();</span>
<span class="p">}</span>

<span class="kt">bool</span> <span class="n">TaskDep</span><span class="o">::</span><span class="n">CheckTaskFinished</span><span class="p">(</span><span class="n">TaskID</span> <span class="n">task_id</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="n">finished_task_ids_</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="n">task_id</span><span class="p">)</span> <span class="o">!=</span> <span class="n">finished_task_ids_</span><span class="p">.</span><span class="n">end</span><span class="p">();</span>

<span class="p">}</span>

<span class="kt">void</span> <span class="n">TaskDep</span><span class="o">::</span><span class="n">GetTaskArg</span><span class="p">(</span><span class="n">TaskID</span> <span class="n">task_id</span><span class="p">,</span> <span class="n">TaskArg</span><span class="o">&amp;</span> <span class="n">task_arg</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">const</span> <span class="k">auto</span><span class="o">&amp;</span> <span class="n">ta</span> <span class="o">=</span> <span class="n">task_args_</span><span class="p">[</span><span class="n">task_id</span><span class="p">];</span>
  <span class="n">task_arg</span><span class="p">.</span><span class="n">task_id</span> <span class="o">=</span> <span class="n">ta</span><span class="p">.</span><span class="n">task_id</span><span class="p">;</span>
  <span class="n">task_arg</span><span class="p">.</span><span class="n">num_total_tasks</span> <span class="o">=</span> <span class="n">ta</span><span class="p">.</span><span class="n">num_total_tasks</span><span class="p">;</span>
  <span class="n">task_arg</span><span class="p">.</span><span class="n">runnable</span> <span class="o">=</span> <span class="n">ta</span><span class="p">.</span><span class="n">runnable</span><span class="p">;</span>
  <span class="n">task_arg</span><span class="p">.</span><span class="n">remain_dep_parent_task_count</span> <span class="o">=</span> <span class="n">ta</span><span class="p">.</span><span class="n">remain_dep_parent_task_count</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="n">TaskDep</span><span class="o">::</span><span class="n">AddTaskDep</span><span class="p">(</span><span class="n">TaskID</span> <span class="n">child</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">TaskID</span><span class="o">&gt;</span> <span class="n">deps</span><span class="p">,</span> <span class="n">IRunnable</span><span class="o">*</span> <span class="n">runnable</span><span class="p">,</span> <span class="kt">int</span> <span class="n">num_total_tasks</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">TaskArg</span> <span class="n">ta</span><span class="p">;</span>
  <span class="n">ta</span><span class="p">.</span><span class="n">task_id</span> <span class="o">=</span> <span class="n">child</span><span class="p">;</span>
  <span class="n">ta</span><span class="p">.</span><span class="n">remain_dep_parent_task_count</span> <span class="o">=</span> <span class="n">deps</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>
  <span class="n">ta</span><span class="p">.</span><span class="n">runnable</span> <span class="o">=</span> <span class="n">runnable</span><span class="p">;</span>
  <span class="n">ta</span><span class="p">.</span><span class="n">num_total_tasks</span> <span class="o">=</span> <span class="n">num_total_tasks</span><span class="p">;</span>
  <span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="n">deps</span><span class="p">.</span><span class="n">empty</span><span class="p">())</span> <span class="p">{</span>
  <span class="k">for</span><span class="p">(</span><span class="n">TaskID</span> <span class="n">task_id</span><span class="o">:</span> <span class="n">deps</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">dependent_parents_</span><span class="p">[</span><span class="n">child</span><span class="p">].</span><span class="n">insert</span><span class="p">(</span><span class="n">task_id</span><span class="p">);</span>
  <span class="p">}</span>

  <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="n">dependent_parents_</span><span class="p">[</span><span class="n">child</span><span class="p">]</span> <span class="o">=</span> <span class="p">{};</span>
  <span class="p">}</span>
  <span class="n">task_args_</span><span class="p">[</span><span class="n">child</span><span class="p">]</span> <span class="o">=</span> <span class="n">ta</span><span class="p">;</span>

<span class="p">}</span>
</code></pre></div></div> <p>Notice the difference between code below</p> <p>The first piece of code would not work because it creates a copy of the elements of dependent_parents_</p> <p>so <code class="language-plaintext highlighter-rouge">dependent_parents_[child_task_id].empty()</code> would always return false</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  for(auto iter: dependent_parents_) {

    if(scheduled_task_ids_.find(child_task_id) == scheduled_task_ids_.end() &amp;&amp;dependent_parents_[child_task_id].empty()){
      scheduled_task_ids_.insert(child_task_id);
      printf("new task schedule:%d\n", child_task_id);
      tasks.emplace_back(child_task_id);
      to_erase.emplace_back(child_task_id);
      // dependent_parents_.erase(child_task_id);
    }
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  for(auto &amp;iter: dependent_parents_) {

    if(scheduled_task_ids_.find(child_task_id) == scheduled_task_ids_.end() &amp;&amp;dependent_parents_[child_task_id].empty()){
      scheduled_task_ids_.insert(child_task_id);
      printf("new task schedule:%d\n", child_task_id);
      tasks.emplace_back(child_task_id);
      to_erase.emplace_back(child_task_id);
      // dependent_parents_.erase(child_task_id);
    }
</code></pre></div></div> <p>Result:</p> <p>Not good. I think it’s because I wake up threads frequently.</p> <p>Try to reduce wake up time.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Executing test: super_super_light_async...
Reference binary: ./runtasks_ref_linux
Results for: super_super_light_async
                                        STUDENT   REFERENCE   PERF?
[Serial]                                8.706     12.433      0.70  (OK)
[Parallel + Always Spawn]               8.406     56.047      0.15  (OK)
[Parallel + Thread Pool + Spin]         8.27      25.412      0.33  (OK)
[Parallel + Thread Pool + Sleep]        224.619   24.681      9.10  (NOT OK)

================================================================================

Executing test: super_light_async...
Reference binary: ./runtasks_ref_linux
Results for: super_light_async
                                        STUDENT   REFERENCE   PERF?
[Serial]                                82.485    95.578      0.86  (OK)
[Parallel + Always Spawn]               81.039    81.133      1.00  (OK)
[Parallel + Thread Pool + Spin]         81.268    34.526      2.35  (NOT OK)
[Parallel + Thread Pool + Sleep]        408.665   31.755      12.87  (NOT OK)

================================================================================
Executing test: ping_pong_equal_async...
Reference binary: ./runtasks_ref_linux
Results for: ping_pong_equal_async
                                        STUDENT   REFERENCE   PERF?
[Serial]                                1313.035  1542.283    0.85  (OK)
[Parallel + Always Spawn]               1309.708  701.653     1.87  (NOT OK)
[Parallel + Thread Pool + Spin]         1313.704  227.62      5.77  (NOT OK)
[Parallel + Thread Pool + Sleep]        778.308   224.776     3.46  (NOT OK)
================================================================================

Executing test: ping_pong_unequal_async...
Reference binary: ./runtasks_ref_linux
Results for: ping_pong_unequal_async
                                        STUDENT   REFERENCE   PERF?
[Serial]                                2446.194  2402.307    1.02  (OK)
[Parallel + Always Spawn]               2456.503  976.121     2.52  (NOT OK)
[Parallel + Thread Pool + Spin]         2454.091  332.344     7.38  (NOT OK)
[Parallel + Thread Pool + Sleep]        506.64    330.938     1.53  (NOT OK)
================================================================================

Executing test: recursive_fibonacci_async...
Reference binary: ./runtasks_ref_linux
Results for: recursive_fibonacci_async
                                        STUDENT   REFERENCE   PERF?
[Serial]                                1310.101  1946.319    0.67  (OK)
[Parallel + Always Spawn]               1303.736  505.253     2.58  (NOT OK)
[Parallel + Thread Pool + Spin]         1306.294  261.702     4.99  (NOT OK)
[Parallel + Thread Pool + Sleep]        186.681   264.498     0.71  (OK)
================================================================================

Executing test: math_operations_in_tight_for_loop_async...
Reference binary: ./runtasks_ref_linux
Results for: math_operations_in_tight_for_loop_async
                                        STUDENT   REFERENCE   PERF?
[Serial]                                821.415   854.457     0.96  (OK)
[Parallel + Always Spawn]               822.081   697.755     1.18  (OK)
[Parallel + Thread Pool + Spin]         817.92    149.114     5.49  (NOT OK)
[Parallel + Thread Pool + Sleep]        7622.159  148.934     51.18  (NOT OK)
================================================================================
Executing test: math_operations_in_tight_for_loop_reduction_tree_async...
Reference binary: ./runtasks_ref_linux
Results for: math_operations_in_tight_for_loop_reduction_tree_async
                                        STUDENT   REFERENCE   PERF?
[Serial]                                419.026   439.384     0.95  (OK)
[Parallel + Always Spawn]               418.167   141.737     2.95  (NOT OK)
[Parallel + Thread Pool + Spin]         418.431   72.123      5.80  (NOT OK)
[Parallel + Thread Pool + Sleep]        70.724    71.191      0.99  (OK)
================================================================================
</code></pre></div></div> <h3 id="reduce-run-time">Reduce run time</h3> <p>Another change I want to make is that I can only schedule tasks at the begining of run call or when a task is finished. This means that there will be less check to get runnable task.</p> <p>Because there are only places where task is scheduled and they are</p> <ol> <li>The task is first inserted to system</li> <li>Another task is finished.</li> </ol> <p>Two possible state of parent task.</p> <ol> <li> <p>The parent task is finished. For this, we can erase the task dependency for child task when the child task is submitted.</p> </li> <li> <p>The parent task is not finished. For this, when parent task is finished, it will talk with task manager and tell it to erase parent task from taske dependency structure.</p> </li> </ol> <p>For both situation, check if child task can be scheduled.</p> <p>Code:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>TaskDep::TaskDep() {
  task_id_ = 0;
  finished_tasks_ = 0;
}
TaskID TaskDep::GetNewTaskID() {
  return task_id_.fetch_add(1);

}

int TaskDep::GetFinishedTaskCount() const  {
  return finished_tasks_.load();
}

void TaskDep::FinishTask(TaskID task_id, std::vector&lt;TaskID&gt;&amp; children_tasks) {
  finished_task_ids_.insert(task_id);
  finished_tasks_.fetch_add(1);
  // remove this parent from all of its children.
  for(TaskID child_task_id: dependent_children_[task_id] ) {
    dependent_parents_[child_task_id].erase(task_id);
    // If child has no parent dependency , we change schedule it
    if(dependent_parents_[child_task_id].empty()) {
      children_tasks.emplace_back(child_task_id);
    }
    // if(dependent_children_[child_task_id].find(task_id) != dependent_children_[child_task_id].end()) {
    //   dependent_children_[child_task_id].erase(task_id);
    // }
    // if(dependent_parents_[child_task_id].empty()) {
    //   children_tasks.emplace_back(child_task_id);
    // }

  }
}
bool TaskSystemParallelThreadPoolSleeping::FinishOneSubTask(TaskID task_id, std::vector&lt;TaskID&gt;&amp; children_tasks) {
  if(--taskid_remain_work_count_map_[task_id] ==0 ) {
    // printf("task:%d finished\n", task_id);
    task_dep_.FinishTask(task_id, children_tasks);
    return true;
    }
  return false; 
}

bool TaskDep::CheckAndGetRunnableTasks(std::vector&lt;TaskID&gt;&amp; tasks) {
  std::vector&lt;TaskID&gt; to_erase;
  for(auto &amp;iter: dependent_parents_) {
    TaskID child_task_id = iter.first;
    // printf("child task id:%d\n", child_task_id  );
    for(auto parent_it=iter.second.begin(); parent_it!=iter.second.end();){
      // printf("   parent: %d, finished:%d\n", *parent_it, CheckTaskFinished(*parent_it));
      if( CheckTaskFinished(*parent_it)){
        parent_it = iter.second.erase(parent_it);
      } else {
        parent_it++;  
      }
    }
    bool not_scheduled = scheduled_task_ids_.find(child_task_id) == scheduled_task_ids_.end() ;
    bool parents_empty =dependent_parents_[child_task_id].empty(); 
    if(not_scheduled &amp;&amp; parents_empty){
      scheduled_task_ids_.insert(child_task_id);
      // printf("new task schedule:%d\n", child_task_id);
      tasks.emplace_back(child_task_id);
      to_erase.emplace_back(child_task_id);
    }
  }
  for(TaskID erase_id: to_erase) {
    dependent_parents_.erase(erase_id);
  }
  return !tasks.empty();
}

bool TaskDep::CheckTaskFinished(TaskID task_id) {
  return finished_task_ids_.find(task_id) != finished_task_ids_.end();

}

void TaskDep::GetTaskArg(TaskID task_id, TaskArg&amp; task_arg) {
  const auto&amp; ta = task_args_[task_id];
  task_arg.task_id = ta.task_id;
  task_arg.num_total_tasks = ta.num_total_tasks;
  task_arg.runnable = ta.runnable;
  task_arg.remain_dep_parent_task_count = ta.remain_dep_parent_task_count;
}

void TaskDep::AddTaskDep(TaskID child, std::vector&lt;TaskID&gt; deps, IRunnable* runnable, int num_total_tasks) {
  TaskArg ta;
  ta.task_id = child;
  ta.remain_dep_parent_task_count = deps.size();
  ta.runnable = runnable;
  ta.num_total_tasks = num_total_tasks;
  if(!deps.empty()) {
  for(TaskID task_id: deps) {
    dependent_parents_[child].insert(task_id);
    dependent_children_[task_id].insert(child);
  }

  } else {
    dependent_parents_[child] = {};
  }
  task_args_[child] = ta;

}
void TaskSystemParallelThreadPoolSleeping::threadTask( ) {
  std::unique_lock&lt;std::mutex&gt; lock(mutex_);
  std::vector&lt;TaskID&gt; tasks;
  bool get_new_tasks_to_run = false;
    while(!done_ || !ready_queue_.empty() ) {
    threadArg arg ; 
    bool get_task = false;
    if(!ready_queue_.empty()) {
      arg = ready_queue_.front();
      ready_queue_.pop_front();
      get_task = true;
      // printf("get task\n");
    } else {
      // printf("wait task\n");
      cv_.wait(lock);
      // cv_.wait(lock, [this]{return !ready_queue_.empty() || done_ ;});
    }
    lock.unlock();
    if(get_task) {
      int task_thread_id = arg.task_thread_id;
      int task_id = arg.task_id;
      bool cur_task_finished = false;
      std::vector&lt;TaskID&gt; children_task_to_schedule;
      arg.runnable-&gt;runTask(task_thread_id, arg.num_total_tasks);
      {
        std::unique_lock&lt;std::mutex&gt; inner_lock(mutex_);
        // printf("taskid: %d, thread_id: %d finished\n", task_id, task_thread_id);
        cur_task_finished = FinishOneSubTask(task_id, children_task_to_schedule);
        if(!children_task_to_schedule.empty()) {
          for(TaskID child_task_id: children_task_to_schedule){
            ScheduleTaskToReadyQueue(child_task_id);
            // Is sthis ok ?
            // cv_.notify_all();
          }
        }
      }
      // Move notify_all out of mutex scope so that 
      // other threads can wake up and do some work
      // if(!ready_queue_.empty()  ) {
      // }
      if(!children_task_to_schedule.empty() || wait_sync_.load()) {
        cv_.notify_all();
      }
    }
    lock.lock();
  }
}

// bool TaskSystemParallelThreadPoolSleeping::CheckTaskAndMoveToReadyQueue() {
//   std::vector&lt;TaskID&gt; tasks;
//     bool get_new_tasks_to_run = task_dep_.CheckAndGetRunnableTasks(tasks);
//     for(TaskID task_id: tasks) {
//       ScheduleTaskToReadyQueue(task_id);
//     }
//     // tasks.clear();
//   return get_new_tasks_to_run;

// }
// Prerequisite: mutex_ is held
void  TaskSystemParallelThreadPoolSleeping::ScheduleTaskToReadyQueue(TaskID task_id) {
  TaskArg task_arg;
  task_dep_.GetTaskArg(task_id, task_arg);
  bool not_scheduled = scheduled_task_ids_.find(task_id) == scheduled_task_ids_.end() ;
  if(not_scheduled  ){
    scheduled_task_ids_.insert(task_id);
    // printf("new task schedule:%d\n", child_task_id);
    // to_erase.emplace_back(child_task_id);
  }
  for(int i=0; i &lt; task_arg.num_total_tasks; i++) {
    threadArg ta(i, task_arg.num_total_tasks, task_arg.runnable, task_id);
    taskid_remain_work_count_map_[task_id] = task_arg.num_total_tasks;
    ready_queue_.emplace_back(ta);
  }

}
const char* TaskSystemParallelThreadPoolSleeping::name() {
    return "Parallel + Thread Pool + Sleep";
}

TaskSystemParallelThreadPoolSleeping::TaskSystemParallelThreadPoolSleeping(int num_threads): ITaskSystem(num_threads) {
    //
    // TODO: CS149 student implementations may decide to perform setup
    // operations (such as thread pool construction) here.
    // Implementations are free to add new class member variables
    // (requiring changes to tasksys.h).
    //
  done_ = false;
  // task_id_ = 0;
  num_threads_ = num_threads;
  // finished_tasks_ = 0;
  for(int i=0; i &lt; num_threads_; i++) {
    workers_.emplace_back([this]{
      this-&gt;threadTask();
    });
  }
}

TaskSystemParallelThreadPoolSleeping::~TaskSystemParallelThreadPoolSleeping() {
    //
    // TODO: CS149 student implementations may decide to perform cleanup
    // operations (such as thread pool shutdown construction) here.
    // Implementations are free to add new class member variables
    // (requiring changes to tasksys.h).
    //
  std::unique_lock&lt;std::mutex&gt; lock(mutex_);
  done_=true;
  lock.unlock();
  cv_.notify_all();
  // printf("destructor\n");
  for(int i=0; i &lt; workers_.size(); i++) {
    // cv_.notify_all();
    if(workers_[i].joinable()) {
      workers_[i].join();
    }
  }
  // printf("exit\n");
}

void TaskSystemParallelThreadPoolSleeping::run(IRunnable* runnable, int num_total_tasks) {


    //
    // TODO: CS149 students will modify the implementation of this
    // method in Parts A and B.  The implementation provided below runs all
    // tasks sequentially on the calling thread.
    //

    for (int i = 0; i &lt; num_total_tasks; i++) {
        runnable-&gt;runTask(i, num_total_tasks);
    }
}

// Two places to shcedule tasks and put tasks to ready_queue_ directly 
// or move tasks in task_queue_ to ready_queue_ at the start of runAsyncWithDeps call
// or at threadTask where each TaskID is done
TaskID TaskSystemParallelThreadPoolSleeping::runAsyncWithDeps(IRunnable* runnable, int num_total_tasks,
                                                    const std::vector&lt;TaskID&gt;&amp; deps) {

    //
    // TODO: CS149 students will implement this method in Part B.
    //

  mutex_.lock();
  TaskID new_task = task_dep_.GetNewTaskID();
  printf("task: %d dep count: %ld, dep id:%d\n", new_task, deps.size(), deps.empty() ? 0 : deps[0]);
  // CheckTaskAndMoveToReadyQueue();
  std::vector&lt;TaskID&gt; new_deps;
  for(TaskID parent_task_id: deps) {
    if(!task_dep_.CheckTaskFinished(parent_task_id)) {
      new_deps.emplace_back(parent_task_id);

    }
  }
  task_dep_.AddTaskDep(new_task, new_deps, runnable, num_total_tasks);
  bool scheduled = false;
  if(new_deps.empty()) {
    ScheduleTaskToReadyQueue(new_task);
    scheduled = true;
  } 
  mutex_.unlock();
  if(scheduled) {
    cv_.notify_all();
  }


  return new_task;
}

void TaskSystemParallelThreadPoolSleeping::sync() {

    //
    // TODO: CS149 students will modify the implementation of this method in Part B.
    //
  std::unique_lock&lt;std::mutex&gt; lock(mutex_);
  // In case all threads atre put to sleep

  wait_sync_.store(true);

  while(!ready_queue_.empty() || task_dep_.GetFinishedTaskCount() != task_dep_.GetTotalTaskCount()  ) {
    // printf("finished task count:%d, task_id:%d\n", finished_tasks_.load(), task_id_.load());
    cv_.wait(lock);
    // printf("finished task count:%d, task_id:%d\n", task_dep_.GetFinishedTaskCount(), task_dep_.GetTotalTaskCount());
  }
  wait_sync_.store(false);
    return;
}
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>class TaskDep{
public:
  TaskDep();
  void AddTaskDep(TaskID child, std::vector&lt;TaskID&gt; deps, IRunnable* runnable, int num_total_tasks);
  // Who is responsible for call this function?
  // I guess we should just iterate all task_id to see 
  // if we can schedule them.
  // void CheckAndRemoveDep(TaskID child_task_id);
  void FinishTask(TaskID task_id, std::vector&lt;TaskID&gt;&amp; children_tasks);
  TaskID GetNewTaskID();
  int GetFinishedTaskCount() const ;
  int GetTotalTaskCount() const { return task_id_.load();}
  bool CheckTaskFinished(TaskID task_id);
  bool CheckAndGetRunnableTasks(std::vector&lt;TaskID&gt;&amp; tasks);
  bool HasTaskToSchedule() const { return !dependent_parents_.empty();}
  void GetTaskArg(TaskID task_id, TaskArg&amp; task_arg);

private:
  std::atomic&lt;TaskID&gt; task_id_;
  std::unordered_map&lt;TaskID, std::unordered_set&lt;TaskID&gt;&gt; dependent_parents_;
  std::unordered_map&lt;TaskID, std::unordered_set&lt;TaskID&gt;&gt; dependent_children_;
  std::unordered_set&lt;TaskID&gt; finished_task_ids_;
  std::unordered_set&lt;TaskID&gt; scheduled_task_ids_;
  std::unordered_map&lt;TaskID, TaskArg&gt; task_args_;
  std::atomic&lt;int&gt; finished_tasks_;

 
};
/*
 * TaskSystemParallelThreadPoolSleeping: This class is the student's
 * optimized implementation of a parallel task execution engine that uses
 * a thread pool. See definition of ITaskSystem in
 * itasksys.h for documentation of the ITaskSystem interface.
 */
class TaskSystemParallelThreadPoolSleeping: public ITaskSystem {
    public:
        TaskSystemParallelThreadPoolSleeping(int num_threads);
        ~TaskSystemParallelThreadPoolSleeping();
        const char* name();
        void run(IRunnable* runnable, int num_total_tasks);
        TaskID runAsyncWithDeps(IRunnable* runnable, int num_total_tasks,
                                const std::vector&lt;TaskID&gt;&amp; deps);
        void sync();

private:
  void threadTask( );

  bool FinishOneSubTask(TaskID task_id, std::vector&lt;TaskID&gt;&amp; children_task) ;
  void ScheduleTaskToReadyQueue(TaskID task_id);
  std::vector&lt;std::thread&gt; workers_;
  int num_threads_;
  bool done_;
  std::atomic&lt;bool&gt; wait_sync_;
  std::mutex mutex_;
  std::condition_variable cv_;
  std::deque&lt;threadArg&gt; ready_queue_;
  std::unordered_map&lt;TaskID, int&gt; taskid_remain_work_count_map_;
  std::unordered_set&lt;TaskID&gt; scheduled_task_ids_;
  TaskDep task_dep_;


};


</code></pre></div></div> <p>Test Output:</p> <p>Run time is reduced a lot compared to previsou frequent wake up call.</p> <p>But it still does not have similar run time in some case compared to reference implemntation.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Executing test: super_super_light_async...
Reference binary: ./runtasks_ref_linux
Results for: super_super_light_async
                                        STUDENT   REFERENCE   PERF?
[Serial]                                8.756     12.191      0.72  (OK)
[Parallel + Always Spawn]               8.429     55.629      0.15  (OK)
[Parallel + Thread Pool + Spin]         8.556     26.492      0.32  (OK)
[Parallel + Thread Pool + Sleep]        30.866    15.692      1.97  (NOT OK)
================================================================================
Executing test: super_light_async...
Reference binary: ./runtasks_ref_linux
Results for: super_light_async
                                        STUDENT   REFERENCE   PERF?
[Serial]                                81.03     95.452      0.85  (OK)
[Parallel + Always Spawn]               79.448    80.543      0.99  (OK)
[Parallel + Thread Pool + Spin]         80.317    30.917      2.60  (NOT OK)
[Parallel + Thread Pool + Sleep]        37.437    28.054      1.33  (NOT OK)
================================================================================

Executing test: ping_pong_equal_async...
Reference binary: ./runtasks_ref_linux
Results for: ping_pong_equal_async
                                        STUDENT   REFERENCE   PERF?
[Serial]                                1294.45   1544.952    0.84  (OK)
[Parallel + Always Spawn]               1296.49   662.509     1.96  (NOT OK)
[Parallel + Thread Pool + Spin]         1293.489  226.582     5.71  (NOT OK)
[Parallel + Thread Pool + Sleep]        193.945   224.466     0.86  (OK)
================================================================================

Executing test: ping_pong_unequal_async...
Reference binary: ./runtasks_ref_linux
Results for: ping_pong_unequal_async
                                        STUDENT   REFERENCE   PERF?
[Serial]                                2429.01   2399.749    1.01  (OK)
[Parallel + Always Spawn]               2407.208  1001.25     2.40  (NOT OK)
[Parallel + Thread Pool + Spin]         2417.762  334.029     7.24  (NOT OK)
[Parallel + Thread Pool + Sleep]        344.299   328.969     1.05  (OK)

================================================================================
Executing test: recursive_fibonacci_async...
Reference binary: ./runtasks_ref_linux
Results for: recursive_fibonacci_async
                                        STUDENT   REFERENCE   PERF?
[Serial]                                1581.684  1939.945    0.82  (OK)
[Parallel + Always Spawn]               1585.249  556.636     2.85  (NOT OK)
[Parallel + Thread Pool + Spin]         1584.694  258.648     6.13  (NOT OK)
[Parallel + Thread Pool + Sleep]        220.133   254.85      0.86  (OK)

================================================================================
Executing test: math_operations_in_tight_for_loop_async...
Reference binary: ./runtasks_ref_linux
Results for: math_operations_in_tight_for_loop_async
                                        STUDENT   REFERENCE   PERF?
[Serial]                                808.41    856.84      0.94  (OK)
[Parallel + Always Spawn]               811.738   693.496     1.17  (OK)
[Parallel + Thread Pool + Spin]         808.998   145.345     5.57  (NOT OK)
[Parallel + Thread Pool + Sleep]        152.518   142.003     1.07  (OK)
================================================================================

Executing test: math_operations_in_tight_for_loop_fewer_tasks_async...
Reference binary: ./runtasks_ref_linux
Results for: math_operations_in_tight_for_loop_fewer_tasks_async
                                        STUDENT   REFERENCE   PERF?
[Serial]                                812.784   858.997     0.95  (OK)
[Parallel + Always Spawn]               812.874   811.4       1.00  (OK)
[Parallel + Thread Pool + Spin]         810.69    126.379     6.41  (NOT OK)
[Parallel + Thread Pool + Sleep]        122.005   126.256     0.97  (OK)
================================================================================

Executing test: math_operations_in_tight_for_loop_fan_in_async...
Reference binary: ./runtasks_ref_linux
Results for: math_operations_in_tight_for_loop_fan_in_async
                                        STUDENT   REFERENCE   PERF?
[Serial]                                417.681   435.005     0.96  (OK)
[Parallel + Always Spawn]               413.541   244.769     1.69  (NOT OK)
[Parallel + Thread Pool + Spin]         413.021   75.503      5.47  (NOT OK)
[Parallel + Thread Pool + Sleep]        73.391    65.41       1.12  (OK)
================================================================================

Executing test: math_operations_in_tight_for_loop_reduction_tree_async...
Reference binary: ./runtasks_ref_linux
Results for: math_operations_in_tight_for_loop_reduction_tree_async
                                        STUDENT   REFERENCE   PERF?
[Serial]                                413.848   438.395     0.94  (OK)
[Parallel + Always Spawn]               414.925   195.032     2.13  (NOT OK)
[Parallel + Thread Pool + Spin]         414.513   72.565      5.71  (NOT OK)
[Parallel + Thread Pool + Sleep]        59.153    65.233      0.91  (OK)
================================================================================
</code></pre></div></div> <p>So we can get rid of checking each tasks every time to see if it can be scheduled and put to ready queue.</p> <p>My code does not has comparable result compared to ref for super_light_async and super_super_light_async .</p> <p>I think this is because there is still opt space to reduce wake up frequency..</p> <p>I decide to move on with assign3 of cs149 and just leave the current code as it is.</p> <p>Just don’t want to spend time on this and want to spend time on learning some cuda writing.</p> <h3 id="side-knowkedge-buffering-in-python-command">Side knowkedge: buffering in python command</h3> <p><strong>Prompt ** why I don’t see any output from this command but when I remove | tee ./test.out there is output <br/><br/> python3 ../tests/run_test_harness.py -n 8 -a 2&gt;&amp;1 | tee ./test.out **Response</strong> The issue you’re encountering is likely due to buffering. When you use <code class="language-plaintext highlighter-rouge">tee</code> to redirect output to a file, the output may be buffered, causing it not to appear immediately on the screen.</p> <h3 id="explanation">Explanation:</h3> <ul> <li><strong>Without <code class="language-plaintext highlighter-rouge">tee</code></strong>: The output is directly sent to the terminal, and you see it immediately.</li> <li><strong>With <code class="language-plaintext highlighter-rouge">tee</code></strong>: The output is first written to a buffer, which is then written to the file and the terminal. This buffering can delay the appearance of the output.</li> </ul> <h3 id="solution">Solution:</h3> <p>You can use the <code class="language-plaintext highlighter-rouge">-u</code> option with <code class="language-plaintext highlighter-rouge">python3</code> to force the standard streams to be unbuffered. This will ensure that the output appears immediately.</p> <p>Revised command:</p> <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python3 <span class="nt">-u</span> ../tests/run_test_harness.py <span class="nt">-n</span> 8 <span class="nt">-a</span> 2&gt;&amp;1 | <span class="nb">tee</span> ./test.out
</code></pre></div></div> <p>This should resolve the issue and allow you to see the output in real-time while still writing it to <code class="language-plaintext highlighter-rouge">test.out</code>.</p>]]></content><author><name></name></author><category term="parallel"/><category term="programming"/><category term="parallel"/><category term="programming"/><summary type="html"><![CDATA[Thread pool for task scheduling]]></summary></entry><entry><title type="html">Stf CS149 Parallel Programming - Lecture 7 - Cuda programming model</title><link href="https://bilyz98.github.io/blog/2024/cs149-lecture7-cuda/" rel="alternate" type="text/html" title="Stf CS149 Parallel Programming - Lecture 7 - Cuda programming model"/><published>2024-10-26T11:59:00+00:00</published><updated>2024-10-26T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/cs149-lecture7-cuda</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/cs149-lecture7-cuda/"><![CDATA[<p><a href="https://gfxcourses.stanford.edu/cs149/fall23/lecture/gpucuda/">Lecture 7 slides</a></p> <p><a href="https://www.youtube.com/watch?v=qQTDF0CBoxE&amp;list=PLoROMvodv4rMp7MTFr4hQsDEcX7Bx6Odp&amp;index=7&amp;pp=iAQB">Video lecture</a></p> <h2 id="cuda-programming-model--abstraction-">CUDA programming model ( abstraction )</h2> <p>Three execution unit and memory address</p> <ol> <li>thread</li> <li>thread block</li> <li>cuda kernel</li> </ol> <p>A thread block contains bunch of threads.</p> <p>A cuda kernal contains all the thread blocks.</p> <p>Memory address space</p> <ol> <li>Each thread has its own memory address space</li> <li>Each thread block has its own shared memory address space for all threads in the thread block</li> <li>All threads across all thread blocks share a process memory address space</li> </ol> <p><img src="https://github.com/user-attachments/assets/851fe0f2-52ec-4b7b-8a23-d3870982c520" alt="image"/></p> <p>Why this 3 level hierachy adress space ? For efficient memory access when threads in thread block are scheduled in the same core.</p> <h2 id="nvidia-gpu-implementation">Nvidia gpu (implementation)</h2> <p>A warp in nvidia gpu is a gropu of 32 threads in thread block. <img src="https://github.com/user-attachments/assets/e2f4aa55-103c-404b-828b-28d693b9c72b" alt="image"/></p> <p>Different CUDA thread has it own PC(Program counter) even though they are in the same warp.</p> <p>However, since all threads in the same warp is likely to execute the same code and same instructions it effectively looks like that there are only 4 unique PCs even though in reality there are 4 * 32 = 128 PCs.</p> <p>Difference between warp and thread block.</p> <p>A thread block is an programming model abstraction.</p> <p>A warp in hardware implementation.</p> <p>Both represent the concept of group of threads .</p> <p>sub-core has 4 warp in the diagram below.</p> <p>Each SM(streaming multi-processor) has 4 sub-core.</p> <p>V100 has 80 SMs in total.</p> <p>For V100, each SM(streaming multi-processor) has 4 sub-cores. <img src="https://github.com/user-attachments/assets/dbca936d-0da6-42fa-82d9-ceaf3d91596d" alt="image"/></p> <p>Instruction execution.</p> <p>Since we have more execution context than ALUs, each instructions is finished half of the work in one cycle and another half of the work in the next cycle.</p> <p><img src="https://github.com/user-attachments/assets/0531761c-6aef-437d-814a-095990d67950" alt="image"/></p>]]></content><author><name></name></author><category term="parallel"/><category term="programming"/><category term="parallel"/><category term="programming"/><summary type="html"><![CDATA[Lecture 7 slides]]></summary></entry><entry><title type="html">Stf CS149 Parallel Programming - Assign1</title><link href="https://bilyz98.github.io/blog/2024/stf-cs149-assign1/" rel="alternate" type="text/html" title="Stf CS149 Parallel Programming - Assign1"/><published>2024-10-22T11:59:00+00:00</published><updated>2024-10-22T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/stf-cs149-assign1</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/stf-cs149-assign1/"><![CDATA[<p><a href="https://github.com/stanford-cs149/asst1">Source link</a></p> <h1 id="program1-generate-image-with-multiple-threads">Program1: generate image with multiple threads.</h1> <p>Hardware: hyperthreads?</p> <p>Code: partition the image generation task.</p> <p>Plot speedup line with number of threads as x axis.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) ➜  prog1_mandelbrot_threads git:(master) ✗ ./mandelbrot --threads 2
[mandelbrot serial]:            [525.650] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot thread]:            [280.569] ms
Wrote image file mandelbrot-thread.ppm
                                (1.87x speedup from 2 threads)
(base) ➜  prog1_mandelbrot_threads git:(master) ✗ ./mandelbrot --threads 3
Wrote image file mandelbrot-serial.ppm
[mandelbrot thread]:            [341.063] ms
Wrote image file mandelbrot-thread.ppm                                                                                                                                                       (1.56x speedup from 3 threads)
(base) ➜  prog1_mandelbrot_threads git:(master) ✗ ./mandelbrot --threads 4
[mandelbrot serial]:            [531.202] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot thread]:            [237.027] ms
Wrote image file mandelbrot-thread.ppm                                                                                                                                                       (2.24x speedup from 4 threads)
(base) ➜  prog1_mandelbrot_threads git:(master) ✗ ./mandelbrot --threads 5
[mandelbrot serial]:            [532.980] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot thread]:            [213.517] ms
Wrote image file mandelbrot-thread.ppm                                                                                                                                                       (2.50x speedup from 5 threads)
(base) ➜  prog1_mandelbrot_threads git:(master) ✗ ./mandelbrot --threads 6
[mandelbrot serial]:            [531.480] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot thread]:            [182.457] ms
Wrote image file mandelbrot-thread.ppm                                                                                                                                                       (2.91x speedup from 6 threads)
(base) ➜  prog1_mandelbrot_threads git:(master) ✗ ./mandelbrot --threads 7
[mandelbrot serial]:            [530.595] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot thread]:            [173.007] ms
Wrote image file mandelbrot-thread.ppm
Mismatch : [1197][142], Expected : 1, Actual : 0
Error : Output from threads does not match serial output
(base) ➜  prog1_mandelbrot_threads git:(master) ✗ ./mandelbrot --threads 8
[mandelbrot serial]:            [534.651] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot thread]:            [150.080] ms
Wrote image file mandelbrot-thread.ppm                                                                                                                                                       (3.56x speedup from 8 threads)
</code></pre></div></div> <p>Time for each thread</p> <p>Not all threads run with same finish time.</p> <p>Why is that?</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) ➜  prog1_mandelbrot_threads git:(master) ✗ ./mandelbrot --threads 2
[mandelbrot serial]:            [529.644] ms
Wrote image file mandelbrot-serial.ppm
exe time: 275.106996 ms
exe time: 294.014979 ms
exe time: 278.083589 ms
exe time: 280.188169 ms
exe time: 268.240355 ms
exe time: 288.978558 ms
exe time: 274.672702 ms
exe time: 285.212621 ms
exe time: 275.313959 ms
exe time: 291.359153 ms
[mandelbrot thread]:            [280.327] ms
Wrote image file mandelbrot-thread.ppm                                                                                                                                                       
(1.89x speedup from 2 threads)


(base) ➜  prog1_mandelbrot_threads git:(master) ✗ ./mandelbrot --threads 3
[mandelbrot serial]:            [532.551] ms
Wrote image file mandelbrot-serial.ppm
exe time: 120.048959 ms
exe time: 127.574176 ms
exe time: 346.292444 ms
exe time: 122.336693 ms
exe time: 122.885458 ms
exe time: 342.198521 ms
exe time: 123.949669 ms
exe time: 123.917334 ms
exe time: 343.334582 ms
exe time: 121.276554 ms
exe time: 121.796411 ms
exe time: 339.319866 ms
exe time: 122.690346 ms
exe time: 123.405423 ms
exe time: 341.921013 ms
[mandelbrot thread]:            [339.491] ms
Wrote image file mandelbrot-thread.ppm
                                (1.57x speedup from 3 threads)


(base) ➜  prog1_mandelbrot_threads git:(master) ✗ ./mandelbrot --threads 4
[mandelbrot serial]:            [532.573] ms
Wrote image file mandelbrot-serial.ppm
exe time: 66.314548 ms
exe time: 69.146506 ms
exe time: 236.007646 ms
exe time: 236.860119 ms
exe time: 67.293212 ms
exe time: 68.643764 ms
exe time: 235.531762 ms
exe time: 235.957604 ms
exe time: 67.872606 ms
exe time: 68.252590 ms
exe time: 231.048137 ms
exe time: 236.915503 ms
exe time: 68.757534 ms
exe time: 70.160590 ms
exe time: 219.524853 ms
exe time: 238.315675 ms
exe time: 66.293016 ms
exe time: 66.733379 ms
exe time: 233.316239 ms
exe time: 234.051295 ms
[mandelbrot thread]:            [234.236] ms
Wrote image file mandelbrot-thread.ppm
                                (2.27x speedup from 4 threads)


(base) ➜  prog1_mandelbrot_threads git:(master) ✗ ./mandelbrot --threads 8
[mandelbrot serial]:            [533.956] ms
Wrote image file mandelbrot-serial.ppm
exe time: 21.111727 ms
exe time: 21.316495 ms
exe time: 59.669584 ms
exe time: 59.972882 ms
exe time: 101.592321 ms
exe time: 104.972839 ms
exe time: 144.783191 ms
exe time: 145.647489 ms
[mandelbrot thread]:            [133.506] ms
Wrote image file mandelbrot-thread.ppm
                                (4.00x speedup from 8 threads)
</code></pre></div></div> <h2 id="more-efficient-implementation">More efficient implementation</h2> <p>cacheline aware ?</p> <p>In this code image is divided by <code class="language-plaintext highlighter-rouge">numThreads</code> blocks and each thread with <code class="language-plaintext highlighter-rouge">threadId</code> accesses idx:threadId of each block.</p> <p>This means that it’s highly likely that at the same moment each thread access the same memory block that is in cache.</p> <p>This is just my understanding.</p> <p>The reason for some threads taking much longer time to finish the job is that some adjacent rows need much more time to compute. If we use round-robin assignment strategy then we can distribute the computation job evenly and each thread can get equal amount of computation job.</p> <p>GPT give me following answer when I asked it why to use round-robin assignment:</p> <p>Thread 2 has one more row to process than the other threads, which can lead to a slight imbalance. However, the imbalance becomes more pronounced if the work done per row is not uniform. For example, if the computation for the Mandelbrot set is more complex for certain rows, the threads processing those rows will take longer to complete, leading to idle time for other threads.</p> <p>This imbalance can be avoided by using a better load balancing strategy, such as the round-robin assignment used in the original code, which distributes the rows more evenly across the threads. 😊</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">workerThreadStart</span><span class="p">(</span><span class="n">WorkerArgs</span> <span class="o">*</span> <span class="k">const</span> <span class="n">args</span><span class="p">)</span> <span class="p">{</span>

  <span class="c1">// TODO FOR CS149 STUDENTS: Implement the body of the worker</span>
  <span class="c1">// thread here. Each thread should make a call to mandelbrotSerial()</span>
  <span class="c1">// to compute a part of the output image.  For example, in a</span>
  <span class="c1">// program that uses two threads, thread 0 could compute the top</span>
  <span class="c1">// half of the image and thread 1 could compute the bottom half.</span>
  <span class="c1">//</span>
  <span class="kt">double</span> <span class="n">startTime</span> <span class="o">=</span> <span class="n">CycleTimer</span><span class="o">::</span><span class="n">currentSeconds</span><span class="p">();</span>
  <span class="kt">float</span> <span class="n">x0</span> <span class="o">=</span> <span class="n">args</span><span class="o">-&gt;</span><span class="n">x0</span><span class="p">;</span>
  <span class="kt">float</span> <span class="n">y0</span> <span class="o">=</span> <span class="n">args</span><span class="o">-&gt;</span><span class="n">y0</span><span class="p">;</span>
  <span class="kt">float</span> <span class="n">x1</span> <span class="o">=</span> <span class="n">args</span><span class="o">-&gt;</span><span class="n">x1</span><span class="p">;</span>
  <span class="kt">float</span> <span class="n">y1</span> <span class="o">=</span> <span class="n">args</span><span class="o">-&gt;</span><span class="n">y1</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">width</span> <span class="o">=</span> <span class="n">args</span><span class="o">-&gt;</span><span class="n">width</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">height</span> <span class="o">=</span> <span class="n">args</span><span class="o">-&gt;</span><span class="n">height</span><span class="p">;</span>

  <span class="c1">// printf("cur start row: %d, cur total row:%d\n", cur_start_row, cur_total_rows);</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">height</span><span class="o">/</span><span class="n">args</span><span class="o">-&gt;</span><span class="n">numThreads</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">start_row</span> <span class="o">=</span> <span class="n">args</span><span class="o">-&gt;</span><span class="n">threadId</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">args</span><span class="o">-&gt;</span><span class="n">numThreads</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">num_rows</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="n">mandelbrotSerial</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">y0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span>
                     <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span>
                     <span class="n">start_row</span><span class="p">,</span> <span class="n">num_rows</span><span class="p">,</span>
                     <span class="n">args</span><span class="o">-&gt;</span><span class="n">maxIterations</span><span class="p">,</span> <span class="n">args</span><span class="o">-&gt;</span><span class="n">output</span><span class="p">);</span>


  <span class="p">}</span>
  <span class="kt">double</span> <span class="n">endTime</span> <span class="o">=</span> <span class="n">CycleTimer</span><span class="o">::</span><span class="n">currentSeconds</span><span class="p">();</span>
  <span class="kt">double</span> <span class="n">exe_time</span> <span class="o">=</span> <span class="n">endTime</span> <span class="o">-</span> <span class="n">startTime</span><span class="p">;</span>
  <span class="n">printf</span><span class="p">(</span><span class="s">"exe time: %f ms</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">exe_time</span><span class="o">*</span><span class="mi">1000</span><span class="p">);</span>


  <span class="c1">// printf("Hello world from thread %d\n", args-&gt;threadId);</span>
<span class="p">}</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) ➜  prog1_mandelbrot_threads git:(master) ✗ ./mandelbrot --threads 4
[mandelbrot serial]:            [533.651] ms
Wrote image file mandelbrot-serial.ppm
exe time: 142.692391 ms
exe time: 157.330707 ms
exe time: 157.454997 ms
exe time: 157.499295 ms
exe time: 141.290620 ms
exe time: 150.249667 ms
exe time: 150.373559 ms
exe time: 150.334526 ms
exe time: 138.450164 ms
exe time: 151.096858 ms
exe time: 151.156478 ms
exe time: 151.210513 ms
exe time: 138.270788 ms
exe time: 150.668491 ms
exe time: 150.774766 ms
exe time: 150.800020 ms
exe time: 138.079636 ms
exe time: 150.737014 ms
exe time: 150.741972 ms
exe time: 150.848471 ms
[mandelbrot thread]:            [150.471] ms
Wrote image file mandelbrot-thread.ppm
                                (3.55x speedup from 4 threads)
</code></pre></div></div> <h3 id="comparison-between-inefficient-assignment-and-round-robin-assignment">Comparison between inefficient assignment and round-robin assignment</h3> <p>Naive sequential assignment:</p> <p>Thread running time for another image genration</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) ➜  prog1_mandelbrot_threads git:(master) ✗ ./mandelbrot --view 2 --threads 4
[mandelbrot serial]:            [311.051] ms
Wrote image file mandelbrot-serial.ppm
exe time: 84.468454 ms
exe time: 86.912777 ms
exe time: 87.307919 ms
exe time: 133.808278 ms
[mandelbrot thread]:            [119.725] ms
Wrote image file mandelbrot-thread.ppm                                                                                                                                                       
(2.60x speedup from 4 threads)
</code></pre></div></div> <p>Round-robin assignment:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) ➜  prog1_mandelbrot_threads git:(master) ✗ ./mandelbrot --view 2 --threads 4
[mandelbrot serial]:            [310.842] ms
Wrote image file mandelbrot-serial.ppm
exe time: 83.830711 ms
exe time: 93.051653 ms
exe time: 93.096461 ms
exe time: 93.373701 ms
[mandelbrot thread]:            [93.562] ms
Wrote image file mandelbrot-thread.ppm                                                                                                                                                       (3.32x speedup from 4 threads)
</code></pre></div></div> <h1 id="prog2">Prog2</h1> <p><a href="https://ark.intel.com/content/www/us/en/ark/products/192450/intel-xeon-gold-6230n-processor-27-5m-cache-2-30-ghz.html">cpu xeon 6230n</a> Instruction set extensions: Intel® SSE4.2, Intel® AVX, Intel® AVX2, Intel® AVX-512</p> <p><a href="https://ark.intel.com/content/www/us/en/ark/products/97129/intel-core-i7-7700k-processor-8m-cache-up-to-4-50-ghz.html">cpu i7-7700k</a> Instruction set extensions: Intel® SSE4.1, Intel® SSE4.2, Intel® AVX2</p> <p>Both support hyper-threading technology which means each hardware core has two processing threads per physical core.</p> <h2 id="prog2-vectorizing--code-using-simd-intrinsics">Prog2: Vectorizing code using SIMD intrinsics</h2> <p><a href="https://github.com/stanford-cs149/asst1?tab=readme-ov-file#program-2-vectorizing-code-using-simd-intrinsics-20-points">Assignment link</a></p> <p>Solution idea:</p> <p>Just translate the <code class="language-plaintext highlighter-rouge">clampedExpSerial</code> the code to use SIMD. Refer to this <code class="language-plaintext highlighter-rouge">absVector</code> and <code class="language-plaintext highlighter-rouge">absSerial</code> to see how translation works.</p> <p>To deal with situation that total number of loop iterations is not a multiple of SIMD vector width we can set <code class="language-plaintext highlighter-rouge">maskAll</code> at the beginning of the function so that only valid values of input vector is used for SIMD computation.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">if</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">VECTOR_WIDTH</span> <span class="o">&gt;</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">maskAll</span> <span class="o">=</span> <span class="n">_cs149_init_ones</span><span class="p">(</span><span class="n">remain_count</span><span class="p">);</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="n">maskAll</span> <span class="o">=</span> <span class="n">_cs149_init_ones</span><span class="p">();</span>
    <span class="p">}</span>

</code></pre></div></div> <p>code:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">clampedExpVector</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span> <span class="n">values</span><span class="p">,</span> <span class="kt">int</span><span class="o">*</span> <span class="n">exponents</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="n">output</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>

  <span class="c1">//</span>
  <span class="c1">// CS149 STUDENTS TODO: Implement your vectorized version of</span>
  <span class="c1">// clampedExpSerial() here.</span>
  <span class="c1">//</span>
  <span class="c1">// Your solution should work for any value of</span>
  <span class="c1">// N and VECTOR_WIDTH, not just when VECTOR_WIDTH divides N</span>
  <span class="c1">//</span>
  
  <span class="n">__cs149_vec_float</span> <span class="n">x</span><span class="p">;</span>
  <span class="n">__cs149_vec_int</span>   <span class="n">y_exponents</span><span class="p">;</span>
  <span class="n">__cs149_vec_float</span> <span class="n">result</span><span class="p">;</span>
  <span class="n">__cs149_vec_int</span> <span class="n">zeros_int</span> <span class="o">=</span> <span class="n">_cs149_vset_int</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
  <span class="n">__cs149_vec_int</span> <span class="n">ones_int</span> <span class="o">=</span> <span class="n">_cs149_vset_int</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
  <span class="n">__cs149_vec_float</span> <span class="n">ones_float</span> <span class="o">=</span> <span class="n">_cs149_vset_float</span><span class="p">(</span><span class="mf">1.0</span><span class="n">f</span><span class="p">);</span>
  <span class="n">__cs149_mask</span> <span class="n">maskAll</span><span class="p">,</span> <span class="n">maskExponentIsZero</span><span class="p">,</span> <span class="n">maskExponentNotZero</span><span class="p">;</span>  
  <span class="kt">int</span> <span class="n">remain_count</span> <span class="o">=</span> <span class="n">N</span> <span class="o">%</span> <span class="n">VECTOR_WIDTH</span><span class="p">;</span>
  <span class="c1">// int first_valid_count = remain_count &gt; 0 ? VECTOR_WIDTH - remain_count : VECTOR_WIDTH;</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">;</span> <span class="n">i</span><span class="o">+=</span> <span class="n">VECTOR_WIDTH</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">VECTOR_WIDTH</span> <span class="o">&gt;</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">maskAll</span> <span class="o">=</span> <span class="n">_cs149_init_ones</span><span class="p">(</span><span class="n">remain_count</span><span class="p">);</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="n">maskAll</span> <span class="o">=</span> <span class="n">_cs149_init_ones</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="c1">// CS149Logger.addLog("initones", maskAll, VECTOR_WIDTH);</span>

    <span class="n">maskExponentIsZero</span> <span class="o">=</span> <span class="n">_cs149_init_ones</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>

    <span class="n">_cs149_vload_float</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">values</span><span class="o">+</span><span class="n">i</span><span class="p">,</span> <span class="n">maskAll</span><span class="p">);</span>
    <span class="n">_cs149_vload_int</span><span class="p">(</span><span class="n">y_exponents</span><span class="p">,</span> <span class="n">exponents</span><span class="o">+</span><span class="n">i</span><span class="p">,</span> <span class="n">maskAll</span><span class="p">);</span>

    <span class="c1">// if y== 0</span>
    <span class="n">_cs149_veq_int</span><span class="p">(</span><span class="n">maskExponentIsZero</span><span class="p">,</span> <span class="n">y_exponents</span><span class="p">,</span> <span class="n">zeros_int</span><span class="p">,</span> <span class="n">maskAll</span><span class="p">);</span>
    <span class="n">maskExponentNotZero</span> <span class="o">=</span> <span class="n">_cs149_mask_not</span><span class="p">(</span><span class="n">maskExponentIsZero</span><span class="p">);</span>

    <span class="c1">// x == 1  if y_exponents == 0</span>
    <span class="c1">//</span>
    <span class="n">_cs149_vmove_float</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">ones_float</span><span class="p">,</span> <span class="n">maskExponentIsZero</span><span class="p">);</span>      

    <span class="c1">// else </span>
    <span class="c1">// result = x;</span>
    <span class="n">_cs149_vmove_float</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">maskExponentNotZero</span><span class="p">);</span>
    <span class="c1">// count = y -1;</span>
    <span class="n">_cs149_vsub_int</span><span class="p">(</span><span class="n">y_exponents</span><span class="p">,</span> <span class="n">y_exponents</span><span class="p">,</span> <span class="n">ones_int</span><span class="p">,</span> <span class="n">maskExponentNotZero</span><span class="p">);</span>
    <span class="n">__cs149_mask</span> <span class="n">maskExpNotZeroCnt</span><span class="p">;</span>
    <span class="n">_cs149_vgt_int</span><span class="p">(</span><span class="n">maskExpNotZeroCnt</span><span class="p">,</span> <span class="n">y_exponents</span><span class="p">,</span>  <span class="n">zeros_int</span><span class="p">,</span> <span class="n">maskAll</span><span class="p">);</span>
    <span class="c1">// while (count &gt; 0)</span>
    <span class="c1">// result *= x ;</span>
    <span class="c1">// count--;</span>
    <span class="k">while</span><span class="p">(</span><span class="n">_cs149_cntbits</span><span class="p">(</span><span class="n">maskExpNotZeroCnt</span><span class="p">))</span> <span class="p">{</span>
      <span class="n">_cs149_vmult_float</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">result</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">maskExpNotZeroCnt</span><span class="p">);</span>

      <span class="n">_cs149_vsub_int</span><span class="p">(</span><span class="n">y_exponents</span><span class="p">,</span> <span class="n">y_exponents</span><span class="p">,</span> <span class="n">ones_int</span><span class="p">,</span> <span class="n">maskExponentNotZero</span><span class="p">);</span>
      <span class="n">_cs149_vgt_int</span><span class="p">(</span><span class="n">maskExpNotZeroCnt</span><span class="p">,</span> <span class="n">y_exponents</span><span class="p">,</span>  <span class="n">zeros_int</span><span class="p">,</span> <span class="n">maskAll</span><span class="p">);</span>
    <span class="p">}</span>


    <span class="c1">// if( result &gt; 9.999999f) {</span>
    <span class="c1">// result = 9.999999f;</span>
    <span class="c1">// }</span>
    <span class="n">__cs149_mask</span> <span class="n">mask_gt_9</span><span class="p">;</span>
    <span class="n">__cs149_vec_float</span> <span class="n">nine_float</span> <span class="o">=</span> <span class="n">_cs149_vset_float</span><span class="p">(</span><span class="mf">9.999999</span><span class="n">f</span><span class="p">);</span>
    <span class="n">_cs149_vgt_float</span><span class="p">(</span><span class="n">mask_gt_9</span><span class="p">,</span> <span class="n">result</span><span class="p">,</span>  <span class="n">nine_float</span><span class="p">,</span> <span class="n">maskAll</span><span class="p">);</span>
    <span class="n">_cs149_vmove_float</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">nine_float</span><span class="p">,</span> <span class="n">mask_gt_9</span><span class="p">);</span>

    <span class="c1">// output[i] = result;</span>
    <span class="n">_cs149_vstore_float</span><span class="p">(</span><span class="n">output</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">result</span><span class="p">,</span> <span class="n">maskAll</span><span class="p">);</span>

    
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>Run ./myexp -s 10000 and sweep the vector width from 2, 4, 8, to 16. Record the resulting vector utilization. You can do this by changing the #define VECTOR_WIDTH value in CS149intrin.h. Does the vector utilization increase, decrease or stay the same as VECTOR_WIDTH changes? Why?</p> <p>Answer: The vector utilization decrease as <code class="language-plaintext highlighter-rouge">VECTOR_WIDTH</code> increases. The reason I think it’s that not all values in vector is used for computation as <code class="language-plaintext highlighter-rouge">VECTOR_WIDTH</code> increases.</p> <p>So it’s not a very good idea to have very large <code class="language-plaintext highlighter-rouge">VECTOR_WIDTH</code>?</p> <p>vector width 2:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) ➜  prog2_vecintrin git:(master) ✗ ./myexp -s 10000
CLAMPED EXPONENT (required)
Results matched with answer!
****************** Printing Vector Unit Statistics *******************
Vector Width:              2
Total Vector Instructions: 167727
Vector Utilization:        88.7%
Utilized Vector Lanes:     297685
Total Vector Lanes:        335454
************************ Result Verification *************************
Passed!!!
</code></pre></div></div> <p>vector width 4:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) ➜  prog2_vecintrin git:(master) ✗ ./myexp -s 10000
CLAMPED EXPONENT (required)
Results matched with answer!
****************** Printing Vector Unit Statistics *******************
Vector Width:              4
Total Vector Instructions: 97075
Vector Utilization:        86.2%
Utilized Vector Lanes:     334817
Total Vector Lanes:        388300
************************ Result Verification *************************
Passed!!!
</code></pre></div></div> <p>vector width 8:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) ➜  prog2_vecintrin git:(master) ✗ ./myexp -s 10000
CLAMPED EXPONENT (required)
Results matched with answer!
****************** Printing Vector Unit Statistics *******************
Vector Width:              8
Total Vector Instructions: 52877
Vector Utilization:        85.0%
Utilized Vector Lanes:     359535
Total Vector Lanes:        423016
************************ Result Verification *************************
Passed!!!
</code></pre></div></div> <p>vector width 16:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) ➜  prog2_vecintrin git:(master) ✗ ./myexp -s 10000
CLAMPED EXPONENT (required)
Results matched with answer!
****************** Printing Vector Unit Statistics *******************
Vector Width:              16
Total Vector Instructions: 27592
Vector Utilization:        84.4%
Utilized Vector Lanes:     372781
Total Vector Lanes:        441472
************************ Result Verification *************************
Passed!!!
</code></pre></div></div> <h1 id="prog3">Prog3</h1> <h2 id="speedup-with-ispc">Speedup with ISPC</h2> <p>launching 80 tasks brings 62x speedup.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">export</span> <span class="kt">void</span> <span class="nf">mandelbrot_ispc_withtasks</span><span class="p">(</span><span class="n">uniform</span> <span class="kt">float</span> <span class="n">x0</span><span class="p">,</span> <span class="n">uniform</span> <span class="kt">float</span> <span class="n">y0</span><span class="p">,</span>
                                      <span class="n">uniform</span> <span class="kt">float</span> <span class="n">x1</span><span class="p">,</span> <span class="n">uniform</span> <span class="kt">float</span> <span class="n">y1</span><span class="p">,</span>
                                      <span class="n">uniform</span> <span class="kt">int</span> <span class="n">width</span><span class="p">,</span> <span class="n">uniform</span> <span class="kt">int</span> <span class="n">height</span><span class="p">,</span>
                                      <span class="n">uniform</span> <span class="kt">int</span> <span class="n">maxIterations</span><span class="p">,</span>
                                      <span class="n">uniform</span> <span class="kt">int</span> <span class="n">output</span><span class="p">[])</span>
<span class="p">{</span>

    <span class="n">uniform</span> <span class="kt">int</span> <span class="n">rowsPerTask</span> <span class="o">=</span> <span class="n">height</span> <span class="o">/</span> <span class="mi">80</span><span class="p">;</span>

    <span class="c1">// create 2 tasks</span>
    <span class="n">launch</span><span class="p">[</span><span class="mi">80</span><span class="p">]</span> <span class="n">mandelbrot_ispc_task</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">y0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span>
                                     <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span>
                                     <span class="n">rowsPerTask</span><span class="p">,</span>
                                     <span class="n">maxIterations</span><span class="p">,</span>
                                     <span class="n">output</span><span class="p">);</span> 
<span class="p">}</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) ➜  prog3_mandelbrot_ispc git:(master) ✗ ./mandelbrot_ispc  --tasks
[mandelbrot serial]:            [268.624] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot ispc]:              [55.141] ms
Wrote image file mandelbrot-ispc.ppm
[mandelbrot multicore ispc]:    [4.328] ms
Wrote image file mandelbrot-task-ispc.ppm
                                (4.87x speedup from ISPC)
                                (62.07x speedup from task ISPC)
</code></pre></div></div> <p>Speedup for different image generation task with same task parallelism settings is different</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) ➜  prog3_mandelbrot_ispc git:(master) ✗ ./mandelbrot_ispc  --tasks  --view 0
[mandelbrot serial]:            [267.687] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot ispc]:              [54.364] ms
Wrote image file mandelbrot-ispc.ppm
[mandelbrot multicore ispc]:    [4.698] ms
Wrote image file mandelbrot-task-ispc.ppm                                                                                                                                                    (4.92x speedup from ISPC)                                                                                                                                    
(56.97x speedup from task ISPC)

(base) ➜  prog3_mandelbrot_ispc git:(master) ✗ ./mandelbrot_ispc  --tasks  --view 1
[mandelbrot serial]:            [266.777] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot ispc]:              [53.877] ms
Wrote image file mandelbrot-ispc.ppm
[mandelbrot multicore ispc]:    [5.287] ms
Wrote image file mandelbrot-task-ispc.ppm
                                (4.95x speedup from ISPC)
                                (50.46x speedup from task ISPC)

(base) ➜  prog3_mandelbrot_ispc git:(master) ✗ ./mandelbrot_ispc  --tasks  --view 2
[mandelbrot serial]:            [159.744] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot ispc]:              [37.937] ms
Wrote image file mandelbrot-ispc.ppm
[mandelbrot multicore ispc]:    [5.020] ms
Wrote image file mandelbrot-task-ispc.ppm                                                                                                                                                    (4.21x speedup from ISPC)                                                                                                                                    (31.82x speedup from task ISPC)
</code></pre></div></div> <h2 id="difference-between-launch-and-foreach-in-ispc">Difference between launch and foreach in ISPC</h2> <p>TLDR; both <code class="language-plaintext highlighter-rouge">launch</code> and <code class="language-plaintext highlighter-rouge">foreach</code> can do task parallelism. But <code class="language-plaintext highlighter-rouge">foreach</code> can use SIMD and <code class="language-plaintext highlighter-rouge">launch</code> can not do that itself.</p> <p>The difference between <code class="language-plaintext highlighter-rouge">launch</code> and <code class="language-plaintext highlighter-rouge">foreach</code> in ISPC lies in the type of parallelism they express and how they are used:</p> <ul> <li><strong><code class="language-plaintext highlighter-rouge">launch</code></strong>: This keyword is used to create a task that runs independently. When you use <code class="language-plaintext highlighter-rouge">launch</code>, you’re telling ISPC to execute a function asynchronously, potentially on a different core. This is useful for task parallelism, where you have separate tasks that can run concurrently. For example: <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">launch</span> <span class="nf">myFunction</span><span class="p">();</span>
</code></pre></div> </div> <p>This will execute <code class="language-plaintext highlighter-rouge">myFunction</code> as a separate task.</p> </li> <li><strong><code class="language-plaintext highlighter-rouge">foreach</code></strong>: This construct is used for data parallelism, where the same operation is applied to multiple data elements in parallel. The <code class="language-plaintext highlighter-rouge">foreach</code> loop allows ISPC to execute iterations in parallel, utilizing SIMD vector units. For example: <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">foreach</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">...</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// loop body</span>
<span class="p">}</span>
</code></pre></div> </div> <p>This will execute the loop body in parallel for each value of <code class="language-plaintext highlighter-rouge">i</code> from <code class="language-plaintext highlighter-rouge">0</code> to <code class="language-plaintext highlighter-rouge">N-1</code>.</p> </li> </ul> <p>In summary, <code class="language-plaintext highlighter-rouge">launch</code> is used for task parallelism to run independent tasks concurrently, while <code class="language-plaintext highlighter-rouge">foreach</code> is used for data parallelism to apply the same operation to multiple data elements in parallel. Both constructs help you write parallel code, but they are suited for different types of parallelism. 😊</p> <p>The <code class="language-plaintext highlighter-rouge">launch</code> construct in ISPC is primarily designed for task parallelism, which means it can run tasks in parallel on multiple cores. However, <code class="language-plaintext highlighter-rouge">launch</code> itself does not directly utilize SIMD parallelism.</p> <p>Here’s a more detailed breakdown:</p> <ul> <li> <p><strong><code class="language-plaintext highlighter-rouge">launch</code></strong>: When you use <code class="language-plaintext highlighter-rouge">launch</code>, ISPC creates a new task that can run concurrently with other tasks. These tasks can be scheduled on different CPU cores, allowing for parallel execution. The focus of <code class="language-plaintext highlighter-rouge">launch</code> is on task-level parallelism, not on vectorization or SIMD parallelism.</p> </li> <li> <p><strong><code class="language-plaintext highlighter-rouge">foreach</code></strong>: On the other hand, <code class="language-plaintext highlighter-rouge">foreach</code> is designed for data parallelism and can utilize both SIMD and multi-core parallelism. It vectorizes the loop to use SIMD instructions and also distributes the iterations across multiple cores.</p> </li> </ul> <p>While <code class="language-plaintext highlighter-rouge">launch</code> does not directly use SIMD, the tasks that are launched can themselves contain <code class="language-plaintext highlighter-rouge">foreach</code> loops or other code that uses SIMD parallelism. So, you can combine <code class="language-plaintext highlighter-rouge">launch</code> and <code class="language-plaintext highlighter-rouge">foreach</code> to achieve a mix of task parallelism and data parallelism. For example:</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">taskFunction</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span> <span class="n">data</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">foreach</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">...</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="n">launch</span> <span class="nf">taskFunction</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">N</span><span class="p">);</span>
</code></pre></div></div> <p>In this example, <code class="language-plaintext highlighter-rouge">taskFunction</code> uses <code class="language-plaintext highlighter-rouge">foreach</code> to process data in parallel using SIMD, and <code class="language-plaintext highlighter-rouge">launch</code> runs <code class="language-plaintext highlighter-rouge">taskFunction</code> as a separate task on a different core.</p> <p>Would you like to explore more about how to effectively combine <code class="language-plaintext highlighter-rouge">launch</code> and <code class="language-plaintext highlighter-rouge">foreach</code> in ISPC, or have any other questions? 😊</p> <h1 id="prog4">Prog4</h1> <h2 id="change-values-array-to-change-speed-up-of-sqrt">Change values array to change speed up of sqrt</h2> <p>The best case is that all simd vectors handles the same value. And we would get max speed up if each SIMD vector takes long time to finish which reduce the percentage of sync and communication/ scheduling overhead brought by ispc.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) ➜  prog4_sqrt git:(master) ✗ ./sqrt;
[sqrt serial]:          [2062.501] ms
[sqrt ispc]:            [332.707] ms
[sqrt task ispc]:       [14.827] ms                                                                                                                                                          (6.20x speedup from ISPC)                                                                                                                                    (139.11x speedup from task ISPC)
</code></pre></div></div> <p>The worst case is that one value in vector takes extremely long time to finish and all other values in vector take shortest time to finish.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) ➜  prog4_sqrt git:(master) ✗ ./sqrt;
[sqrt serial]:          [286.506] ms
[sqrt ispc]:            [330.483] ms
[sqrt task ispc]:       [14.916] ms
                                (0.87x speedup from ISPC)
                                (19.21x speedup from task ISPC)
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    for (unsigned int i=0; i&lt;N; i++)
    {
        // TODO: CS149 students.  Attempt to change the values in the
        // array here to meet the instructions in the handout: we want
        // to you generate best and worse-case speedups
        
      // best case
    values[i] = 2.998f;

    // worst case
    // if(i%8 == 0) {
    //   values[i] = 2.998f;
    // } else {
    //   values[i] = 1.f;
    // }
    //
    //random:
        // starter code populates array with random input values
        // values[i] = .001f + 2.998f * static_cast&lt;float&gt;(rand()) / RAND_MAX;
    }


</code></pre></div></div> <p>Reference:</p> <p><a href="https://github.com/PKUFlyingPig/asst1/blob/master/prog4_sqrt/main.cpp">https://github.com/PKUFlyingPig/asst1/blob/master/prog4_sqrt/main.cpp</a></p> <h1 id="prog5">Prog5</h1> <p>Extra Credit: (1 point) Note that the total memory bandwidth consumed computation in main.cpp is TOTAL_BYTES = 4 * N * sizeof(float);. Even though saxpy loads one element from X, one element from Y, and writes one element to result the multiplier by 4 is correct. Why is this the case? (Hint, think about how CPU caches work.)</p> <p>Answer: It’s because saxpy fetch 4 vector variables through the memory.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">saxpySerial</span><span class="p">(</span><span class="kt">int</span> <span class="n">N</span><span class="p">,</span>
                       <span class="kt">float</span> <span class="n">scale</span><span class="p">,</span>
                       <span class="kt">float</span> <span class="n">X</span><span class="p">[],</span>
                       <span class="kt">float</span> <span class="n">Y</span><span class="p">[],</span>
                       <span class="kt">float</span> <span class="n">result</span><span class="p">[])</span>
<span class="p">{</span>

    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">result</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="p">}</span>
<span class="p">}</span>

</code></pre></div></div> <p>Output:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) ➜  prog5_saxpy git:(master) ✗ ./saxpy
[saxpy serial]:         [20.605] ms     [14.464] GB/s   [1.941] GFLOPS
[saxpy ispc]:           [17.866] ms     [16.681] GB/s   [2.239] GFLOPS
[saxpy task ispc]:      [3.122] ms      [95.446] GB/s   [12.810] GFLOPS                                                                                                                                                           
(5.72x speedup from use of tasks)
</code></pre></div></div> <p>Extra Credit: (points handled on a case-by-case basis) Improve the performance of saxpy. We’re looking for a significant speedup here, not just a few percentage points. If successful, describe how you did it and what a best-possible implementation on these systems might achieve. Also, if successful, come tell the staff, we’ll be interested. ;-)</p> <p>Answer: I don’t know how to do that.</p>]]></content><author><name></name></author><category term="parallel"/><category term="programming"/><category term="parallel"/><category term="programming"/><summary type="html"><![CDATA[Source link]]></summary></entry><entry><title type="html">ssh display image on local server</title><link href="https://bilyz98.github.io/blog/2024/ssh-display-img/" rel="alternate" type="text/html" title="ssh display image on local server"/><published>2024-10-17T11:59:00+00:00</published><updated>2024-10-17T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/ssh-display-img</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/ssh-display-img/"><![CDATA[<p>To display an image on your local machine after using the <code class="language-plaintext highlighter-rouge">ssh -Y</code> command, you’ll need to have an image viewer installed on the remote server. Here’s a step-by-step example:</p> <ol> <li><strong>Connect to the remote server with X11 forwarding</strong>: <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ssh <span class="nt">-Y</span> user@remote-server
</code></pre></div> </div> </li> <li><strong>Check if an image viewer is installed</strong>: <ul> <li>Common image viewers include <code class="language-plaintext highlighter-rouge">eog</code> (Eye of GNOME), <code class="language-plaintext highlighter-rouge">display</code> (ImageMagick), and <code class="language-plaintext highlighter-rouge">xdg-open</code>.</li> <li>You can check if one of these is installed by running, for example: <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>which eog
</code></pre></div> </div> <p>If it’s installed, the command will return the path to the executable. If not, you might need to install it using the package manager for your distribution.</p> </li> </ul> </li> <li><strong>Display an image</strong>: <ul> <li>Assuming you have an image file named <code class="language-plaintext highlighter-rouge">example.png</code> in your home directory on the remote server, you can display it using: <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>eog ~/example.png
</code></pre></div> </div> </li> <li>This command will open the image using the Eye of GNOME image viewer, and the image should be displayed on your local machine.</li> </ul> </li> </ol> <p>Remember, the exact command to display an image will depend on the image viewers available on the remote server. If you’re not sure which image viewers are installed, you can try running the command for a few common ones until you find one that works. Also, ensure that your local machine is running an X server (like XQuartz on macOS or Xming on Windows) to handle the forwarded X11 display.</p>]]></content><author><name></name></author><category term="ssh"/><category term="ssh"/><summary type="html"><![CDATA[To display an image on your local machine after using the ssh -Y command, you’ll need to have an image viewer installed on the remote server. Here’s a step-by-step example:]]></summary></entry><entry><title type="html">C compiler - single letter local variable</title><link href="https://bilyz98.github.io/blog/2024/chibicc-single-letter-ident/" rel="alternate" type="text/html" title="C compiler - single letter local variable"/><published>2024-10-15T11:59:00+00:00</published><updated>2024-10-15T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/chibicc-single-letter-ident</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/chibicc-single-letter-ident/"><![CDATA[<h2 id="add-single-letter-identity-in-c-compiler">Add single letter identity in c compiler</h2> <p>Need to allocate memory address for single letter variable.</p> <p>Use following two registers. <code class="language-plaintext highlighter-rouge">rsp</code> <code class="language-plaintext highlighter-rouge">rbp</code></p> <p>In x86 assembly language, <code class="language-plaintext highlighter-rouge">rsp</code> and <code class="language-plaintext highlighter-rouge">rbp</code> are registers that play a crucial role in stack management and function calls:</p> <ul> <li> <p><strong><code class="language-plaintext highlighter-rouge">rsp</code> (Stack Pointer)</strong>: This register points to the top of the stack, which is a region of memory used for dynamic storage during program execution. The stack pointer is adjusted automatically when values are pushed onto or popped off the stack. It’s typically used to keep track of the current position in the stack.</p> </li> <li> <p><strong><code class="language-plaintext highlighter-rouge">rbp</code> (Base Pointer)</strong>: This register is used as a reference point for the stack frame of a function. A stack frame contains the function’s local variables and saved registers. The base pointer is usually set to the value of the stack pointer at the beginning of a function and remains constant throughout the function’s execution. This allows for easy access to function parameters and local variables via fixed offsets from <code class="language-plaintext highlighter-rouge">rbp</code>.</p> </li> </ul> <p>Here’s a brief example to illustrate their usage in a function call:</p> <pre><code class="language-assembly">push rbp            ; Save the caller's base pointer
mov rbp, rsp        ; Set the base pointer to the current stack pointer
sub rsp, 16         ; Allocate space for local variables
; Function body
mov rsp, rbp        ; Restore the stack pointer
pop rbp             ; Restore the caller's base pointer
ret                 ; Return to the caller
</code></pre> <p>In this example:</p> <ul> <li>The caller’s base pointer is saved on the stack.</li> <li>The base pointer is set to the current stack pointer, establishing a new stack frame.</li> <li>Space is allocated on the stack for local variables.</li> <li>At the end of the function, the stack pointer and base pointer are restored, and control is returned to the caller.</li> </ul> <p>These registers are essential for implementing nested function calls and maintaining a clean and organized stack structure. If you’re interested in learning more about x86 assembly and stack management, I can provide further details or examples. Just let me know! 😊</p> <p><code class="language-plaintext highlighter-rouge">mov (%%rax), %%rax</code> moves value in <code class="language-plaintext highlighter-rouge">%rax</code> address memory to %rax</p> <p><code class="language-plaintext highlighter-rouge">lea 8(%%rbp), %%rax</code> calculate the effective address <code class="language-plaintext highlighter-rouge">8+%rbp</code> and then load effective address (not memory content) into <code class="language-plaintext highlighter-rouge">%%rax</code></p> <h3 id="parse">Parse</h3> <p>Add assign expression and equality expression.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// expr = assign</span>
<span class="k">static</span> <span class="n">Node</span><span class="o">*</span> <span class="nf">expr</span><span class="p">(</span><span class="n">Token</span> <span class="o">**</span><span class="n">rest</span><span class="p">,</span> <span class="n">Token</span><span class="o">*</span> <span class="n">tok</span><span class="p">){</span>
  <span class="k">return</span> <span class="n">assign</span><span class="p">(</span><span class="n">rest</span><span class="p">,</span> <span class="n">tok</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// assign = equality ("=" assign)?</span>
<span class="k">static</span> <span class="n">Node</span><span class="o">*</span> <span class="nf">assign</span><span class="p">(</span><span class="n">Token</span><span class="o">**</span> <span class="n">rest</span><span class="p">,</span> <span class="n">Token</span><span class="o">*</span> <span class="n">tok</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">Node</span><span class="o">*</span> <span class="n">node</span> <span class="o">=</span> <span class="n">equality</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tok</span><span class="p">,</span> <span class="n">tok</span><span class="p">);</span>
  <span class="k">if</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="s">"="</span><span class="p">))</span> <span class="p">{</span>
    <span class="n">node</span> <span class="o">=</span> <span class="n">new_binary</span><span class="p">(</span><span class="n">ND_ASSIGN</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">assign</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tok</span><span class="p">,</span> <span class="n">tok</span><span class="o">-&gt;</span><span class="n">next</span><span class="p">));</span>
  <span class="p">}</span>

  <span class="o">*</span><span class="n">rest</span> <span class="o">=</span> <span class="n">tok</span><span class="p">;</span>
  <span class="k">return</span> <span class="n">node</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>Add ident type in primary expression.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// primary = "(" expr ")" | ident | num</span>
<span class="k">static</span> <span class="n">Node</span><span class="o">*</span> <span class="nf">primary</span><span class="p">(</span><span class="n">Token</span> <span class="o">**</span><span class="n">rest</span><span class="p">,</span> <span class="n">Token</span><span class="o">*</span> <span class="n">tok</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">if</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="s">"("</span><span class="p">))</span> <span class="p">{</span>
    <span class="n">Node</span><span class="o">*</span> <span class="n">node</span> <span class="o">=</span> <span class="n">expr</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tok</span><span class="p">,</span> <span class="n">tok</span><span class="o">-&gt;</span><span class="n">next</span><span class="p">);</span>
    <span class="o">*</span><span class="n">rest</span> <span class="o">=</span> <span class="n">skip</span><span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="s">")"</span><span class="p">);</span>
    <span class="k">return</span> <span class="n">node</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="k">if</span><span class="p">(</span><span class="n">tok</span><span class="o">-&gt;</span><span class="n">kind</span> <span class="o">==</span> <span class="n">TK_IDENT</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">Node</span><span class="o">*</span> <span class="n">node</span> <span class="o">=</span> <span class="n">new_var_node</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="n">tok</span><span class="o">-&gt;</span><span class="n">loc</span><span class="p">));</span>
    <span class="o">*</span><span class="n">rest</span> <span class="o">=</span> <span class="n">tok</span><span class="o">-&gt;</span><span class="n">next</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">node</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="k">if</span><span class="p">(</span><span class="n">tok</span><span class="o">-&gt;</span><span class="n">kind</span>  <span class="o">==</span> <span class="n">TK_NUM</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">Node</span><span class="o">*</span> <span class="n">node</span> <span class="o">=</span> <span class="n">new_num</span><span class="p">(</span><span class="n">tok</span><span class="o">-&gt;</span><span class="n">val</span><span class="p">);</span>
    <span class="o">*</span><span class="n">rest</span> <span class="o">=</span> <span class="n">tok</span><span class="o">-&gt;</span><span class="n">next</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">node</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">error_tok</span><span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="s">"expected an expression"</span><span class="p">);</span>

<span class="p">}</span>
</code></pre></div></div> <h3 id="codegen">Codegen</h3> <p>Add two new node types.</p> <ol> <li><code class="language-plaintext highlighter-rouge">ND_VAR</code> for loading memory address of variable.</li> <li><code class="language-plaintext highlighter-rouge">ND_ASSIGN</code> for get the value of right hand side expression and assign the value to memory address of the left hand side variable.</li> </ol> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">static</span> <span class="kt">void</span> <span class="nf">gen_expr</span><span class="p">(</span><span class="n">Node</span><span class="o">*</span> <span class="n">node</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">switch</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">kind</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">case</span> <span class="n">ND_NUM</span><span class="p">:</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">" mov $%d, %%rax</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">node</span><span class="o">-&gt;</span><span class="n">val</span><span class="p">);</span>
    <span class="k">return</span><span class="p">;</span>

    <span class="k">case</span> <span class="n">ND_NEG</span><span class="p">:</span>
    <span class="n">gen_expr</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">lhs</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">" neg %%rax</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="k">return</span><span class="p">;</span>

    <span class="k">case</span> <span class="n">ND_VAR</span><span class="p">:</span>
    <span class="n">gen_addr</span><span class="p">(</span><span class="n">node</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"  mov (%%rax), %%rax</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="k">return</span><span class="p">;;</span>

    <span class="k">case</span> <span class="n">ND_ASSIGN</span><span class="p">:</span>
    <span class="n">gen_addr</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">lhs</span><span class="p">);</span>
    <span class="n">push</span><span class="p">();</span>
    <span class="n">gen_expr</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">rhs</span><span class="p">);</span>
    <span class="n">pop</span><span class="p">(</span><span class="s">"%rdi"</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"  mov %%rax, (%%rdi)</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="k">return</span><span class="p">;</span>
  <span class="p">}</span>

</code></pre></div></div> <p>Only use stack memory to store value of variable. Each single letter variable takes 8 bytes memory space.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">static</span> <span class="kt">void</span> <span class="nf">gen_addr</span><span class="p">(</span><span class="n">Node</span><span class="o">*</span> <span class="n">node</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">if</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">kind</span> <span class="o">==</span> <span class="n">ND_VAR</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">offset</span> <span class="o">=</span> <span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">name</span> <span class="o">-</span> <span class="sc">'a'</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="mi">8</span><span class="p">;</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"  lea %d(%%rbp), %%rax</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="o">-</span><span class="n">offset</span><span class="p">);</span>
    <span class="k">return</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">error</span><span class="p">(</span><span class="s">"not an lvalue"</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="compiler"/><category term="c"/><category term="compiler"/><summary type="html"><![CDATA[Add single letter identity in c compiler Need to allocate memory address for single letter variable.]]></summary></entry><entry><title type="html">C compiler - parse example walkthrough</title><link href="https://bilyz98.github.io/blog/2024/statement-and-comparison/" rel="alternate" type="text/html" title="C compiler - parse example walkthrough"/><published>2024-10-14T11:59:00+00:00</published><updated>2024-10-14T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/statement-and-comparison</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/statement-and-comparison/"><![CDATA[<h2 id="abstract-syntax-tree-generation-example">Abstract syntax tree generation example</h2> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"5+20-4;"
</code></pre></div></div> <pre><code class="language-asm">  .globl main
main: 
 mov $4, %rax
 push %rax
 mov $20, %rax
 push %rax
 mov $5, %rax
 pop %rdi
 add %rdi, %rax
 pop %rdi
 sub %rdi, %rax
  ret
</code></pre> <p>The parse tree looks like this</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     ─  
   /  \ 
  +    4
/  \    
5  20
</code></pre></div></div> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">static</span> <span class="kt">void</span> <span class="nf">gen_expr</span><span class="p">(</span><span class="n">Node</span><span class="o">*</span> <span class="n">node</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">switch</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">kind</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">case</span> <span class="n">ND_NUM</span><span class="p">:</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">" mov $%d, %%rax</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">node</span><span class="o">-&gt;</span><span class="n">val</span><span class="p">);</span>
    <span class="k">return</span><span class="p">;</span>

    <span class="k">case</span> <span class="n">ND_NEG</span><span class="p">:</span>
    <span class="n">gen_expr</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">lhs</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">" neg %%rax</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="k">return</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">gen_expr</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">rhs</span><span class="p">);</span>
  <span class="n">push</span><span class="p">();</span>
  <span class="n">gen_expr</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">lhs</span><span class="p">);</span>
  <span class="n">pop</span><span class="p">(</span><span class="s">"%rdi"</span><span class="p">);</span>

  <span class="k">switch</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">kind</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">case</span> <span class="n">ND_ADD</span><span class="p">:</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">" add %%rdi, %%rax</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="k">return</span><span class="p">;</span>
    
    <span class="k">case</span> <span class="n">ND_SUB</span><span class="p">:</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">" sub %%rdi, %%rax</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="k">return</span><span class="p">;</span>


</code></pre></div></div>]]></content><author><name></name></author><category term="compiler"/><category term="c"/><category term="compiler"/><summary type="html"><![CDATA[Abstract syntax tree generation example "5+20-4;"]]></summary></entry></feed>