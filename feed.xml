<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://bilyz98.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://bilyz98.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-10-21T07:44:36+00:00</updated><id>https://bilyz98.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Cs149 Assign1 Prog3</title><link href="https://bilyz98.github.io/blog/2024/cs149-assign1-prog3/" rel="alternate" type="text/html" title="Cs149 Assign1 Prog3"/><published>2024-10-20T00:00:00+00:00</published><updated>2024-10-20T00:00:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/cs149-assign1-prog3</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/cs149-assign1-prog3/"><![CDATA[<h2 id="speedup-with-ispc">Speedup with ISPC</h2> <p>launching 80 tasks brings 62x speedup.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="k">export</span> <span class="kt">void</span> <span class="nf">mandelbrot_ispc_withtasks</span><span class="p">(</span><span class="n">uniform</span> <span class="kt">float</span> <span class="n">x0</span><span class="p">,</span> <span class="n">uniform</span> <span class="kt">float</span> <span class="n">y0</span><span class="p">,</span>
                                      <span class="n">uniform</span> <span class="kt">float</span> <span class="n">x1</span><span class="p">,</span> <span class="n">uniform</span> <span class="kt">float</span> <span class="n">y1</span><span class="p">,</span>
                                      <span class="n">uniform</span> <span class="kt">int</span> <span class="n">width</span><span class="p">,</span> <span class="n">uniform</span> <span class="kt">int</span> <span class="n">height</span><span class="p">,</span>
                                      <span class="n">uniform</span> <span class="kt">int</span> <span class="n">maxIterations</span><span class="p">,</span>
                                      <span class="n">uniform</span> <span class="kt">int</span> <span class="n">output</span><span class="p">[])</span>
<span class="p">{</span>

    <span class="n">uniform</span> <span class="kt">int</span> <span class="n">rowsPerTask</span> <span class="o">=</span> <span class="n">height</span> <span class="o">/</span> <span class="mi">80</span><span class="p">;</span>

    <span class="c1">// create 2 tasks</span>
    <span class="n">launch</span><span class="p">[</span><span class="mi">80</span><span class="p">]</span> <span class="n">mandelbrot_ispc_task</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">y0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span>
                                     <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span>
                                     <span class="n">rowsPerTask</span><span class="p">,</span>
                                     <span class="n">maxIterations</span><span class="p">,</span>
                                     <span class="n">output</span><span class="p">);</span> 
<span class="p">}</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) âžœ  prog3_mandelbrot_ispc git:(master) âœ— ./mandelbrot_ispc  --tasks
[mandelbrot serial]:            [268.624] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot ispc]:              [55.141] ms
Wrote image file mandelbrot-ispc.ppm
[mandelbrot multicore ispc]:    [4.328] ms
Wrote image file mandelbrot-task-ispc.ppm
                                (4.87x speedup from ISPC)
                                (62.07x speedup from task ISPC)
</code></pre></div></div> <p>Speedup for different image generation task with same task parallelism settings is different</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) âžœ  prog3_mandelbrot_ispc git:(master) âœ— ./mandelbrot_ispc  --tasks  --view 0
[mandelbrot serial]:            [267.687] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot ispc]:              [54.364] ms
Wrote image file mandelbrot-ispc.ppm
[mandelbrot multicore ispc]:    [4.698] ms
Wrote image file mandelbrot-task-ispc.ppm                                                                                                                                                    (4.92x speedup from ISPC)                                                                                                                                    
(56.97x speedup from task ISPC)

(base) âžœ  prog3_mandelbrot_ispc git:(master) âœ— ./mandelbrot_ispc  --tasks  --view 1
[mandelbrot serial]:            [266.777] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot ispc]:              [53.877] ms
Wrote image file mandelbrot-ispc.ppm
[mandelbrot multicore ispc]:    [5.287] ms
Wrote image file mandelbrot-task-ispc.ppm
                                (4.95x speedup from ISPC)
                                (50.46x speedup from task ISPC)

(base) âžœ  prog3_mandelbrot_ispc git:(master) âœ— ./mandelbrot_ispc  --tasks  --view 2
[mandelbrot serial]:            [159.744] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot ispc]:              [37.937] ms
Wrote image file mandelbrot-ispc.ppm
[mandelbrot multicore ispc]:    [5.020] ms
Wrote image file mandelbrot-task-ispc.ppm                                                                                                                                                    (4.21x speedup from ISPC)                                                                                                                                    (31.82x speedup from task ISPC)
</code></pre></div></div> <h2 id="difference-between-launch-and-foreach-in-ispc">Difference between launch and foreach in ISPC</h2> <p>TLDR; both <code class="language-plaintext highlighter-rouge">launch</code> and <code class="language-plaintext highlighter-rouge">foreach</code> can do task parallelism. But <code class="language-plaintext highlighter-rouge">foreach</code> can use SIMD and <code class="language-plaintext highlighter-rouge">launch</code> can not do that itself.</p> <p>The difference between <code class="language-plaintext highlighter-rouge">launch</code> and <code class="language-plaintext highlighter-rouge">foreach</code> in ISPC lies in the type of parallelism they express and how they are used:</p> <ul> <li><strong><code class="language-plaintext highlighter-rouge">launch</code></strong>: This keyword is used to create a task that runs independently. When you use <code class="language-plaintext highlighter-rouge">launch</code>, youâ€™re telling ISPC to execute a function asynchronously, potentially on a different core. This is useful for task parallelism, where you have separate tasks that can run concurrently. For example: <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">launch</span> <span class="nf">myFunction</span><span class="p">();</span>
</code></pre></div> </div> <p>This will execute <code class="language-plaintext highlighter-rouge">myFunction</code> as a separate task.</p> </li> <li><strong><code class="language-plaintext highlighter-rouge">foreach</code></strong>: This construct is used for data parallelism, where the same operation is applied to multiple data elements in parallel. The <code class="language-plaintext highlighter-rouge">foreach</code> loop allows ISPC to execute iterations in parallel, utilizing SIMD vector units. For example: <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">foreach</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">...</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// loop body</span>
<span class="p">}</span>
</code></pre></div> </div> <p>This will execute the loop body in parallel for each value of <code class="language-plaintext highlighter-rouge">i</code> from <code class="language-plaintext highlighter-rouge">0</code> to <code class="language-plaintext highlighter-rouge">N-1</code>.</p> </li> </ul> <p>In summary, <code class="language-plaintext highlighter-rouge">launch</code> is used for task parallelism to run independent tasks concurrently, while <code class="language-plaintext highlighter-rouge">foreach</code> is used for data parallelism to apply the same operation to multiple data elements in parallel. Both constructs help you write parallel code, but they are suited for different types of parallelism. ðŸ˜Š</p> <p>The <code class="language-plaintext highlighter-rouge">launch</code> construct in ISPC is primarily designed for task parallelism, which means it can run tasks in parallel on multiple cores. However, <code class="language-plaintext highlighter-rouge">launch</code> itself does not directly utilize SIMD parallelism.</p> <p>Hereâ€™s a more detailed breakdown:</p> <ul> <li> <p><strong><code class="language-plaintext highlighter-rouge">launch</code></strong>: When you use <code class="language-plaintext highlighter-rouge">launch</code>, ISPC creates a new task that can run concurrently with other tasks. These tasks can be scheduled on different CPU cores, allowing for parallel execution. The focus of <code class="language-plaintext highlighter-rouge">launch</code> is on task-level parallelism, not on vectorization or SIMD parallelism.</p> </li> <li> <p><strong><code class="language-plaintext highlighter-rouge">foreach</code></strong>: On the other hand, <code class="language-plaintext highlighter-rouge">foreach</code> is designed for data parallelism and can utilize both SIMD and multi-core parallelism. It vectorizes the loop to use SIMD instructions and also distributes the iterations across multiple cores.</p> </li> </ul> <p>While <code class="language-plaintext highlighter-rouge">launch</code> does not directly use SIMD, the tasks that are launched can themselves contain <code class="language-plaintext highlighter-rouge">foreach</code> loops or other code that uses SIMD parallelism. So, you can combine <code class="language-plaintext highlighter-rouge">launch</code> and <code class="language-plaintext highlighter-rouge">foreach</code> to achieve a mix of task parallelism and data parallelism. For example:</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">taskFunction</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span> <span class="n">data</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">foreach</span> <span class="p">(</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">...</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="n">launch</span> <span class="nf">taskFunction</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">N</span><span class="p">);</span>
</code></pre></div></div> <p>In this example, <code class="language-plaintext highlighter-rouge">taskFunction</code> uses <code class="language-plaintext highlighter-rouge">foreach</code> to process data in parallel using SIMD, and <code class="language-plaintext highlighter-rouge">launch</code> runs <code class="language-plaintext highlighter-rouge">taskFunction</code> as a separate task on a different core.</p> <p>Would you like to explore more about how to effectively combine <code class="language-plaintext highlighter-rouge">launch</code> and <code class="language-plaintext highlighter-rouge">foreach</code> in ISPC, or have any other questions? ðŸ˜Š</p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Cs149 Assign1 Prog4</title><link href="https://bilyz98.github.io/blog/2024/cs149-assign1-prog4/" rel="alternate" type="text/html" title="Cs149 Assign1 Prog4"/><published>2024-10-20T00:00:00+00:00</published><updated>2024-10-20T00:00:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/cs149-assign1-prog4</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/cs149-assign1-prog4/"><![CDATA[<p>Reference:</p> <p><a href="https://github.com/PKUFlyingPig/asst1/blob/master/prog4_sqrt/main.cpp">https://github.com/PKUFlyingPig/asst1/blob/master/prog4_sqrt/main.cpp</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Parallel programming - SIMD intrinsics</title><link href="https://bilyz98.github.io/blog/2024/cs149-assign1-prog2/" rel="alternate" type="text/html" title="Parallel programming - SIMD intrinsics"/><published>2024-10-18T11:59:00+00:00</published><updated>2024-10-18T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/cs149-assign1-prog2</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/cs149-assign1-prog2/"><![CDATA[<p><a href="https://ark.intel.com/content/www/us/en/ark/products/192450/intel-xeon-gold-6230n-processor-27-5m-cache-2-30-ghz.html">cpu xeon 6230n</a> Instruction set extensions: IntelÂ® SSE4.2, IntelÂ® AVX, IntelÂ® AVX2, IntelÂ® AVX-512</p> <p><a href="https://ark.intel.com/content/www/us/en/ark/products/97129/intel-core-i7-7700k-processor-8m-cache-up-to-4-50-ghz.html">cpu i7-7700k</a> Instruction set extensions: IntelÂ® SSE4.1, IntelÂ® SSE4.2, IntelÂ® AVX2</p> <p>Both support hyper-threading technology which means each hardware core has two processing threads per physical core.</p> <h2 id="prog2-vectorizing--code-using-simd-intrinsics">Prog2: Vectorizing code using SIMD intrinsics</h2> <p><a href="https://github.com/stanford-cs149/asst1?tab=readme-ov-file#program-2-vectorizing-code-using-simd-intrinsics-20-points">Assignment link</a></p> <p>Solution idea:</p> <p>Just translate the <code class="language-plaintext highlighter-rouge">clampedExpSerial</code> the code to use SIMD. Refer to this <code class="language-plaintext highlighter-rouge">absVector</code> and <code class="language-plaintext highlighter-rouge">absSerial</code> to see how translation works.</p> <p>To deal with situation that total number of loop iterations is not a multiple of SIMD vector width we can set <code class="language-plaintext highlighter-rouge">maskAll</code> at the beginning of the function so that only valid values of input vector is used for SIMD computation.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">if</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">VECTOR_WIDTH</span> <span class="o">&gt;</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">maskAll</span> <span class="o">=</span> <span class="n">_cs149_init_ones</span><span class="p">(</span><span class="n">remain_count</span><span class="p">);</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="n">maskAll</span> <span class="o">=</span> <span class="n">_cs149_init_ones</span><span class="p">();</span>
    <span class="p">}</span>

</code></pre></div></div> <p>code:</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">clampedExpVector</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span> <span class="n">values</span><span class="p">,</span> <span class="kt">int</span><span class="o">*</span> <span class="n">exponents</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="n">output</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>

  <span class="c1">//</span>
  <span class="c1">// CS149 STUDENTS TODO: Implement your vectorized version of</span>
  <span class="c1">// clampedExpSerial() here.</span>
  <span class="c1">//</span>
  <span class="c1">// Your solution should work for any value of</span>
  <span class="c1">// N and VECTOR_WIDTH, not just when VECTOR_WIDTH divides N</span>
  <span class="c1">//</span>
  
  <span class="n">__cs149_vec_float</span> <span class="n">x</span><span class="p">;</span>
  <span class="n">__cs149_vec_int</span>   <span class="n">y_exponents</span><span class="p">;</span>
  <span class="n">__cs149_vec_float</span> <span class="n">result</span><span class="p">;</span>
  <span class="n">__cs149_vec_int</span> <span class="n">zeros_int</span> <span class="o">=</span> <span class="n">_cs149_vset_int</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
  <span class="n">__cs149_vec_int</span> <span class="n">ones_int</span> <span class="o">=</span> <span class="n">_cs149_vset_int</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
  <span class="n">__cs149_vec_float</span> <span class="n">ones_float</span> <span class="o">=</span> <span class="n">_cs149_vset_float</span><span class="p">(</span><span class="mf">1.0</span><span class="n">f</span><span class="p">);</span>
  <span class="n">__cs149_mask</span> <span class="n">maskAll</span><span class="p">,</span> <span class="n">maskExponentIsZero</span><span class="p">,</span> <span class="n">maskExponentNotZero</span><span class="p">;</span>  
  <span class="kt">int</span> <span class="n">remain_count</span> <span class="o">=</span> <span class="n">N</span> <span class="o">%</span> <span class="n">VECTOR_WIDTH</span><span class="p">;</span>
  <span class="c1">// int first_valid_count = remain_count &gt; 0 ? VECTOR_WIDTH - remain_count : VECTOR_WIDTH;</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">;</span> <span class="n">i</span><span class="o">+=</span> <span class="n">VECTOR_WIDTH</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="n">VECTOR_WIDTH</span> <span class="o">&gt;</span> <span class="n">N</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">maskAll</span> <span class="o">=</span> <span class="n">_cs149_init_ones</span><span class="p">(</span><span class="n">remain_count</span><span class="p">);</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="n">maskAll</span> <span class="o">=</span> <span class="n">_cs149_init_ones</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="c1">// CS149Logger.addLog("initones", maskAll, VECTOR_WIDTH);</span>

    <span class="n">maskExponentIsZero</span> <span class="o">=</span> <span class="n">_cs149_init_ones</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>

    <span class="n">_cs149_vload_float</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">values</span><span class="o">+</span><span class="n">i</span><span class="p">,</span> <span class="n">maskAll</span><span class="p">);</span>
    <span class="n">_cs149_vload_int</span><span class="p">(</span><span class="n">y_exponents</span><span class="p">,</span> <span class="n">exponents</span><span class="o">+</span><span class="n">i</span><span class="p">,</span> <span class="n">maskAll</span><span class="p">);</span>

    <span class="c1">// if y== 0</span>
    <span class="n">_cs149_veq_int</span><span class="p">(</span><span class="n">maskExponentIsZero</span><span class="p">,</span> <span class="n">y_exponents</span><span class="p">,</span> <span class="n">zeros_int</span><span class="p">,</span> <span class="n">maskAll</span><span class="p">);</span>
    <span class="n">maskExponentNotZero</span> <span class="o">=</span> <span class="n">_cs149_mask_not</span><span class="p">(</span><span class="n">maskExponentIsZero</span><span class="p">);</span>

    <span class="c1">// x == 1  if y_exponents == 0</span>
    <span class="c1">//</span>
    <span class="n">_cs149_vmove_float</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">ones_float</span><span class="p">,</span> <span class="n">maskExponentIsZero</span><span class="p">);</span>      

    <span class="c1">// else </span>
    <span class="c1">// result = x;</span>
    <span class="n">_cs149_vmove_float</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">maskExponentNotZero</span><span class="p">);</span>
    <span class="c1">// count = y -1;</span>
    <span class="n">_cs149_vsub_int</span><span class="p">(</span><span class="n">y_exponents</span><span class="p">,</span> <span class="n">y_exponents</span><span class="p">,</span> <span class="n">ones_int</span><span class="p">,</span> <span class="n">maskExponentNotZero</span><span class="p">);</span>
    <span class="n">__cs149_mask</span> <span class="n">maskExpNotZeroCnt</span><span class="p">;</span>
    <span class="n">_cs149_vgt_int</span><span class="p">(</span><span class="n">maskExpNotZeroCnt</span><span class="p">,</span> <span class="n">y_exponents</span><span class="p">,</span>  <span class="n">zeros_int</span><span class="p">,</span> <span class="n">maskAll</span><span class="p">);</span>
    <span class="c1">// while (count &gt; 0)</span>
    <span class="c1">// result *= x ;</span>
    <span class="c1">// count--;</span>
    <span class="k">while</span><span class="p">(</span><span class="n">_cs149_cntbits</span><span class="p">(</span><span class="n">maskExpNotZeroCnt</span><span class="p">))</span> <span class="p">{</span>
      <span class="n">_cs149_vmult_float</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">result</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">maskExpNotZeroCnt</span><span class="p">);</span>

      <span class="n">_cs149_vsub_int</span><span class="p">(</span><span class="n">y_exponents</span><span class="p">,</span> <span class="n">y_exponents</span><span class="p">,</span> <span class="n">ones_int</span><span class="p">,</span> <span class="n">maskExponentNotZero</span><span class="p">);</span>
      <span class="n">_cs149_vgt_int</span><span class="p">(</span><span class="n">maskExpNotZeroCnt</span><span class="p">,</span> <span class="n">y_exponents</span><span class="p">,</span>  <span class="n">zeros_int</span><span class="p">,</span> <span class="n">maskAll</span><span class="p">);</span>
    <span class="p">}</span>


    <span class="c1">// if( result &gt; 9.999999f) {</span>
    <span class="c1">// result = 9.999999f;</span>
    <span class="c1">// }</span>
    <span class="n">__cs149_mask</span> <span class="n">mask_gt_9</span><span class="p">;</span>
    <span class="n">__cs149_vec_float</span> <span class="n">nine_float</span> <span class="o">=</span> <span class="n">_cs149_vset_float</span><span class="p">(</span><span class="mf">9.999999</span><span class="n">f</span><span class="p">);</span>
    <span class="n">_cs149_vgt_float</span><span class="p">(</span><span class="n">mask_gt_9</span><span class="p">,</span> <span class="n">result</span><span class="p">,</span>  <span class="n">nine_float</span><span class="p">,</span> <span class="n">maskAll</span><span class="p">);</span>
    <span class="n">_cs149_vmove_float</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">nine_float</span><span class="p">,</span> <span class="n">mask_gt_9</span><span class="p">);</span>

    <span class="c1">// output[i] = result;</span>
    <span class="n">_cs149_vstore_float</span><span class="p">(</span><span class="n">output</span> <span class="o">+</span> <span class="n">i</span><span class="p">,</span> <span class="n">result</span><span class="p">,</span> <span class="n">maskAll</span><span class="p">);</span>

    
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>Run ./myexp -s 10000 and sweep the vector width from 2, 4, 8, to 16. Record the resulting vector utilization. You can do this by changing the #define VECTOR_WIDTH value in CS149intrin.h. Does the vector utilization increase, decrease or stay the same as VECTOR_WIDTH changes? Why?</p> <p>Answer: The vector utilization decrease as <code class="language-plaintext highlighter-rouge">VECTOR_WIDTH</code> increases. The reason I think itâ€™s that not all values in vector is used for computation as <code class="language-plaintext highlighter-rouge">VECTOR_WIDTH</code> increases.</p> <p>So itâ€™s not a very good idea to have very large <code class="language-plaintext highlighter-rouge">VECTOR_WIDTH</code>?</p> <p>vector width 2:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) âžœ  prog2_vecintrin git:(master) âœ— ./myexp -s 10000
CLAMPED EXPONENT (required)
Results matched with answer!
****************** Printing Vector Unit Statistics *******************
Vector Width:              2
Total Vector Instructions: 167727
Vector Utilization:        88.7%
Utilized Vector Lanes:     297685
Total Vector Lanes:        335454
************************ Result Verification *************************
Passed!!!
</code></pre></div></div> <p>vector width 4:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) âžœ  prog2_vecintrin git:(master) âœ— ./myexp -s 10000
CLAMPED EXPONENT (required)
Results matched with answer!
****************** Printing Vector Unit Statistics *******************
Vector Width:              4
Total Vector Instructions: 97075
Vector Utilization:        86.2%
Utilized Vector Lanes:     334817
Total Vector Lanes:        388300
************************ Result Verification *************************
Passed!!!
</code></pre></div></div> <p>vector width 8:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) âžœ  prog2_vecintrin git:(master) âœ— ./myexp -s 10000
CLAMPED EXPONENT (required)
Results matched with answer!
****************** Printing Vector Unit Statistics *******************
Vector Width:              8
Total Vector Instructions: 52877
Vector Utilization:        85.0%
Utilized Vector Lanes:     359535
Total Vector Lanes:        423016
************************ Result Verification *************************
Passed!!!
</code></pre></div></div> <p>vector width 16:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) âžœ  prog2_vecintrin git:(master) âœ— ./myexp -s 10000
CLAMPED EXPONENT (required)
Results matched with answer!
****************** Printing Vector Unit Statistics *******************
Vector Width:              16
Total Vector Instructions: 27592
Vector Utilization:        84.4%
Utilized Vector Lanes:     372781
Total Vector Lanes:        441472
************************ Result Verification *************************
Passed!!!
</code></pre></div></div>]]></content><author><name></name></author><category term="parallel"/><category term="programming"/><category term="parallel"/><category term="programming"/><summary type="html"><![CDATA[cpu xeon 6230n Instruction set extensions: IntelÂ® SSE4.2, IntelÂ® AVX, IntelÂ® AVX2, IntelÂ® AVX-512]]></summary></entry><entry><title type="html">Stf Cs149 Lecture Takeaway</title><link href="https://bilyz98.github.io/blog/2024/stf-cs149-lecture-takeaway/" rel="alternate" type="text/html" title="Stf Cs149 Lecture Takeaway"/><published>2024-10-18T00:00:00+00:00</published><updated>2024-10-18T00:00:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/stf-cs149-lecture-takeaway</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/stf-cs149-lecture-takeaway/"><![CDATA[<h2 id="lecture-5">Lecture 5</h2> <p><a href="https://youtu.be/mmO2Ri_dJkk?si=CCG3Tf9dDYZiExq6">Video</a> Deciding granularity is important for dynamic scheduling in parallel programming.</p> <p>Small granularity leads to better workload distribution but comes with higher synchronization overhead.</p> <h2 id="lecture-6">Lecture 6</h2> <p>Performance optimization: locality, communication and contention.</p> <p>Reduce costs of communication between:</p> <ol> <li>processors.</li> <li>between processors and memory.</li> </ol> <p>Shared memory communication. Numa: non-uniform memory access</p> <p>Message passing blocking send and non-blocking send</p> <p>Reduce communication is important to achieve max utilization of cpu. Just to keep cpu busy</p> <p>Roofline model: To achieve maximum computation throughput GFLOPS/s of cpu or gpus one has to have algorithm that has high operation intensity -&gt; high flops/bytes.</p> <p>Need to has many computation per byte access unit.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">ssh display image on local server</title><link href="https://bilyz98.github.io/blog/2024/ssh-display-img/" rel="alternate" type="text/html" title="ssh display image on local server"/><published>2024-10-17T11:59:00+00:00</published><updated>2024-10-17T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/ssh-display-img</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/ssh-display-img/"><![CDATA[<p>To display an image on your local machine after using the <code class="language-plaintext highlighter-rouge">ssh -Y</code> command, youâ€™ll need to have an image viewer installed on the remote server. Hereâ€™s a step-by-step example:</p> <ol> <li><strong>Connect to the remote server with X11 forwarding</strong>: <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ssh <span class="nt">-Y</span> user@remote-server
</code></pre></div> </div> </li> <li><strong>Check if an image viewer is installed</strong>: <ul> <li>Common image viewers include <code class="language-plaintext highlighter-rouge">eog</code> (Eye of GNOME), <code class="language-plaintext highlighter-rouge">display</code> (ImageMagick), and <code class="language-plaintext highlighter-rouge">xdg-open</code>.</li> <li>You can check if one of these is installed by running, for example: <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>which eog
</code></pre></div> </div> <p>If itâ€™s installed, the command will return the path to the executable. If not, you might need to install it using the package manager for your distribution.</p> </li> </ul> </li> <li><strong>Display an image</strong>: <ul> <li>Assuming you have an image file named <code class="language-plaintext highlighter-rouge">example.png</code> in your home directory on the remote server, you can display it using: <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>eog ~/example.png
</code></pre></div> </div> </li> <li>This command will open the image using the Eye of GNOME image viewer, and the image should be displayed on your local machine.</li> </ul> </li> </ol> <p>Remember, the exact command to display an image will depend on the image viewers available on the remote server. If youâ€™re not sure which image viewers are installed, you can try running the command for a few common ones until you find one that works. Also, ensure that your local machine is running an X server (like XQuartz on macOS or Xming on Windows) to handle the forwarded X11 display.</p>]]></content><author><name></name></author><category term="ssh"/><category term="ssh"/><summary type="html"><![CDATA[To display an image on your local machine after using the ssh -Y command, youâ€™ll need to have an image viewer installed on the remote server. Hereâ€™s a step-by-step example:]]></summary></entry><entry><title type="html">Parallel programming - round robin assignment</title><link href="https://bilyz98.github.io/blog/2024/stf-cs149-parallel-programming-assignment1/" rel="alternate" type="text/html" title="Parallel programming - round robin assignment"/><published>2024-10-17T11:59:00+00:00</published><updated>2024-10-17T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/stf-cs149-parallel-programming-assignment1</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/stf-cs149-parallel-programming-assignment1/"><![CDATA[<h2 id="program1-generate-image-with-multiple-threads">Program1: generate image with multiple threads.</h2> <p>Hardware: hyperthreads?</p> <p>Code: partition the image generation task.</p> <p>Plot speedup line with number of threads as x axis.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) âžœ  prog1_mandelbrot_threads git:(master) âœ— ./mandelbrot --threads 2
[mandelbrot serial]:            [525.650] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot thread]:            [280.569] ms
Wrote image file mandelbrot-thread.ppm
                                (1.87x speedup from 2 threads)
(base) âžœ  prog1_mandelbrot_threads git:(master) âœ— ./mandelbrot --threads 3
Wrote image file mandelbrot-serial.ppm
[mandelbrot thread]:            [341.063] ms
Wrote image file mandelbrot-thread.ppm                                                                                                                                                       (1.56x speedup from 3 threads)
(base) âžœ  prog1_mandelbrot_threads git:(master) âœ— ./mandelbrot --threads 4
[mandelbrot serial]:            [531.202] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot thread]:            [237.027] ms
Wrote image file mandelbrot-thread.ppm                                                                                                                                                       (2.24x speedup from 4 threads)
(base) âžœ  prog1_mandelbrot_threads git:(master) âœ— ./mandelbrot --threads 5
[mandelbrot serial]:            [532.980] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot thread]:            [213.517] ms
Wrote image file mandelbrot-thread.ppm                                                                                                                                                       (2.50x speedup from 5 threads)
(base) âžœ  prog1_mandelbrot_threads git:(master) âœ— ./mandelbrot --threads 6
[mandelbrot serial]:            [531.480] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot thread]:            [182.457] ms
Wrote image file mandelbrot-thread.ppm                                                                                                                                                       (2.91x speedup from 6 threads)
(base) âžœ  prog1_mandelbrot_threads git:(master) âœ— ./mandelbrot --threads 7
[mandelbrot serial]:            [530.595] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot thread]:            [173.007] ms
Wrote image file mandelbrot-thread.ppm
Mismatch : [1197][142], Expected : 1, Actual : 0
Error : Output from threads does not match serial output
(base) âžœ  prog1_mandelbrot_threads git:(master) âœ— ./mandelbrot --threads 8
[mandelbrot serial]:            [534.651] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot thread]:            [150.080] ms
Wrote image file mandelbrot-thread.ppm                                                                                                                                                       (3.56x speedup from 8 threads)
</code></pre></div></div> <p>Time for each thread</p> <p>Not all threads run with same finish time.</p> <p>Why is that?</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) âžœ  prog1_mandelbrot_threads git:(master) âœ— ./mandelbrot --threads 2
[mandelbrot serial]:            [529.644] ms
Wrote image file mandelbrot-serial.ppm
exe time: 275.106996 ms
exe time: 294.014979 ms
exe time: 278.083589 ms
exe time: 280.188169 ms
exe time: 268.240355 ms
exe time: 288.978558 ms
exe time: 274.672702 ms
exe time: 285.212621 ms
exe time: 275.313959 ms
exe time: 291.359153 ms
[mandelbrot thread]:            [280.327] ms
Wrote image file mandelbrot-thread.ppm                                                                                                                                                       
(1.89x speedup from 2 threads)


(base) âžœ  prog1_mandelbrot_threads git:(master) âœ— ./mandelbrot --threads 3
[mandelbrot serial]:            [532.551] ms
Wrote image file mandelbrot-serial.ppm
exe time: 120.048959 ms
exe time: 127.574176 ms
exe time: 346.292444 ms
exe time: 122.336693 ms
exe time: 122.885458 ms
exe time: 342.198521 ms
exe time: 123.949669 ms
exe time: 123.917334 ms
exe time: 343.334582 ms
exe time: 121.276554 ms
exe time: 121.796411 ms
exe time: 339.319866 ms
exe time: 122.690346 ms
exe time: 123.405423 ms
exe time: 341.921013 ms
[mandelbrot thread]:            [339.491] ms
Wrote image file mandelbrot-thread.ppm
                                (1.57x speedup from 3 threads)


(base) âžœ  prog1_mandelbrot_threads git:(master) âœ— ./mandelbrot --threads 4
[mandelbrot serial]:            [532.573] ms
Wrote image file mandelbrot-serial.ppm
exe time: 66.314548 ms
exe time: 69.146506 ms
exe time: 236.007646 ms
exe time: 236.860119 ms
exe time: 67.293212 ms
exe time: 68.643764 ms
exe time: 235.531762 ms
exe time: 235.957604 ms
exe time: 67.872606 ms
exe time: 68.252590 ms
exe time: 231.048137 ms
exe time: 236.915503 ms
exe time: 68.757534 ms
exe time: 70.160590 ms
exe time: 219.524853 ms
exe time: 238.315675 ms
exe time: 66.293016 ms
exe time: 66.733379 ms
exe time: 233.316239 ms
exe time: 234.051295 ms
[mandelbrot thread]:            [234.236] ms
Wrote image file mandelbrot-thread.ppm
                                (2.27x speedup from 4 threads)


(base) âžœ  prog1_mandelbrot_threads git:(master) âœ— ./mandelbrot --threads 8
[mandelbrot serial]:            [533.956] ms
Wrote image file mandelbrot-serial.ppm
exe time: 21.111727 ms
exe time: 21.316495 ms
exe time: 59.669584 ms
exe time: 59.972882 ms
exe time: 101.592321 ms
exe time: 104.972839 ms
exe time: 144.783191 ms
exe time: 145.647489 ms
[mandelbrot thread]:            [133.506] ms
Wrote image file mandelbrot-thread.ppm
                                (4.00x speedup from 8 threads)
</code></pre></div></div> <h2 id="more-efficient-implementation">More efficient implementation</h2> <p>cacheline aware ?</p> <p>In this code image is divided by <code class="language-plaintext highlighter-rouge">numThreads</code> blocks and each thread with <code class="language-plaintext highlighter-rouge">threadId</code> accesses idx:threadId of each block.</p> <p>This means that itâ€™s highly likely that at the same moment each thread access the same memory block that is in cache.</p> <p>This is just my understanding.</p> <p>The reason for some threads taking much longer time to finish the job is that some adjacent rows need much more time to compute. If we use round-robin assignment strategy then we can distribute the computation job evenly and each thread can get equal amount of computation job.</p> <p>GPT give me following answer when I asked it why to use round-robin assignment:</p> <p>Thread 2 has one more row to process than the other threads, which can lead to a slight imbalance. However, the imbalance becomes more pronounced if the work done per row is not uniform. For example, if the computation for the Mandelbrot set is more complex for certain rows, the threads processing those rows will take longer to complete, leading to idle time for other threads.</p> <p>This imbalance can be avoided by using a better load balancing strategy, such as the round-robin assignment used in the original code, which distributes the rows more evenly across the threads. ðŸ˜Š</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">workerThreadStart</span><span class="p">(</span><span class="n">WorkerArgs</span> <span class="o">*</span> <span class="k">const</span> <span class="n">args</span><span class="p">)</span> <span class="p">{</span>

  <span class="c1">// TODO FOR CS149 STUDENTS: Implement the body of the worker</span>
  <span class="c1">// thread here. Each thread should make a call to mandelbrotSerial()</span>
  <span class="c1">// to compute a part of the output image.  For example, in a</span>
  <span class="c1">// program that uses two threads, thread 0 could compute the top</span>
  <span class="c1">// half of the image and thread 1 could compute the bottom half.</span>
  <span class="c1">//</span>
  <span class="kt">double</span> <span class="n">startTime</span> <span class="o">=</span> <span class="n">CycleTimer</span><span class="o">::</span><span class="n">currentSeconds</span><span class="p">();</span>
  <span class="kt">float</span> <span class="n">x0</span> <span class="o">=</span> <span class="n">args</span><span class="o">-&gt;</span><span class="n">x0</span><span class="p">;</span>
  <span class="kt">float</span> <span class="n">y0</span> <span class="o">=</span> <span class="n">args</span><span class="o">-&gt;</span><span class="n">y0</span><span class="p">;</span>
  <span class="kt">float</span> <span class="n">x1</span> <span class="o">=</span> <span class="n">args</span><span class="o">-&gt;</span><span class="n">x1</span><span class="p">;</span>
  <span class="kt">float</span> <span class="n">y1</span> <span class="o">=</span> <span class="n">args</span><span class="o">-&gt;</span><span class="n">y1</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">width</span> <span class="o">=</span> <span class="n">args</span><span class="o">-&gt;</span><span class="n">width</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">height</span> <span class="o">=</span> <span class="n">args</span><span class="o">-&gt;</span><span class="n">height</span><span class="p">;</span>

  <span class="c1">// printf("cur start row: %d, cur total row:%d\n", cur_start_row, cur_total_rows);</span>
  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">height</span><span class="o">/</span><span class="n">args</span><span class="o">-&gt;</span><span class="n">numThreads</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">start_row</span> <span class="o">=</span> <span class="n">args</span><span class="o">-&gt;</span><span class="n">threadId</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">args</span><span class="o">-&gt;</span><span class="n">numThreads</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">num_rows</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="n">mandelbrotSerial</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">y0</span><span class="p">,</span> <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span>
                     <span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span>
                     <span class="n">start_row</span><span class="p">,</span> <span class="n">num_rows</span><span class="p">,</span>
                     <span class="n">args</span><span class="o">-&gt;</span><span class="n">maxIterations</span><span class="p">,</span> <span class="n">args</span><span class="o">-&gt;</span><span class="n">output</span><span class="p">);</span>


  <span class="p">}</span>
  <span class="kt">double</span> <span class="n">endTime</span> <span class="o">=</span> <span class="n">CycleTimer</span><span class="o">::</span><span class="n">currentSeconds</span><span class="p">();</span>
  <span class="kt">double</span> <span class="n">exe_time</span> <span class="o">=</span> <span class="n">endTime</span> <span class="o">-</span> <span class="n">startTime</span><span class="p">;</span>
  <span class="n">printf</span><span class="p">(</span><span class="s">"exe time: %f ms</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">exe_time</span><span class="o">*</span><span class="mi">1000</span><span class="p">);</span>


  <span class="c1">// printf("Hello world from thread %d\n", args-&gt;threadId);</span>
<span class="p">}</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) âžœ  prog1_mandelbrot_threads git:(master) âœ— ./mandelbrot --threads 4
[mandelbrot serial]:            [533.651] ms
Wrote image file mandelbrot-serial.ppm
exe time: 142.692391 ms
exe time: 157.330707 ms
exe time: 157.454997 ms
exe time: 157.499295 ms
exe time: 141.290620 ms
exe time: 150.249667 ms
exe time: 150.373559 ms
exe time: 150.334526 ms
exe time: 138.450164 ms
exe time: 151.096858 ms
exe time: 151.156478 ms
exe time: 151.210513 ms
exe time: 138.270788 ms
exe time: 150.668491 ms
exe time: 150.774766 ms
exe time: 150.800020 ms
exe time: 138.079636 ms
exe time: 150.737014 ms
exe time: 150.741972 ms
exe time: 150.848471 ms
[mandelbrot thread]:            [150.471] ms
Wrote image file mandelbrot-thread.ppm
                                (3.55x speedup from 4 threads)
</code></pre></div></div> <h3 id="comparison-between-inefficient-assignment-and-round-robin-assignment">Comparison between inefficient assignment and round-robin assignment</h3> <p>Naive sequential assignment:</p> <p>Thread running time for another image genration</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) âžœ  prog1_mandelbrot_threads git:(master) âœ— ./mandelbrot --view 2 --threads 4
[mandelbrot serial]:            [311.051] ms
Wrote image file mandelbrot-serial.ppm
exe time: 84.468454 ms
exe time: 86.912777 ms
exe time: 87.307919 ms
exe time: 133.808278 ms
[mandelbrot thread]:            [119.725] ms
Wrote image file mandelbrot-thread.ppm                                                                                                                                                       
(2.60x speedup from 4 threads)
</code></pre></div></div> <p>Round-robin assignment:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) âžœ  prog1_mandelbrot_threads git:(master) âœ— ./mandelbrot --view 2 --threads 4
[mandelbrot serial]:            [310.842] ms
Wrote image file mandelbrot-serial.ppm
exe time: 83.830711 ms
exe time: 93.051653 ms
exe time: 93.096461 ms
exe time: 93.373701 ms
[mandelbrot thread]:            [93.562] ms
Wrote image file mandelbrot-thread.ppm                                                                                                                                                       (3.32x speedup from 4 threads)
</code></pre></div></div>]]></content><author><name></name></author><category term="parallel"/><category term="programming"/><category term="parallel"/><category term="programming"/><summary type="html"><![CDATA[Program1: generate image with multiple threads.]]></summary></entry><entry><title type="html">C compiler - single letter local variable</title><link href="https://bilyz98.github.io/blog/2024/chibicc-single-letter-ident/" rel="alternate" type="text/html" title="C compiler - single letter local variable"/><published>2024-10-15T11:59:00+00:00</published><updated>2024-10-15T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/chibicc-single-letter-ident</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/chibicc-single-letter-ident/"><![CDATA[<h2 id="add-single-letter-identity-in-c-compiler">Add single letter identity in c compiler</h2> <p>Need to allocate memory address for single letter variable.</p> <p>Use following two registers. <code class="language-plaintext highlighter-rouge">rsp</code> <code class="language-plaintext highlighter-rouge">rbp</code></p> <p>In x86 assembly language, <code class="language-plaintext highlighter-rouge">rsp</code> and <code class="language-plaintext highlighter-rouge">rbp</code> are registers that play a crucial role in stack management and function calls:</p> <ul> <li> <p><strong><code class="language-plaintext highlighter-rouge">rsp</code> (Stack Pointer)</strong>: This register points to the top of the stack, which is a region of memory used for dynamic storage during program execution. The stack pointer is adjusted automatically when values are pushed onto or popped off the stack. Itâ€™s typically used to keep track of the current position in the stack.</p> </li> <li> <p><strong><code class="language-plaintext highlighter-rouge">rbp</code> (Base Pointer)</strong>: This register is used as a reference point for the stack frame of a function. A stack frame contains the functionâ€™s local variables and saved registers. The base pointer is usually set to the value of the stack pointer at the beginning of a function and remains constant throughout the functionâ€™s execution. This allows for easy access to function parameters and local variables via fixed offsets from <code class="language-plaintext highlighter-rouge">rbp</code>.</p> </li> </ul> <p>Hereâ€™s a brief example to illustrate their usage in a function call:</p> <pre><code class="language-assembly">push rbp            ; Save the caller's base pointer
mov rbp, rsp        ; Set the base pointer to the current stack pointer
sub rsp, 16         ; Allocate space for local variables
; Function body
mov rsp, rbp        ; Restore the stack pointer
pop rbp             ; Restore the caller's base pointer
ret                 ; Return to the caller
</code></pre> <p>In this example:</p> <ul> <li>The callerâ€™s base pointer is saved on the stack.</li> <li>The base pointer is set to the current stack pointer, establishing a new stack frame.</li> <li>Space is allocated on the stack for local variables.</li> <li>At the end of the function, the stack pointer and base pointer are restored, and control is returned to the caller.</li> </ul> <p>These registers are essential for implementing nested function calls and maintaining a clean and organized stack structure. If youâ€™re interested in learning more about x86 assembly and stack management, I can provide further details or examples. Just let me know! ðŸ˜Š</p> <p><code class="language-plaintext highlighter-rouge">mov (%%rax), %%rax</code> moves value in <code class="language-plaintext highlighter-rouge">%rax</code> address memory to %rax</p> <p><code class="language-plaintext highlighter-rouge">lea 8(%%rbp), %%rax</code> calculate the effective address <code class="language-plaintext highlighter-rouge">8+%rbp</code> and then load effective address (not memory content) into <code class="language-plaintext highlighter-rouge">%%rax</code></p> <h3 id="parse">Parse</h3> <p>Add assign expression and equality expression.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// expr = assign</span>
<span class="k">static</span> <span class="n">Node</span><span class="o">*</span> <span class="nf">expr</span><span class="p">(</span><span class="n">Token</span> <span class="o">**</span><span class="n">rest</span><span class="p">,</span> <span class="n">Token</span><span class="o">*</span> <span class="n">tok</span><span class="p">){</span>
  <span class="k">return</span> <span class="n">assign</span><span class="p">(</span><span class="n">rest</span><span class="p">,</span> <span class="n">tok</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// assign = equality ("=" assign)?</span>
<span class="k">static</span> <span class="n">Node</span><span class="o">*</span> <span class="nf">assign</span><span class="p">(</span><span class="n">Token</span><span class="o">**</span> <span class="n">rest</span><span class="p">,</span> <span class="n">Token</span><span class="o">*</span> <span class="n">tok</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">Node</span><span class="o">*</span> <span class="n">node</span> <span class="o">=</span> <span class="n">equality</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tok</span><span class="p">,</span> <span class="n">tok</span><span class="p">);</span>
  <span class="k">if</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="s">"="</span><span class="p">))</span> <span class="p">{</span>
    <span class="n">node</span> <span class="o">=</span> <span class="n">new_binary</span><span class="p">(</span><span class="n">ND_ASSIGN</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">assign</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tok</span><span class="p">,</span> <span class="n">tok</span><span class="o">-&gt;</span><span class="n">next</span><span class="p">));</span>
  <span class="p">}</span>

  <span class="o">*</span><span class="n">rest</span> <span class="o">=</span> <span class="n">tok</span><span class="p">;</span>
  <span class="k">return</span> <span class="n">node</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>Add ident type in primary expression.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// primary = "(" expr ")" | ident | num</span>
<span class="k">static</span> <span class="n">Node</span><span class="o">*</span> <span class="nf">primary</span><span class="p">(</span><span class="n">Token</span> <span class="o">**</span><span class="n">rest</span><span class="p">,</span> <span class="n">Token</span><span class="o">*</span> <span class="n">tok</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">if</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="s">"("</span><span class="p">))</span> <span class="p">{</span>
    <span class="n">Node</span><span class="o">*</span> <span class="n">node</span> <span class="o">=</span> <span class="n">expr</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tok</span><span class="p">,</span> <span class="n">tok</span><span class="o">-&gt;</span><span class="n">next</span><span class="p">);</span>
    <span class="o">*</span><span class="n">rest</span> <span class="o">=</span> <span class="n">skip</span><span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="s">")"</span><span class="p">);</span>
    <span class="k">return</span> <span class="n">node</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="k">if</span><span class="p">(</span><span class="n">tok</span><span class="o">-&gt;</span><span class="n">kind</span> <span class="o">==</span> <span class="n">TK_IDENT</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">Node</span><span class="o">*</span> <span class="n">node</span> <span class="o">=</span> <span class="n">new_var_node</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="n">tok</span><span class="o">-&gt;</span><span class="n">loc</span><span class="p">));</span>
    <span class="o">*</span><span class="n">rest</span> <span class="o">=</span> <span class="n">tok</span><span class="o">-&gt;</span><span class="n">next</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">node</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="k">if</span><span class="p">(</span><span class="n">tok</span><span class="o">-&gt;</span><span class="n">kind</span>  <span class="o">==</span> <span class="n">TK_NUM</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">Node</span><span class="o">*</span> <span class="n">node</span> <span class="o">=</span> <span class="n">new_num</span><span class="p">(</span><span class="n">tok</span><span class="o">-&gt;</span><span class="n">val</span><span class="p">);</span>
    <span class="o">*</span><span class="n">rest</span> <span class="o">=</span> <span class="n">tok</span><span class="o">-&gt;</span><span class="n">next</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">node</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">error_tok</span><span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="s">"expected an expression"</span><span class="p">);</span>

<span class="p">}</span>
</code></pre></div></div> <h3 id="codegen">Codegen</h3> <p>Add two new node types.</p> <ol> <li><code class="language-plaintext highlighter-rouge">ND_VAR</code> for loading memory address of variable.</li> <li><code class="language-plaintext highlighter-rouge">ND_ASSIGN</code> for get the value of right hand side expression and assign the value to memory address of the left hand side variable.</li> </ol> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">static</span> <span class="kt">void</span> <span class="nf">gen_expr</span><span class="p">(</span><span class="n">Node</span><span class="o">*</span> <span class="n">node</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">switch</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">kind</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">case</span> <span class="n">ND_NUM</span><span class="p">:</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">" mov $%d, %%rax</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">node</span><span class="o">-&gt;</span><span class="n">val</span><span class="p">);</span>
    <span class="k">return</span><span class="p">;</span>

    <span class="k">case</span> <span class="n">ND_NEG</span><span class="p">:</span>
    <span class="n">gen_expr</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">lhs</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">" neg %%rax</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="k">return</span><span class="p">;</span>

    <span class="k">case</span> <span class="n">ND_VAR</span><span class="p">:</span>
    <span class="n">gen_addr</span><span class="p">(</span><span class="n">node</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"  mov (%%rax), %%rax</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="k">return</span><span class="p">;;</span>

    <span class="k">case</span> <span class="n">ND_ASSIGN</span><span class="p">:</span>
    <span class="n">gen_addr</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">lhs</span><span class="p">);</span>
    <span class="n">push</span><span class="p">();</span>
    <span class="n">gen_expr</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">rhs</span><span class="p">);</span>
    <span class="n">pop</span><span class="p">(</span><span class="s">"%rdi"</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"  mov %%rax, (%%rdi)</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="k">return</span><span class="p">;</span>
  <span class="p">}</span>

</code></pre></div></div> <p>Only use stack memory to store value of variable. Each single letter variable takes 8 bytes memory space.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">static</span> <span class="kt">void</span> <span class="nf">gen_addr</span><span class="p">(</span><span class="n">Node</span><span class="o">*</span> <span class="n">node</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">if</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">kind</span> <span class="o">==</span> <span class="n">ND_VAR</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">offset</span> <span class="o">=</span> <span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">name</span> <span class="o">-</span> <span class="sc">'a'</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="mi">8</span><span class="p">;</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"  lea %d(%%rbp), %%rax</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="o">-</span><span class="n">offset</span><span class="p">);</span>
    <span class="k">return</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">error</span><span class="p">(</span><span class="s">"not an lvalue"</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="compiler"/><category term="c"/><category term="compiler"/><summary type="html"><![CDATA[Add single letter identity in c compiler Need to allocate memory address for single letter variable.]]></summary></entry><entry><title type="html">C compiler - parse example walkthrough</title><link href="https://bilyz98.github.io/blog/2024/statement-and-comparison/" rel="alternate" type="text/html" title="C compiler - parse example walkthrough"/><published>2024-10-14T11:59:00+00:00</published><updated>2024-10-14T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/statement-and-comparison</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/statement-and-comparison/"><![CDATA[<h2 id="abstract-syntax-tree-generation-example">Abstract syntax tree generation example</h2> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"5+20-4;"
</code></pre></div></div> <pre><code class="language-asm">  .globl main
main: 
 mov $4, %rax
 push %rax
 mov $20, %rax
 push %rax
 mov $5, %rax
 pop %rdi
 add %rdi, %rax
 pop %rdi
 sub %rdi, %rax
  ret
</code></pre> <p>The parse tree looks like this</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     â”€  
   /  \ 
  +    4
/  \    
5  20
</code></pre></div></div> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">static</span> <span class="kt">void</span> <span class="nf">gen_expr</span><span class="p">(</span><span class="n">Node</span><span class="o">*</span> <span class="n">node</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">switch</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">kind</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">case</span> <span class="n">ND_NUM</span><span class="p">:</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">" mov $%d, %%rax</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">node</span><span class="o">-&gt;</span><span class="n">val</span><span class="p">);</span>
    <span class="k">return</span><span class="p">;</span>

    <span class="k">case</span> <span class="n">ND_NEG</span><span class="p">:</span>
    <span class="n">gen_expr</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">lhs</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">" neg %%rax</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="k">return</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">gen_expr</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">rhs</span><span class="p">);</span>
  <span class="n">push</span><span class="p">();</span>
  <span class="n">gen_expr</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">lhs</span><span class="p">);</span>
  <span class="n">pop</span><span class="p">(</span><span class="s">"%rdi"</span><span class="p">);</span>

  <span class="k">switch</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">kind</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">case</span> <span class="n">ND_ADD</span><span class="p">:</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">" add %%rdi, %%rax</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="k">return</span><span class="p">;</span>
    
    <span class="k">case</span> <span class="n">ND_SUB</span><span class="p">:</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">" sub %%rdi, %%rax</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="k">return</span><span class="p">;</span>


</code></pre></div></div>]]></content><author><name></name></author><category term="compiler"/><category term="c"/><category term="compiler"/><summary type="html"><![CDATA[Abstract syntax tree generation example "5+20-4;"]]></summary></entry><entry><title type="html">Linux get cpu time and wall clock time</title><link href="https://bilyz98.github.io/blog/2024/get-function-cpu-time/" rel="alternate" type="text/html" title="Linux get cpu time and wall clock time"/><published>2024-10-13T11:59:00+00:00</published><updated>2024-10-13T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/get-function-cpu-time</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/get-function-cpu-time/"><![CDATA[<h2 id="difference-between-wall-clock-time-and-cpu-time">Difference between wall clock time and cpu time</h2> <p>The difference between CPU time and system clock time (also known as wall-clock time) is an important concept in performance measurement:</p> <p><strong>CPU Time:</strong></p> <ul> <li><strong>User CPU Time</strong>: The amount of time the CPU spends executing code in user mode, outside the kernel.</li> <li><strong>System CPU Time</strong>: The amount of time the CPU spends executing code in kernel mode, on behalf of the process.</li> <li><strong>Total CPU Time</strong>: The sum of user and system CPU time, representing the total time the CPU was actively working on a specific process.</li> </ul> <p><strong>System Clock Time (Wall-Clock Time):</strong></p> <ul> <li>This is the real-world elapsed time from the start to the end of a process, as if measured by a stopwatch.</li> <li>It includes all time, including time spent waiting for I/O operations, network responses, or other processes to complete.</li> </ul> <p><strong>Key Differences:</strong></p> <ul> <li><strong>CPU time</strong> only accounts for the time the CPU is actively working on a task, while <strong>wall-clock time</strong> includes all waiting periods.</li> <li><strong>Wall-clock time</strong> is always greater than or equal to <strong>CPU time</strong> for a single-threaded process.</li> <li>For multi-threaded processes, <strong>CPU time</strong> can exceed <strong>wall-clock time</strong> if multiple threads are running in parallel on multiple CPU cores.</li> </ul> <p><strong>Example:</strong> If a program takes 2 seconds of CPU time but 5 seconds of wall-clock time, it means the program was waiting for 3 seconds (e.g., for I/O operations or network responses).</p> <p>Understanding these differences can help identify performance bottlenecks. If CPU time is close to wall-clock time, the process is CPU-bound. If wall-clock time is significantly higher, the process is likely I/O-bound or waiting on other resources.</p> <h2 id="get-cpu-time-in-rocksdb">Get cpu time in rocksdb</h2> <p>https://github.com/BilyZ98/rocksdb_kv_sep/blob/8a5f06aef1d74d4dace2ffdcd2f07b90ddcff083/db/flush_job.cc#L697</p> <p>Wall clock time: <code class="language-plaintext highlighter-rouge">CLOCK_MONOTONIC</code> is used to get wall clock time</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="kt">uint64_t</span> <span class="n">NowNanos</span><span class="p">()</span> <span class="k">override</span> <span class="p">{</span>
<span class="cp">#if defined(OS_LINUX) || defined(OS_FREEBSD) || defined(OS_GNU_KFREEBSD) || \
    defined(OS_AIX)
</span>    <span class="k">struct</span> <span class="nc">timespec</span> <span class="n">ts</span><span class="p">;</span>
    <span class="n">clock_gettime</span><span class="p">(</span><span class="n">CLOCK_MONOTONIC</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">ts</span><span class="p">);</span>
    <span class="k">return</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">uint64_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">ts</span><span class="p">.</span><span class="n">tv_sec</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000000000</span> <span class="o">+</span> <span class="n">ts</span><span class="p">.</span><span class="n">tv_nsec</span><span class="p">;</span>
<span class="cp">#elif defined(OS_SOLARIS)
</span>    <span class="k">return</span> <span class="n">gethrtime</span><span class="p">();</span>
<span class="cp">#elif defined(__MACH__)
</span>    <span class="n">clock_serv_t</span> <span class="n">cclock</span><span class="p">;</span>
    <span class="n">mach_timespec_t</span> <span class="n">ts</span><span class="p">;</span>
    <span class="n">host_get_clock_service</span><span class="p">(</span><span class="n">mach_host_self</span><span class="p">(),</span> <span class="n">CALENDAR_CLOCK</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">cclock</span><span class="p">);</span>
    <span class="n">clock_get_time</span><span class="p">(</span><span class="n">cclock</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">ts</span><span class="p">);</span>
    <span class="n">mach_port_deallocate</span><span class="p">(</span><span class="n">mach_task_self</span><span class="p">(),</span> <span class="n">cclock</span><span class="p">);</span>
    <span class="k">return</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">uint64_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">ts</span><span class="p">.</span><span class="n">tv_sec</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000000000</span> <span class="o">+</span> <span class="n">ts</span><span class="p">.</span><span class="n">tv_nsec</span><span class="p">;</span>
<span class="cp">#else
</span>    <span class="k">return</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration_cast</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">nanoseconds</span><span class="o">&gt;</span><span class="p">(</span>
               <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">steady_clock</span><span class="o">::</span><span class="n">now</span><span class="p">().</span><span class="n">time_since_epoch</span><span class="p">())</span>
        <span class="p">.</span><span class="n">count</span><span class="p">();</span>
<span class="cp">#endif
</span>  <span class="p">}</span>
</code></pre></div></div> <p>CPU time: <code class="language-plaintext highlighter-rouge">CLOCK_THREAD_CPUTIME_ID</code> is used to get cpu time</p> <p>https://github.com/BilyZ98/rocksdb_kv_sep/blob/8a5f06aef1d74d4dace2ffdcd2f07b90ddcff083/env/env_posix.cc#L164</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="kt">uint64_t</span> <span class="n">CPUMicros</span><span class="p">()</span> <span class="k">override</span> <span class="p">{</span>
<span class="cp">#if defined(OS_LINUX) || defined(OS_FREEBSD) || defined(OS_GNU_KFREEBSD) || \
    defined(OS_AIX) || (defined(__MACH__) &amp;&amp; defined(__MAC_10_12))
</span>    <span class="k">struct</span> <span class="nc">timespec</span> <span class="n">ts</span><span class="p">;</span>
    <span class="n">clock_gettime</span><span class="p">(</span><span class="n">CLOCK_THREAD_CPUTIME_ID</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">ts</span><span class="p">);</span>
    <span class="k">return</span> <span class="p">(</span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">uint64_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">ts</span><span class="p">.</span><span class="n">tv_sec</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000000000</span> <span class="o">+</span> <span class="n">ts</span><span class="p">.</span><span class="n">tv_nsec</span><span class="p">)</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">;</span>
<span class="cp">#endif
</span>    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
  <span class="p">}</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="os"/><category term="c"/><category term="linux"/><summary type="html"><![CDATA[Difference between wall clock time and cpu time The difference between CPU time and system clock time (also known as wall-clock time) is an important concept in performance measurement:]]></summary></entry><entry><title type="html">Simple c compiler unary</title><link href="https://bilyz98.github.io/blog/2024/chibicc-unary/" rel="alternate" type="text/html" title="Simple c compiler unary"/><published>2024-10-10T11:59:00+00:00</published><updated>2024-10-10T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/chibicc-unary</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/chibicc-unary/"><![CDATA[<h2 id="add-unary-to-parser">Add unary to parser</h2> <p><a href="./2024-10-12-chibicc-gen-expr.md">Previous parser post</a></p> <p>Add unary symbol in mul. Add unary node kind and replace primary with unary. unary is a super set of unary and primary.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// expr = unary ("*" unary | "/" unary)*</span>
<span class="k">static</span> <span class="n">Node</span><span class="o">*</span> <span class="nf">mul</span><span class="p">(</span><span class="n">Token</span><span class="o">**</span><span class="n">rest</span><span class="p">,</span> <span class="n">Token</span><span class="o">*</span> <span class="n">tok</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">Node</span><span class="o">*</span> <span class="n">node</span> <span class="o">=</span> <span class="n">unary</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tok</span><span class="p">,</span> <span class="n">tok</span><span class="p">);</span>

  <span class="k">for</span><span class="p">(;;)</span> <span class="p">{</span>
    <span class="k">if</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="s">"*"</span><span class="p">))</span> <span class="p">{</span>
      <span class="n">node</span> <span class="o">=</span>  <span class="n">new_binary</span><span class="p">(</span><span class="n">ND_MUL</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">unary</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tok</span><span class="p">,</span> <span class="n">tok</span><span class="o">-&gt;</span><span class="n">next</span><span class="p">));</span>
      <span class="k">continue</span><span class="p">;;</span>
    <span class="p">}</span>

    <span class="k">if</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="s">"/"</span><span class="p">))</span> <span class="p">{</span>
      <span class="n">node</span> <span class="o">=</span> <span class="n">new_binary</span><span class="p">(</span><span class="n">ND_DIV</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">unary</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tok</span><span class="p">,</span> <span class="n">tok</span><span class="o">-&gt;</span><span class="n">next</span><span class="p">));</span>
      <span class="k">continue</span><span class="p">;;</span>
    <span class="p">}</span>

    <span class="o">*</span><span class="n">rest</span> <span class="o">=</span> <span class="n">tok</span><span class="p">;</span>
    <span class="k">return</span> <span class="n">node</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span>


<span class="c1">// unary = ("+" | "-") unary | primary</span>
<span class="k">static</span> <span class="n">Node</span><span class="o">*</span> <span class="nf">unary</span><span class="p">(</span><span class="n">Token</span> <span class="o">**</span><span class="n">rest</span><span class="p">,</span> <span class="n">Token</span><span class="o">*</span> <span class="n">tok</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">if</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="s">"+"</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">unary</span><span class="p">(</span><span class="n">rest</span><span class="p">,</span> <span class="n">tok</span><span class="o">-&gt;</span><span class="n">next</span><span class="p">);</span>

  <span class="k">if</span><span class="p">(</span><span class="n">equal</span><span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="s">"-"</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">new_unary</span><span class="p">(</span><span class="n">ND_NEG</span><span class="p">,</span> <span class="n">unary</span><span class="p">(</span><span class="n">rest</span><span class="p">,</span> <span class="n">tok</span><span class="o">-&gt;</span><span class="n">next</span><span class="p">));</span>

  <span class="k">return</span> <span class="n">primary</span><span class="p">(</span><span class="n">rest</span><span class="p">,</span> <span class="n">tok</span><span class="p">);</span>

<span class="p">}</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="compiler"/><category term="c"/><category term="compiler"/><summary type="html"><![CDATA[Add unary to parser Previous parser post]]></summary></entry></feed>