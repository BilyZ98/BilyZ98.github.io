<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://bilyz98.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://bilyz98.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-06-19T14:06:45+00:00</updated><id>https://bilyz98.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Basic digital electronic</title><link href="https://bilyz98.github.io/blog/2024/digital-electronic/" rel="alternate" type="text/html" title="Basic digital electronic"/><published>2024-06-17T11:59:00+00:00</published><updated>2024-06-17T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/digital-electronic</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/digital-electronic/"><![CDATA[<h2 id="basic-digital">Basic digital</h2> <p>Transistor to ALU <a href="https://youtu.be/HjneAhCy2N4?si=OpouvGQDJhw4sSKE">https://youtu.be/HjneAhCy2N4?si=OpouvGQDJhw4sSKE</a></p> <p>Transistor to memory <a href="https://youtu.be/rM9BjciBLmg?si=TQe2Wijej4iezyzV">https://youtu.be/rM9BjciBLmg?si=TQe2Wijej4iezyzV</a></p>]]></content><author><name></name></author><category term="ml-fundamental"/><category term="transistor"/><summary type="html"><![CDATA[transistor]]></summary></entry><entry><title type="html">llm.c</title><link href="https://bilyz98.github.io/blog/2024/llm-c/" rel="alternate" type="text/html" title="llm.c"/><published>2024-06-17T11:59:00+00:00</published><updated>2024-06-17T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/llm-c</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/llm-c/"><![CDATA[<p>roadmap</p> <ul class="task-list"> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Running llm.c</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Running llm.c with cuda</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Inference with fp16</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>Inference with vllm</li> <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled"/>try other inference acceleartion tech</li> </ul> <h2 id="running-llmc">Running llm.c</h2> <p><a href="https://github.com/karpathy/llm.c">https://github.com/karpathy/llm.c</a></p> <h3 id="gpu">GPU</h3> <p>Had issue running gpu There is only cuda 11.2 on my machine but torch 2.1.0 is installed which requires cuda 12.0</p> <p>Solution: Manually specify torch==1.3.1</p> <p>Get error</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>yhrun <span class="nt">-n</span> 4 <span class="nt">-p</span> gpu_v100 python train_gpt2.py
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Traceback (most recent call last):
  File "train_gpt2.py", line 24, in &lt;module&gt;
    from contextlib import nullcontext
ImportError: cannot import name 'nullcontext'
Traceback (most recent call last):
  File "train_gpt2.py", line 24, in &lt;module&gt;
    from contextlib import nullcontext
ImportError: cannot import name 'nullcontext'
Traceback (most recent call last):
  File "train_gpt2.py", line 24, in &lt;module&gt;
    from contextlib import nullcontext
ImportError: cannot import name 'nullcontext'
Traceback (most recent call last):
  File "train_gpt2.py", line 24, in &lt;module&gt;
    from contextlib import nullcontext
ImportError: cannot import name 'nullcontext'
yhrun: error: gpu55: tasks 0-3: Exited with exit code 1
</code></pre></div></div> <p>The issue is that nullcontext is introduced in python &gt;=3.7 So I need to upgrade python version</p> <p>Still can not solve problem above because I can’t not import new module to existing module list.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Currently Loaded Modulefiles:
 1) proxy/1.0   2) CUDA/10.0   3) cudnn/7.6.4-CUDA10.0   4) PyTorch/1.2.0-CUDA10.0-py3.6

 $ yhrun -n 4 -p gpu_v100 python train_gpt2.py
Traceback (most recent call last):
  File "train_gpt2.py", line 24, in &lt;module&gt;
    from contextlib import nullcontext
ImportError: cannot import name 'nullcontext'
Traceback (most recent call last):
  File "train_gpt2.py", line 24, in &lt;module&gt;
    from contextlib import nullcontext
ImportError: cannot import name 'nullcontext'
Traceback (most recent call last):
  File "train_gpt2.py", line 24, in &lt;module&gt;
    from contextlib import nullcontext
ImportError: cannot import name 'nullcontext'
Traceback (most recent call last):
  File "train_gpt2.py", line 24, in &lt;module&gt;
    from contextlib import nullcontext
ImportError: cannot import name 'nullcontext'
</code></pre></div></div> <p>My friend told me that I can just use conda to create new namespace and then I can ssh to the compute node and activate the conda environment. And then I can run training process.</p> <p>This means that compute node shares the same file system with login node. But the operating system is different. Because each node has its own hostname.</p> <p>Learn new thing every day.</p> <p>Here’s all available nodes I have.</p> <p>Karpathy has updated gpt2 parameter download script so now I can download parameter via shell script</p> <p>Issue: Can not connect to huggingface todownload pretrained model via proxy</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(llmc) [nsccgz_qylin_1@ln102%tianhe2-K llm.c]$ curl -v https://huggingface.co
* About to connect() to proxy 10.20.18.21 port 3128 (#0)
*   Trying 10.20.18.21...
* Connected to 10.20.18.21 (10.20.18.21) port 3128 (#0)
* Establish HTTP proxy tunnel to huggingface.co:443
&gt; CONNECT huggingface.co:443 HTTP/1.1
&gt; Host: huggingface.co:443
&gt; User-Agent: curl/7.29.0
&gt; Proxy-Connection: Keep-Alive
&gt;
&lt; HTTP/1.1 503 Service Unavailable
&lt; Proxy-Agent: gost/2.11.1
&lt; Content-Length: 0
&lt;
* Received HTTP code 503 from proxy after CONNECT
* Connection #0 to host 10.20.18.21 left intact
curl: (56) Received HTTP code 503 from proxy after CONNECT
</code></pre></div></div> <p>Solution: I decide to download on my local laptop and then upload these model parameter files to gpu nodes.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">chmod </span>u+x ./dev/download_starter_pack.sh
./dev/download_starter_pack.sh
make train_gpt2fp32cu
./train_gpt2fp32cu
</code></pre></div></div> <p>cuda env:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Currently Loaded Modulefiles:
 1) proxy/1.0   2) python/3.6.7_anaconda3   3) CUDA/11.2   4) gmp/4.2.4   5) mpfr/2.4.2   6) mpc/0.8.1   7) gcc/9.2.0
</code></pre></div></div> <p>Output :</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>step   61/74: train loss 3.213066 (312.014672 ms, 13127 tok/s)
step   62/74: train loss 3.450736 (314.262273 ms, 13033 tok/s)
step   63/74: train loss 3.370245 (315.130342 ms, 12997 tok/s)
step   64/74: train loss 3.407992 (316.778140 ms, 12930 tok/s)
step   65/74: train loss 3.580323 (315.324538 ms, 12989 tok/s)
step   66/74: train loss 3.029552 (317.274858 ms, 12909 tok/s)
step   67/74: train loss 3.296448 (317.588671 ms, 12897 tok/s)
step   68/74: train loss 3.675703 (314.929981 ms, 13006 tok/s)
step   69/74: train loss 3.297087 (313.282229 ms, 13074 tok/s)
step   70/74: train loss 3.646337 (315.271277 ms, 12991 tok/s)
step   71/74: train loss 3.566427 (316.123225 ms, 12956 tok/s)
step   72/74: train loss 3.732521 (315.446478 ms, 12984 tok/s)
step   73/74: train loss 3.825229 (318.325142 ms, 12867 tok/s)
step   74/74: train loss 3.380326 (318.066751 ms, 12877 tok/s)
val loss 3.491223
generating:
---
BUCKINGHAM:
But of my penitent ambition
Rome Slicom against Reimy, justice about him!
In case the witness should speak with joy:
Shall now that by these dwelling House,
Suspicions are declaim'd of the Albanian king.
Go
---
total average iteration time: 312.354733 ms
</code></pre></div></div> <h3 id="cpu">CPU</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt
python dev/data/tinyshakespeare.py
python train_gpt2.py
make train_gpt2
<span class="nv">OMP_NUM_THREADS</span><span class="o">=</span>8 ./train_gpt2
</code></pre></div></div> <p>Output</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>step 20: train loss 4.527330 (took 2636.617334 ms)
step 21: train loss 4.065797 (took 2701.692621 ms)
step 22: train loss 3.965316 (took 2681.297241 ms)
step 23: train loss 3.449409 (took 2650.111416 ms)
step 24: train loss 4.490954 (took 2637.116332 ms)
step 25: train loss 4.035361 (took 2659.843151 ms)
step 26: train loss 3.445302 (took 2652.557792 ms)
step 27: train loss 3.993789 (took 2649.868369 ms)
step 28: train loss 4.199468 (took 2638.095098 ms)
step 29: train loss 4.538460 (took 2669.385015 ms)
val loss 4.350866
step 30: train loss 4.306292 (took 2658.306411 ms)
step 31: train loss 4.851407 (took 2634.616368 ms)
step 32: train loss 4.577479 (took 2670.470130 ms)
step 33: train loss 4.124943 (took 2660.545565 ms)
step 34: train loss 4.330319 (took 2669.532886 ms)
step 35: train loss 3.399416 (took 2639.378693 ms)
step 36: train loss 3.661207 (took 2632.377219 ms)
step 37: train loss 3.330453 (took 2637.114896 ms)
step 38: train loss 3.567853 (took 2645.744510 ms)
step 39: train loss 3.902004 (took 2635.939546 ms)
val loss 4.319361
generating:
---
EditBOOK IX:
Under the boasted sute of Georges:
So lordly is the prize had sin is high;
Hell is the way to God: frankish friends from blessed daughters
To Bermuda have heard the saying,
Then how to place the artscape.
Strong should a bellow
---
step 40: train loss 3.952987 (took 2665.948189 ms)
</code></pre></div></div> <p>Some questions? How many low end gpus are there in the market? I am thinking about utilizing low end gpus to train model, large or small model.</p>]]></content><author><name></name></author><category term="ml"/><category term="ml"/><category term="ai"/><category term="cuda"/><summary type="html"><![CDATA[llm minikune]]></summary></entry><entry><title type="html">K8s Advance</title><link href="https://bilyz98.github.io/blog/2024/k8s-advance/" rel="alternate" type="text/html" title="K8s Advance"/><published>2024-06-16T11:59:00+00:00</published><updated>2024-06-16T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/k8s-advance</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/k8s-advance/"><![CDATA[<h2 id="kubectl-inspect-volume-content"><code class="language-plaintext highlighter-rouge">kubectl</code> inspect volume content</h2> <p><a href="https://stackoverflow.com/questions/49529005/how-to-inspect-the-content-of-persistent-volume-by-kubernetes-on-azure-cloud-ser">https://stackoverflow.com/questions/49529005/how-to-inspect-the-content-of-persistent-volume-by-kubernetes-on-azure-cloud-ser</a></p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: pvc-inspector
spec:
  containers:
  - image: busybox
    name: pvc-inspector
    command: ["tail"]
    args: ["-f", "/dev/null"]
    volumeMounts:
    - mountPath: /pvc
      name: pvc-mount
  volumes:
  - name: pvc-mount
    persistentVolumeClaim:
      claimName: YOUR_CLAIM_NAME_HERE
</span><span class="no">EOF
</span></code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl exec -it pvc-inspector -- sh
$ ls /pvc
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl delete pod pvc-inspector
</code></pre></div></div>]]></content><author><name></name></author><category term="cloud"/><category term="cloud"/><category term="k8s"/><summary type="html"><![CDATA[k8s minikune]]></summary></entry><entry><title type="html">Difference between Dockerfile and Docker Compose</title><link href="https://bilyz98.github.io/blog/2024/difference-between-dockerfile-and-docker-compose/" rel="alternate" type="text/html" title="Difference between Dockerfile and Docker Compose"/><published>2024-06-16T07:31:03+00:00</published><updated>2024-06-16T07:31:03+00:00</updated><id>https://bilyz98.github.io/blog/2024/difference-between-dockerfile-and-docker-compose</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/difference-between-dockerfile-and-docker-compose/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">Docker Rocksdb build</title><link href="https://bilyz98.github.io/blog/2024/docker-rocksdb-build/" rel="alternate" type="text/html" title="Docker Rocksdb build"/><published>2024-06-16T07:29:37+00:00</published><updated>2024-06-16T07:29:37+00:00</updated><id>https://bilyz98.github.io/blog/2024/docker-rocksdb-build</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/docker-rocksdb-build/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">K3s beginner</title><link href="https://bilyz98.github.io/blog/2024/k3s/" rel="alternate" type="text/html" title="K3s beginner"/><published>2024-06-14T11:59:00+00:00</published><updated>2024-06-14T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/k3s</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/k3s/"><![CDATA[<h2 id="whats-k3s-and-why-we-need-it-">What’s K3s and why we need it ?</h2> <p>K3s is a lightweight distribution of k8s to make k8s accessible in resource-constrained environments. Advantages of k3s:</p> <ol> <li>Size and efficiency</li> <li>Easy to install</li> <li>Some built-in tools</li> </ol> <h2 id="install">Install</h2> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-sfL</span> https://get.k3s.io | sh -
</code></pre></div></div> <p>Check k3s process status</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> systemctl status k3s.service
</code></pre></div></div> <p>Got this issue <code class="language-plaintext highlighter-rouge">FATA[0000] starting kubernetes: preparing server: init cluster datastore and https: listen tcp :6443: bind: address already in use</code> Solutions:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo lsof -i :6443 
sudo kill -9 $(sudo lsof -t -i:6443)

sudo kill -9 &lt;PID&gt;
sudo systemctl restart k3s
</code></pre></div></div> <p>Issue: Not able to get k3s cluster status.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> kubectl get all -n kube-system

E0616 16:26:56.936188 1761783 memcache.go:265] couldn't get current server API group list: Get "https://192.168.49.2:8443/api?timeout=32s": dial tcp 192.168.49.2:8443: connect: no route to host
E0616 16:27:00.007979 1761783 memcache.go:265] couldn't get current server API group list: Get "https://192.168.49.2:8443/api?timeout=32s": dial tcp 192.168.49.2:8443: connect: no route to host
E0616 16:27:03.080047 1761783 memcache.go:265] couldn't get current server API group list: Get "https://192.168.49.2:8443/api?timeout=32s": dial tcp 192.168.49.2:8443: connect: no route to host
</code></pre></div></div> <p>I have install k8s on this node before. So I think the issue is that I do not copy the k3s config to <code class="language-plaintext highlighter-rouge">.kube</code> folder. Tried that</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Copy K3s kubeconfig to ~/.kube/config</span>
<span class="nb">sudo cp</span> /etc/rancher/k3s/k3s.yaml ~/.kube/config

<span class="c"># Change the owner of the config file to the current user</span>
<span class="nb">sudo chown</span> <span class="nv">$USER</span> ~/.kube/config

 kubectl get all <span class="nt">-n</span> kube-system
</code></pre></div></div> <p>Now I am able to get k3s cluster status.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME                                          READY   STATUS      RESTARTS   AGE
pod/coredns-6799fbcd5-2s8tn                   1/1     Running     0          46m
pod/local-path-provisioner-6c86858495-sfghq   1/1     Running     0          46m
pod/helm-install-traefik-crd-22tc9            0/1     Completed   0          46m
pod/helm-install-traefik-976dn                0/1     Completed   1          46m
pod/metrics-server-54fd9b65b-g5k5z            1/1     Running     0          46m
pod/svclb-traefik-ee33812d-mvwjp              2/2     Running     0          45m
pod/traefik-7d5f6474df-fjdgf                  1/1     Running     0          45m

NAME                     TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)                      AGE
service/kube-dns         ClusterIP      10.43.0.10     &lt;none&gt;        53/UDP,53/TCP,9153/TCP       46m
service/metrics-server   ClusterIP      10.43.199.96   &lt;none&gt;        443/TCP                      46m
service/traefik          LoadBalancer   10.43.62.153   28.10.10.62   80:30148/TCP,443:30314/TCP   45m
</code></pre></div></div> <p>Check this article to know more about installing k3s on ubuntu <a href="https://www.digitalocean.com/community/tutorials/how-to-setup-k3s-kubernetes-cluster-on-ubuntu">https://www.digitalocean.com/community/tutorials/how-to-setup-k3s-kubernetes-cluster-on-ubuntu</a></p> <h2 id="k3s-use-local-docker-image">K3s use local docker image</h2> <p>If you have a Docker image on your local machine and you want to use it in a Kubernetes cluster, you can follow these steps:</p> <ol> <li> <p><strong>Tag your image</strong>: Tag the Docker image with a version number. For example, if your image is named <code class="language-plaintext highlighter-rouge">my-image</code> and you want to tag it as <code class="language-plaintext highlighter-rouge">v1</code>, you can use the following command:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> docker tag my-image:latest my-image:v1
</code></pre></div> </div> </li> <li> <p><strong>Load the image into your nodes</strong>: If you’re using Minikube, you can use the <code class="language-plaintext highlighter-rouge">minikube docker-env</code> command to configure your current shell to use Minikube’s Docker daemon, then use <code class="language-plaintext highlighter-rouge">docker save</code> and <code class="language-plaintext highlighter-rouge">docker load</code> to move your image. If you’re using K3s, you can load the image directly into the K3s nodes using <code class="language-plaintext highlighter-rouge">ctr</code>:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> docker save my-image:v1 | ctr <span class="nt">-n</span> k8s.io images import -
</code></pre></div> </div> </li> <li> <p><strong>Use the image in Kubernetes</strong>: Now you can use your image in a Kubernetes pod. Here’s an example of a pod specification:</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
 <span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
 <span class="na">metadata</span><span class="pi">:</span>
   <span class="na">name</span><span class="pi">:</span> <span class="s">my-pod</span>
 <span class="na">spec</span><span class="pi">:</span>
   <span class="na">containers</span><span class="pi">:</span>
   <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">my-container</span>
     <span class="na">image</span><span class="pi">:</span> <span class="s">my-image:v1</span>
</code></pre></div> </div> </li> </ol> <p>Remember to replace <code class="language-plaintext highlighter-rouge">my-image:v1</code> with your actual image name and tag.</p> <h2 id="difference-between-deployment-and-pod">Difference between Deployment and Pod</h2> <p>A Pod is a group of one or more containers, with shared storage/network resources, and a specification for how to run the containers. A Pod’s contents are always co-located and co-scheduled, and run in a shared context. A basic pod definition for running a single container of nginx</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">nginx-pod</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">containers</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">nginx-container</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">nginx:1.14.2</span>
</code></pre></div></div> <p>A Deployment is a higher-level concept that manages Pods and provides declarative updates to Pods along with a lot of other useful features. Therefore, a Deployment is a higher-level concept that manages ReplicaSets and Pods. A basic deployment configution</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiversion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">nginx-deployment</span>
    <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">nginx</span>
<span class="na">spec</span><span class="pi">:</span>
    <span class="na">replicas</span><span class="pi">:</span> <span class="m">2</span>
    <span class="na">selector</span><span class="pi">:</span>
        <span class="na">matchLabels</span><span class="pi">:</span>
            <span class="na">app</span><span class="pi">:</span> <span class="s">nginx</span>
    <span class="na">template</span><span class="pi">:</span>
        <span class="na">metadata</span><span class="pi">:</span>
            <span class="na">labels</span><span class="pi">:</span>
                <span class="na">app</span><span class="pi">:</span> <span class="s">nginx</span>
        <span class="na">spec</span><span class="pi">:</span>
            <span class="na">containers</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">nginx-container</span>
            <span class="na">image</span><span class="pi">:</span> <span class="s">nginx:1.14.2</span>
            <span class="na">ports</span><span class="pi">:</span>
                <span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">80</span>
</code></pre></div></div> <p>Deployments wrap pod definition, providing additional management layer. Pods reqquire manual updates and intervention for deploying and scaling Deployments enable automatic updates, rollbacks and scaling.</p> <p>Issue: Still could not pull image from local</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Events:
  Type     Reason     Age   From               Message
  ----     ------     ----  ----               -------
  Normal   Scheduled  2s    default-scheduler  Successfully assigned default/rocksdb-74cc66c9d6-fhsz5 to common-testbed
  Normal   Pulling    2s    kubelet            Pulling image "docker.io/rocksdb:v1"
  Warning  Failed     0s    kubelet            Failed to pull image "docker.io/rocksdb:v1": failed to pull and unpack image "docker.io/library/rocksdb:v1": failed to resolve reference "docker.io/library/rocksdb:v1": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed
  Warning  Failed     0s    kubelet            Error: ErrImagePull
</code></pre></div></div> <p>Solution: Try to push image to docker.io and pull from it. Sure, here’s a basic example of how you can push a Docker image to Docker Hub (docker.io) and then use that image in a Kubernetes deployment YAML file.</p> <p>First, you need to tag your Docker image with the Docker Hub username and repository name:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker tag local-image:tag yourusername/yourrepository:tag
</code></pre></div></div> <p>Then, you can push the Docker image to Docker Hub:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker push yourusername/yourrepository:tag
</code></pre></div></div> <p>After pushing the image to Docker Hub, you can use it in a Kubernetes deployment YAML file:</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">your-deployment</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">your-app</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">3</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">your-app</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">your-app</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">yourusername/yourrepository:tag</span>
        <span class="na">ports</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">8080</span>
</code></pre></div></div> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker tag rocksdb:latest zzt1234/test-rocksdb:v2
docker push zzt1234/test-rocksdb:v2
</code></pre></div></div> <p>In this YAML file, replace <code class="language-plaintext highlighter-rouge">yourusername/yourrepository:tag</code> with the Docker Hub username, repository name, and tag you used earlier. This will pull the image from Docker Hub and use it for the Kubernetes deployment.</p> <p>Please replace <code class="language-plaintext highlighter-rouge">yourusername</code>, <code class="language-plaintext highlighter-rouge">yourrepository</code>, <code class="language-plaintext highlighter-rouge">tag</code>, <code class="language-plaintext highlighter-rouge">your-deployment</code>, <code class="language-plaintext highlighter-rouge">your-app</code>, and <code class="language-plaintext highlighter-rouge">8080</code> with your actual values. Also, make sure you’re logged in to Docker Hub in the environment where you’re running these commands. You can do this using the <code class="language-plaintext highlighter-rouge">docker login</code> command.</p> <p>Remember to apply the deployment using <code class="language-plaintext highlighter-rouge">kubectl apply -f your-deployment.yaml</code>.</p> <p>Another issue: Still can not start container successfully. Want to check logs of container but failed to connect to it</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl logs rocksdb-57c5b55686-mnwvr rocksdb
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) ➜  docker git:(master) ✗ systemctl status kubelet
● kubelet.service - kubelet: The Kubernetes Node Agent
     Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled)
    Drop-In: /etc/systemd/system/kubelet.service.d
             └─10-kubeadm.conf
     Active: activating (auto-restart) (Result: exit-code) since Mon 2024-06-17 17:03:06 HKT; 5s ago
       Docs: https://kubernetes.io/docs/home/
    Process: 1458057 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS (code=exited, status&gt;   Main PID: 1458057 (code=exited, status=1/FAILURE)
</code></pre></div></div> <p>Not able</p> <p>Asked bingchat to give me solutions for how to solve this kubelet connection problem</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>journalctl -u kubelet
</code></pre></div></div> <p>Get this log output</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>May 12 02:49:40 common-testbed kubelet[3632]: E0512 02:49:40.413488    3632 controller.go:146] "Failed to ensure lease exists, will retry" err="leases.coordination.k8s&gt;May 12 02:49:44 common-testbed kubelet[3632]: I0512 02:49:44.813157    3632 kubelet_node_status.go:70] "Attempting to register node" node="common-testbed"
May 12 02:49:44 common-testbed kubelet[3632]: E0512 02:49:44.816687    3632 kubelet_node_status.go:92] "Unable to register node with API server" err="nodes \"common-te&gt;May 12 02:49:47 common-testbed kubelet[3632]: E0512 02:49:47.110624    3632 eviction_manager.go:258] "Eviction manager: failed to get summary stats" err="failed to get&gt;May 12 02:49:47 common-testbed kubelet[3632]: E0512 02:49:47.416828    3632 controller.go:146] "Failed to ensure lease exists, will retry" err="leases.coordination.k8s&gt;May 12 02:49:48 common-testbed kubelet[3632]: E0512 02:49:48.872385    3632 dns.go:153] "Nameserver limits exceeded" err="Nameserver limits were exceeded, some nameser&gt;May 12 02:49:50 common-testbed kubelet[3632]: E0512 02:49:50.873045    3632 dns.go:153] "Nameserver limits exceeded" err="Nameserver limits were exceeded, some nameser&gt;May 12 02:49:51 common-testbed kubelet[36
</code></pre></div></div> <p>So now I decide to restart kubelet service for k3s because this kubelet service was started for previous k8s cluster. I am not sure if there is any domain name issue with it. I don’t know how to solve this problem properly so I decided to reinstall kubelet service.</p> <p>Failed to execute kubectl command after replacing k3s.service file content new(not working):</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Unit]
Description=Lightweight Kubernetes
Documentation=https://k3s.io
After=network-online.target

[Service]
ExecStart=/usr/local/bin/k3s \
    server \
    --kubelet-arg='address=0.0.0.0' \
    --kubelet-arg='anonymous-auth=false' \
    --kubelet-arg='authentication-token-webhook=true' \
    --kubelet-arg='authorization-mode=Webhook' \
    --kubelet-arg='client-ca-file=/var/lib/rancher/k3s/server/tls/client-ca.crt' \
    --kubelet-arg='tls-cert-file=/var/lib/rancher/k3s/server/tls/kubelet.crt' \
    --kubelet-arg='tls-private-key-file=/var/lib/rancher/k3s/server/tls/kubelet.key'
KillMode=process
Delegate=yes
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity
TasksMax=infinity
Restart=always
RestartSec=5s

[Install]
WantedBy=multi-user.target

</code></pre></div></div> <p>old</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Unit]
Description=Lightweight Kubernetes
Documentation=https://k3s.io
Wants=network-online.target
After=network-online.target

[Install]
WantedBy=multi-user.target

[Service]
Type=notify
EnvironmentFile=-/etc/default/%N
EnvironmentFile=-/etc/sysconfig/%N
EnvironmentFile=-/etc/systemd/system/k3s.service.env
KillMode=process
Delegate=yes
# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=1048576
LimitNPROC=infinity
LimitCORE=infinity
TasksMax=infinity
TimeoutStartSec=0
Restart=always
RestartSec=5s
ExecStartPre=/bin/sh -xc '! /usr/bin/systemctl is-enabled --quiet nm-cloud-setup.service 2&gt;/dev/null'
ExecStartPre=-/sbin/modprobe br_netfilter
ExecStartPre=-/sbin/modprobe overlay
ExecStart=/usr/local/bin/k3s \
    server \
    --kubelet-arg='address=0.0.0.0' \
    --kubelet-arg='anonymous-auth=false' \
    --kubelet-arg='authentication-token-webhook=true' \
    --kubelet-arg='authorization-mode=Webhook' \
    --kubelet-arg='client-ca-file=/var/lib/rancher/k3s/server/tls/client-ca.crt' \
    --kubelet-arg='tls-cert-file=/var/lib/rancher/k3s/server/tls/kubelet.crt' \
    --kubelet-arg='tls-private-key-file=/var/lib/rancher/k3s/server/tls/kubelet.key'
</code></pre></div></div> <p>Got error port:6443 already in use Tried to delete all processes that use 6443 First, need to stop kubelet service because it uses 6443 port</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo systemctl stop kubelet
</code></pre></div></div> <p>Then check the process that uses 6443 port</p> <p>I found that there is obsolete content in kubelet starting file</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubel
sudo vim /etc/kubernetes/kubelet.conf

</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURCVENDQWUyZ0F3SUJBZ0lJSkFNTXZ6a0h3ZWN3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TXpFeU1qa3dPVEUxTXpGYUZ3MHpNekV5TWpZd09USXdNekZhTUJVeApFekFSQmdOVkJBTVRDbXQxWW1WeWJtVjBaWE13Z2dFaU1BMEdDU3FHU0liM0RRRUJBUVVBQTRJQkR3QXdnZ0VLCkFvSUJBUURiVWhXYlg1a241M0xLbHVDa2kzME96QUloR3ltVFdEdS9xZjlOUU1JcmtXdnoybUp6M2ptNHAzSFMKbllkY01RKytpL2FxVDN5MDNuSDhycXZ3ZFVRWnVsSS9xTXQreFdOTVg3V0NHR3lqOEhDY0JtdXdaT1A4WjE3dApBNVByNFRrM3VJOFNHMnJoRTBtTithMk5rQnVCZjNFRnR4NllPUnByKytneUtmMmxhQTlqV1A2cytML1plWi94CktYaFRicittclBPbTlXMXBxYnVwamJNNkJJUmROU0dYcWRiL0orcVRabDNQcStZZmtUaHJ6VjU3ZG9rOVBEWUEKMXd1MW8yZ3RMUTBISGcwb2R4V1ZyN2ZKenhNSXU0bWJ5ZGZiUTRPU2g2T2dDNzlNdFEvOGFtQ1hFTlJxK2RPaQo0TUhSQlNGZTh2K0FDMmQwY2NndjRkV1hURm1UQWdNQkFBR2pXVEJYTUE0R0ExVWREd0VCL3dRRUF3SUNwREFQCkJnTlZIUk1CQWY4RUJUQURBUUgvTUIwR0ExVWREZ1FXQkJSaEpoNUkvdys0c1diNjNlcXYycklqOEd2ekhEQVYKQmdOVkhSRUVEakFNZ2dwcmRXSmxjbTVsZEdWek1BMEdDU3FHU0liM0RRRUJDd1VBQTRJQkFRQUR2OWU4T2dRNAoybzBJeUg5OFg2aDI0TnIrbEQ3R1o3KzBDUzdYcnZsYWtrV1hwT3RLYmRVWDI5Y3BPZ2p4WHZLV2NqMzhtK0wxCmJwWUlRK3Q0bXh0SmFlZVJlT2FzcXJzZVBQbC9POFMxRTlxN2xGd2dNWWs4amc3SVFjeHU5QzJBNG5OOGgxeXQKdU1qWi9mUXlkUmdMSkhnYm15Vkw5NGtpZndSOWxJM0RZTExwM2dlYTQ4ejBFZ0ZpOERoVXkrZ1llVDk5dzZXaQp0YmtFNHRTZ05jZFNjS2ZFMDNvTnFrUXJ4dkJXc1lOZnlOS0dPclV1YTNVTjhqN2NRcHFOa0plRlhxTUhsT0sxCmtJbi9XOVl4UC9rWGx2UkIvZXFiTC9uVlYxeTg4SC9tWGFsNHlIZ1owckNOSm1SOW9vRHJsVS9aRWtpMWRZeEIKdzdhdjFMOFU2M1BaCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    server: https://28.10.10.62:6443
  name: kubernetes
contexts:
- context:
    cluster: kubernetes
    user: system:node:k8s-master
  name: system:node:k8s-master@kubernetes
current-context: system:node:k8s-master@kubernetes
kind: Config
preferences: {}
users:
- name: system:node:k8s-master
  user:
    client-certificate: /var/lib/kubelet/pki/kubelet-client-current.pem
    client-key: /var/lib/kubelet/pki/kubelet-client-current.pem
</code></pre></div></div> <p>So what I need to do now is to uninstall kubelet or clean config file. I don’t know the exact relationship between kubelet and k3s yet.</p> <p>I run this command to remove all existing service and clean config files</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo kubeadm reset --cleanup-tmp-dir -f --cri-socket=unix:///run/containerd/containerd.sock

[reset] Reading configuration from the cluster...
[reset] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'
[preflight] Running pre-flight checks
[reset] Deleted contents of the etcd data directory: /var/lib/etcd
[reset] Stopping the kubelet service
[reset] Unmounting mounted directories in "/var/lib/kubelet"
[reset] Deleting contents of directories: [/etc/kubernetes/manifests /var/lib/kubelet /etc/kubernetes/pki /etc/kubernetes/tmp]
[reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf]

The reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d

The reset process does not reset or clean up iptables rules or IPVS tables.
If you wish to reset iptables, you must do so manually by using the "iptables" command.

If your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)
to reset your system's IPVS tables.

The reset process does not clean your kubeconfig files and you must remove them manually.
Please, check the contents of the $HOME/.kube/config file.
</code></pre></div></div> <p>Clear original k8s installment including kubeadm, kubectl, kubulet. Uninstalling Kubernetes involves removing various components including <code class="language-plaintext highlighter-rouge">kubelet</code>, <code class="language-plaintext highlighter-rouge">kubeadm</code>, <code class="language-plaintext highlighter-rouge">kubectl</code>, and the <code class="language-plaintext highlighter-rouge">.kube</code> configuration directory. Here’s a general guide on how you can do it:</p> <ol> <li><strong>Drain and delete the nodes</strong>: If you have a multi-node setup, you need to drain the nodes before deleting them. Replace <code class="language-plaintext highlighter-rouge">&lt;node-name&gt;</code> with the name of your node.</li> </ol> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl drain &lt;node-name&gt; <span class="nt">--delete-local-data</span> <span class="nt">--force</span> <span class="nt">--ignore-daemonsets</span>
kubectl delete node &lt;node-name&gt;
</code></pre></div></div> <ol> <li><strong>Reset kubeadm</strong>: This will revert all the changes made by kubeadm init and kubeadm join.</li> </ol> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>kubeadm reset
</code></pre></div></div> <ol> <li><strong>Remove kubelet and kubeadm</strong>:</li> </ol> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get purge kubeadm kubectl kubelet kubernetes-cni kube<span class="k">*</span>
<span class="nb">sudo </span>apt-get autoremove
</code></pre></div></div> <ol> <li><strong>Delete the .kube directory</strong>:</li> </ol> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">rm</span> <span class="nt">-rf</span> ~/.kube
</code></pre></div></div> <ol> <li><strong>Remove all the docker container network interfaces</strong>:</li> </ol> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker <span class="nb">rm</span> <span class="si">$(</span>docker ps <span class="nt">-a</span> <span class="nt">-q</span><span class="si">)</span>
docker rmi <span class="si">$(</span>docker images <span class="nt">-q</span><span class="si">)</span>
</code></pre></div></div> <p>Got this issue</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) ➜  docker git:(master) ✗ kubectl describe pod
WARN[0000] Unable to read /etc/rancher/k3s/k3s.yaml, please start server with --write-kubeconfig-mode to modify kube config permissions
error: error loading config file "/etc/rancher/k3s/k3s.yaml": open /etc/rancher/k3s/k3s.yaml: permission denied
</code></pre></div></div> <p>Solution: This error is related to the permissions of the <code class="language-plaintext highlighter-rouge">k3s.yaml</code> file. Here are a few ways you can resolve this issue:</p> <ol> <li><strong>Change the permissions of the file</strong>²⁴: <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> sudo chmod 644 /etc/rancher/k3s/k3s.yaml
</code></pre></div> </div> <p>This command changes the permissions of the file to be readable by all users on your system.</p> </li> <li><strong>Change the KUBECONFIG environment variable</strong>¹: <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> KUBECONFIG=~/.kube/config
 export KUBECONFIG=~/.kube/config
 mkdir ~/.kube 2&gt; /dev/null
 sudo k3s kubectl config view --raw &gt; "$KUBECONFIG"
 chmod 600 "$KUBECONFIG"
</code></pre></div> </div> <p>This set of commands changes the <code class="language-plaintext highlighter-rouge">KUBECONFIG</code> environment variable to point to a different location (<code class="language-plaintext highlighter-rouge">~/.kube/config</code>), creates the <code class="language-plaintext highlighter-rouge">.kube</code> directory if it doesn’t exist, copies the current configuration into the new location, and then changes the permissions of the new configuration file.</p> </li> <li><strong>Start the k3s server with modified kube config permissions</strong>³: <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> sudo k3s server --write-kubeconfig-mode 644
</code></pre></div> </div> <p>This command starts the k3s server with the <code class="language-plaintext highlighter-rouge">--write-kubeconfig-mode</code> flag set to <code class="language-plaintext highlighter-rouge">644</code>, which changes the permissions of the kubeconfig file when it is written.</p> </li> </ol> <p>Still getting error that container is not able to start successfully</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Jun 17 22:07:14 common-testbed k3s[3214677]: I0617 22:07:14.939722 3214677 scope.go:117] "RemoveContainer" containerID="e0c6ed40764db0173c3464f2e4b387a2bc9bd13bbf5e3ab&gt;Jun 17 22:07:14 common-testbed k3s[3214677]: E0617 22:07:14.940136 3214677 pod_workers.go:1298] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"r&gt;Jun 17 22:07:25 common-testbed k3s[3214677]: I0617 22:07:25.939271 3214677 scope.go:117] "RemoveContainer" containerID="e0c6ed40764db0173c3464f2e4b387a2bc9bd13bbf5e3ab&gt;Jun 17 22:07:25 common-testbed k3s[3214677]: E0617 22:07:25.939711 3214677 pod_workers.go:1298] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"r&gt;Jun 17 22:07:40 common-testbed k3s[3214677]: I0617 22:07:40.939511 3214677 scope.go:117] "RemoveContainer" containerID="e0c6ed40764db0173c3464f2e4b387a2bc9bd13bbf5e3ab&gt;Jun 17 22:07:40 common-testbed k3s[3214677]: E0617 22:07:40.939941 3214677 pod_workers.go:1298] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"r&gt;~
</code></pre></div></div> <p>Solution: Remove all existing deployments and pods and restart again</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Delete all deployments in the default namespace
kubectl delete deployments --all

# Delete all pods in the default namespace
kubectl delete pods --all

</code></pre></div></div> <p>Still get error that rocksdb container fails to finish successfully. And I can not check logs of container. Solution: BingChat tells me that it’s because of http_proxy env variable issue. Do this</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>export NO_PROXY=$NO_PROXY,&lt;node-ip-address&gt;:6443
unset http_proxy
unset https_proxy

</code></pre></div></div> <p>Still can not call <code class="language-plaintext highlighter-rouge">kubectl logs</code> command to check container logs.</p> <p>Uninstall k3s</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
sudo /usr/local/bin/k3s-uninstall.sh
</code></pre></div></div> <p>https://docs.k3s.io/installation/configuration</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl -sfL https://get.k3s.io | K3S_KUBECONFIG_MODE="644" INSTALL_K3S_EXEC="server" sh -s - --flannel-backend none
</code></pre></div></div> <p>Get metrics server endpoint not available error after reinstallment of k3s Solution Don’t have solution yet.</p> <h2 id="try-minikube">Try minikube</h2> <p>Follow this doc <a href="https://minikube.sigs.k8s.io/docs/start/?arch=%2Flinux%2Fx86-64%2Fstable%2Fbinary+download#Service">https://minikube.sigs.k8s.io/docs/start/?arch=%2Flinux%2Fx86-64%2Fstable%2Fbinary+download#Service</a></p> <p>And then set no proxy to run <code class="language-plaintext highlighter-rouge">kubectl</code> command</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> export no_proxy=$(minikube ip)
</code></pre></div></div> <p>Run this command to set alias</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>alias kubectl="minikube kubectl --"
</code></pre></div></div> <p>Issue: Get image pulling issue</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  Normal   Scheduled  3m32s                default-scheduler  Successfully assigned default/rocksdb-858cd64b59-hnqtg to minikube
  Warning  Failed     3m22s                kubelet            Failed to pull image "zzt1234/test-rocksdb:v2": Error response from daemon: Get "https://registry-1.docker.io/v2/": dial tcp 34.226.69.105:443: connect: no route to host
</code></pre></div></div> <p>I think the reason is thatimage pulling does not go through proxy. Need to find a way to let minikube to use proxy to pull image.</p> <p>https://stackoverflow.com/questions/73756734/minikube-start-error-to-pull-new-external-images-you-may-need-to-configure-a-pr Read this doc to solve image pulling issue</p> <p>Set proxy in doker daemon setting file like this https://docs.docker.com/config/daemon/systemd/#httphttps-proxy</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>minikube start --docker-env HTTP_PROXY=http://127.0.0.1:8081   --docker-env HTTPS_PROXY=http://127.0.0.1:8081
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Events:
  Type     Reason     Age   From               Message
  ----     ------     ----  ----               -------
  Normal   Scheduled  4s    default-scheduler  Successfully assigned default/hello-minikube to minikube
  Normal   Pulling    3s    kubelet            Pulling image "gcr.io/google_containers/echoserver:1.4"
  Warning  Failed     3s    kubelet            Failed to pull image "gcr.io/google_containers/echoserver:1.4": Error response from daemon: Get "https://gcr.io/v2/": proxyconnect tcp: dial tcp 127.0.0.1:8081: connect: connection refused
  Warning  Failed     3s    kubelet            Error: ErrImagePull
</code></pre></div></div> <p>Actually command above about setting proxy is not right. I think I should set proxy address to real ip address of host machine.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> minikube start --docker-env HTTP_PROXY=http://28.10.10.62:8081   --docker-env HTTPS_PROXY=http://28.10.10.62:8081
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  Normal   Scheduled  4s    default-scheduler  Successfully assigned default/hello-minikube to minikube
  Normal   Pulling    3s    kubelet            Pulling image "gcr.io/google_containers/echoserver:1.4"
  Warning  Failed     2s    kubelet            Failed to pull image "gcr.io/google_containers/echoserver:1.4": [DEPRECATION NOTICE] Docker Image Format v1 and Docker Image manifest version 2, schema 1 support is disabled by default and will be removed in an upcoming release. Suggest the author of gcr.io/google_containers/echoserver:1.4 to upgrade the image to the OCI Format or Docker Image manifest v2, schema 2. More information at https://docs.docker.com/go/deprecated-image-specs/
  Warning  Failed     2s    kubelet            Error: ErrImagePull
</code></pre></div></div> <p>Now this issue is finially solved.</p> <p>So what do I learn from this problem solving steps? minikube actually set up a docker vm in host machine to pull image. So when I run <code class="language-plaintext highlighter-rouge">minikube start</code> command, it actually starts a docker vm in host machine. and when I run <code class="language-plaintext highlighter-rouge">kubectl</code> command, it actually runs in docker vm.</p> <p>Finally able to see logs inside k8s container</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(base) ➜  docker git:(master) ✗ kubectl logs rocksdb-858cd64b59-vk28f rocksdb
RocksDB:    version 8.11.3
Date:       Tue Jun 18 04:21:49 2024
CPU:        40 * Intel(R) Xeon(R) Gold 6230N CPU @ 2.30GHz
CPUCache:   28160 KB
Set seed to 1718684509751930 because --seed was 0
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
Integrated BlobDB: blob cache disabled
Keys:       16 bytes each (+ 0 bytes user-defined timestamp)
Values:     100 bytes each (50 bytes after compression)
Entries:    1000000
Prefix:    0 bytes
Keys per prefix:    0
RawSize:    110.6 MB (estimated)
FileSize:   62.9 MB (estimated)
Write rate: 0 bytes/second
Read rate: 0 ops/second
Compression: NoCompression
Compression sampling rate: 0
Memtablerep: SkipListFactory
Perf Level: 1
------------------------------------------------
Initializing RocksDB Options from the specified file
Initializing RocksDB Options from command-line flags
Integrated BlobDB: blob cache disabled
DB path: [/data/]
fillseq      :       2.114 micros/op 473062 ops/sec 2.114 seconds 1000000 operations;   52.3 MB/s
</code></pre></div></div> <p>Looks like that minikube sets docker proxy to map host port to container port.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> ├─3420670 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
 ├─3534038 /usr/bin/docker-proxy -proto tcp -host-ip 127.0.0.1 -host-port 32778 -container-ip 192.168.58.2 -container-port 32443
 ├─3534054 /usr/bin/docker-proxy -proto tcp -host-ip 127.0.0.1 -host-port 32779 -container-ip 192.168.58.2 -container-port 8443
 ├─3534076 /usr/bin/docker-proxy -proto tcp -host-ip 127.0.0.1 -host-port 32780 -container-ip 192.168.58.2 -container-port 5000
 ├─3534090 /usr/bin/docker-proxy -proto tcp -host-ip 127.0.0.1 -host-port 32781 -container-ip 192.168.58.2 -container-port 2376
 └─3534110 /usr/bin/docker-proxy -proto tcp -host-ip 127.0.0.1 -host-port 32782 -container-ip 192.168.58.2 -container-port 22
</code></pre></div></div> <h2 id="kubectl-delete-deployment-and-service"><code class="language-plaintext highlighter-rouge">kubectl</code> delete deployment and service</h2> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Delete deployment</span>
kubectl delete deployment &lt;deployment-name&gt;

<span class="c"># Delete service</span>
kubectl delete service &lt;service-name&gt;
</code></pre></div></div> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># List deployments</span>
kubectl get deployments

<span class="c"># List services</span>
kubectl get services

</code></pre></div></div> <h2 id="submit-container-job-to-k3s">Submit container job to k3s</h2> <p>After pushing local image to docker hub I am able to get normal image pulling message.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl describe pod
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  7s    default-scheduler  Successfully assigned default/rocksdb-57c5b55686-mnwvr to common-testbed
  Normal  Pulling    7s    kubelet            Pulling image "zzt1234/test-rocksdb:v2"
</code></pre></div></div>]]></content><author><name></name></author><category term="cloud"/><category term="cloud"/><category term="k3s"/><category term="k8s"/><summary type="html"><![CDATA[k3s]]></summary></entry><entry><title type="html">Docker beginner</title><link href="https://bilyz98.github.io/blog/2024/docker-file-compose-diff/" rel="alternate" type="text/html" title="Docker beginner"/><published>2024-06-11T11:59:00+00:00</published><updated>2024-06-11T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/docker-file-compose-diff</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/docker-file-compose-diff/"><![CDATA[<h2 id="difference-between-dockerfile-and-docker-compose">Difference between Dockerfile and Docker Compose</h2> <p>Dockerfile and Docker Compose are both important components of Docker, but they serve different purposes:</p> <ol> <li><strong>Dockerfile</strong>¹²³⁴⁵: <ul> <li>A Dockerfile is a text file that contains instructions for building a Docker image¹²³⁴⁵.</li> <li>It’s essentially Docker’s version of a Makefile or build.gradle⁵.</li> <li>It includes commands like <code class="language-plaintext highlighter-rouge">RUN</code>, <code class="language-plaintext highlighter-rouge">ADD</code>, <code class="language-plaintext highlighter-rouge">COPY</code>, <code class="language-plaintext highlighter-rouge">ENTRYPOINT</code>, etc².</li> <li>You build an image from a Dockerfile².</li> <li>An image is a template for running containers, consisting of multiple read-only layers².</li> <li>Dockerfile is used to create a container image².</li> </ul> </li> <li><strong>Docker Compose</strong>¹²³⁴⁵: <ul> <li>Docker Compose is a tool for defining and running multi-container Docker applications¹²³⁴⁵.</li> <li>It uses a YAML file (docker-compose.yml) to define the services that make up your app so they can be run together in an isolated environment³.</li> <li>A single Compose file can contain multiple container deployment configurations².</li> <li>Docker Compose is used to deploy an instance of that image as a container².</li> <li>It’s more readable, more maintainable, more intuitive².</li> </ul> </li> </ol> <p>In summary, a Dockerfile is used to build images, while Docker Compose is used to define and run multi-container applications¹²³⁴⁵. The Dockerfile uses the <code class="language-plaintext highlighter-rouge">docker build</code> command, while the docker-compose.yml file uses the <code class="language-plaintext highlighter-rouge">docker-compose up</code> command⁴. A docker-compose.yml file can reference a Dockerfile, but a Dockerfile can’t reference a docker-compose file⁴.</p> <h2 id="specify-docker-image-storage-location">Specify docker image storage location</h2> <p>To specify a different storage location for Docker images, you need to modify Docker’s configuration. Here are the steps for Linux and Windows:</p> <p><strong>For Linux</strong>¹²:</p> <ol> <li>Stop the Docker daemon if it’s running. You can do this with the command: <code class="language-plaintext highlighter-rouge">sudo systemctl stop docker</code>.</li> <li>Create a <code class="language-plaintext highlighter-rouge">daemon.json</code> file in <code class="language-plaintext highlighter-rouge">/etc/docker/</code> if it doesn’t exist¹.</li> <li>Open the <code class="language-plaintext highlighter-rouge">daemon.json</code> file and add the following, replacing <code class="language-plaintext highlighter-rouge">"/mnt"</code> with your desired path¹:</li> </ol> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"data-root"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/mnt"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <ol> <li>Save and close the file.</li> <li>Start the Docker daemon with the command: <code class="language-plaintext highlighter-rouge">sudo systemctl start docker</code>.</li> </ol> <p><strong>For Windows</strong>³:</p> <ol> <li>Quit Docker Desktop if it’s running.</li> <li>Open the <code class="language-plaintext highlighter-rouge">daemon.json</code> file located at <code class="language-plaintext highlighter-rouge">C:\ProgramData\Docker\config\</code>.</li> <li>Add the following to the file, replacing <code class="language-plaintext highlighter-rouge">"D:\\Virtual Machines\\Docker"</code> with your desired path³:</li> </ol> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"data-root"</span><span class="p">:</span><span class="w"> </span><span class="s2">"D:</span><span class="se">\\</span><span class="s2">Virtual Machines</span><span class="se">\\</span><span class="s2">Docker"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <ol> <li>Save and close the file.</li> <li>Start Docker Desktop.</li> </ol> <p>After making these changes, Docker will store its images in the specified directory. You can confirm the new storage location by running the command <code class="language-plaintext highlighter-rouge">docker info</code> and checking the <code class="language-plaintext highlighter-rouge">Docker Root Dir</code> value¹²³. Please note that you need to have the necessary permissions to read and write to the specified directory¹²³.</p> <h2 id="docker-remove-container-and-image">Docker remove container and image</h2> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># show all containers</span>
docker ps <span class="nt">-a</span>

docker <span class="nb">rm</span> &lt;container_id&gt;
docker rmi &lt;image_id&gt;
</code></pre></div></div> <h2 id="docker-pull-image-with-proxy">Docker pull image with proxy</h2> <ol> <li>Create a systemd drop-in directory for the Docker service if it doesn’t exist²⁴:</li> </ol> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> /etc/systemd/system/docker.service.d
</code></pre></div></div> <ol> <li>Create a file called <code class="language-plaintext highlighter-rouge">/etc/systemd/system/docker.service.d/http-proxy.conf</code>²⁴. Add the following content to the file, replacing <code class="language-plaintext highlighter-rouge">proxy.example.com:80</code> with your proxy host and port²⁴:</li> </ol> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>Service]
<span class="nv">Environment</span><span class="o">=</span><span class="s2">"HTTP_PROXY=http://proxy.example.com:80/"</span>
<span class="nv">Environment</span><span class="o">=</span><span class="s2">"HTTPS_PROXY=http://proxy.example.com:80/"</span>
</code></pre></div></div> <p>If you have internal Docker registries that you need to contact without proxying, you can specify them via the <code class="language-plaintext highlighter-rouge">NO_PROXY</code> environment variable²:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">Environment</span><span class="o">=</span><span class="s2">"NO_PROXY=localhost,127.0.0.0/8,docker-registry.somecorporation.com"</span>
</code></pre></div></div> <ol> <li>Reload the systemd daemon to apply the changes²⁴:</li> </ol> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>systemctl daemon-reload
</code></pre></div></div> <ol> <li>Restart the Docker service²⁴:</li> </ol> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>systemctl restart docker
</code></pre></div></div> <p>Now, Docker will use the specified proxy when pulling images²⁴.</p> <p>Remember, you need to have the necessary permissions to create and modify files in <code class="language-plaintext highlighter-rouge">/etc/systemd/system/docker.service.d</code>²⁴. If you don’t, you may need to use <code class="language-plaintext highlighter-rouge">sudo</code> or log in as root²⁴. Also, ensure that your proxy server is properly configured and reachable from your Docker host²⁴.</p> <h2 id="ubuntu-repository-mirror-in-china">Ubuntu repository mirror in China</h2> <p>http://ftp.sjtu.edu.cn/ubuntu/</p> <h2 id="solve-unable-to-connect-to-archiveubuntucom-during-docker-build">Solve unable to connect to archive.ubuntu.com during docker build</h2> <p>Solution I tried but not work: https://gist.github.com/dyndna/12b2317b5fbade37e747</p> <p>https://stackoverflow.com/questions/24991136/docker-build-could-not-resolve-archive-ubuntu-com-apt-get-fails-to-install-a</p> <p>Tried replacing sources.list with tsinghua source list but not work.</p> <p>Tried to pull the image and enter the conter to see if I can ping Failed.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run -it ubuntu bash
</code></pre></div></div> <p>Tried solution in this doc https://talk.plesk.com/threads/docker-is-unable-to-connect-to-the-internet.370357/</p> <p>Tried ping and curl on host machine ping does not work but curl can work. So I think I found the root cause. I set proxy for curl but I did not set proxy for ping.</p> <p>And I should set proxy for container so that it can do <code class="language-plaintext highlighter-rouge">apt-get update</code> successfully. Add these lines to set proxy that is used in host machine for container.</p> <div class="language-dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Update sources.list</span>
<span class="k">RUN </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/http:\/\/archive.ubuntu.com\/ubuntu\//http:\/\/mirrors.tuna.tsinghua.edu.cn\/ubuntu\//g'</span> /etc/apt/sources.list

<span class="k">ENV</span><span class="s"> http_proxy http://28.10.10.62:8081</span>
<span class="k">ENV</span><span class="s"> https_proxy http://28.10.10.62:8081 </span>

</code></pre></div></div> <h2 id="docker-remove-all-containers">docker remove all containers</h2> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># show all containers</span>
docker ps <span class="nt">-a</span>

docker <span class="nb">rm</span> <span class="si">$(</span>docker ps <span class="nt">-a</span> <span class="nt">-q</span> <span class="nt">-f</span> <span class="nv">status</span><span class="o">=</span>exited<span class="si">)</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="cloud"/><category term="cloud"/><category term="docker"/><summary type="html"><![CDATA[cloud]]></summary></entry><entry><title type="html">Docker RocksDB</title><link href="https://bilyz98.github.io/blog/2024/docker-rocksdb/" rel="alternate" type="text/html" title="Docker RocksDB"/><published>2024-06-11T11:59:00+00:00</published><updated>2024-06-11T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/docker-rocksdb</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/docker-rocksdb/"><![CDATA[<h2 id="rocksdb-dockerfile">RocksDB dockerfile</h2> <div class="language-dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Use an official Alpine runtime as a parent image</span>
<span class="c"># FROM alpine:3.14</span>
<span class="c"># FROM ubuntu:20.04</span>

<span class="c"># Use an official Ubuntu runtime as a parent image</span>
<span class="k">FROM</span><span class="s"> ubuntu:22.04</span>

<span class="c"># Make sure we don't get notifications we can't answer during building.</span>
<span class="c"># ENV DEBIAN_FRONTEND noninteractive</span>

<span class="c"># Update sources.list</span>
<span class="k">RUN </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/http:\/\/archive.ubuntu.com\/ubuntu\//http:\/\/mirrors.tuna.tsinghua.edu.cn\/ubuntu\//g'</span> /etc/apt/sources.list

<span class="k">ENV</span><span class="s"> http_proxy http://28.10.10.62:8081</span>
<span class="k">ENV</span><span class="s"> https_proxy http://28.10.10.62:8081 </span>

<span class="c"># RUN echo "deb http://ftp.sjtu.edu.cn/ubuntu focal main universe\n" &gt; /etc/apt/sources.list \</span>
<span class="c">#     &amp;&amp; echo "deb http://ftp.sjtu.edu.cn/ubuntu focal-updates main universe\n" &gt;&gt; /etc/apt/sources.list</span>

<span class="c"># Update the system</span>
<span class="k">RUN </span>apt-get update <span class="o">&amp;&amp;</span> apt-get upgrade <span class="nt">-y</span>

<span class="c"># Set the RocksDB version</span>
<span class="k">ARG</span><span class="s"> ROCKSDB_VERSION=v8.11.3</span>

<span class="c"># Install necessary packages and build RocksDB</span>
<span class="k">RUN </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> <span class="se">\
</span>    build-essential <span class="se">\
</span>    libgflags-dev <span class="se">\
</span>    libsnappy-dev <span class="se">\
</span>    zlib1g-dev <span class="se">\
</span>    libbz2-dev <span class="se">\
</span>    liblz4-dev <span class="se">\
</span>    libzstd-dev <span class="se">\
</span>    git <span class="se">\
</span>    bash <span class="se">\
</span>    perl <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">rm</span> <span class="nt">-rf</span> /var/lib/apt/lists/<span class="k">*</span> <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">cd</span> /usr/src <span class="se">\
</span>    <span class="o">&amp;&amp;</span> git clone <span class="nt">--depth</span> 1 <span class="nt">--branch</span> <span class="k">${</span><span class="nv">ROCKSDB_VERSION</span><span class="k">}</span> https://github.com/facebook/rocksdb.git  <span class="o">&amp;&amp;</span> <span class="se">\
</span>    <span class="nb">cd </span>rocksdb <span class="o">&amp;&amp;</span> <span class="se">\
</span>    make <span class="nt">-j4</span>  <span class="o">&amp;&amp;</span> <span class="se">\
</span>    make <span class="nb">install</span> 


<span class="c"># RUN apk update &amp;&amp; \</span>
<span class="c">#     apk add --no-cache zlib-dev bzip2-dev lz4-dev snappy-dev zstd-dev gflags-dev &amp;&amp; \</span>
<span class="c">#     apk add --no-cache build-base linux-headers git bash perl &amp;&amp; \</span>
<span class="c">#     mkdir /usr/src &amp;&amp; \</span>
<span class="c">#     cd /usr/src &amp;&amp; \</span>
<span class="c">#     git clone --depth 1 --branch ${ROCKSDB_VERSION} https://github.com/facebook/rocksdb.git &amp;&amp; \</span>
<span class="c">#     cd /usr/src/rocksdb &amp;&amp; \</span>
<span class="c">#     sed -i 's/install -C/install -c/g' Makefile &amp;&amp; \</span>
<span class="c">#     make -j4 shared_lib &amp;&amp; \</span>
<span class="c">#     make install-shared &amp;&amp; \</span>
<span class="c">#     apk del build-base linux-headers git bash perl &amp;&amp; \</span>
<span class="c">#     rm -rf /usr/src/rocksdb</span>

<span class="c"># Set the working directory</span>
<span class="k">WORKDIR</span><span class="s"> /</span>

</code></pre></div></div> <h2 id="docker-run-container">Docker run container</h2> <p>Start with dockerfile</p> <div class="language-dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CMD</span><span class="s">["./benchmark.sh"]</span>
</code></pre></div></div> <p>Docker copmose</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">version</span><span class="pi">:</span> <span class="s1">'</span><span class="s">3.8'</span>
<span class="na">services</span><span class="pi">:</span>
  <span class="na">rocksdb</span><span class="pi">:</span>
    <span class="na">build</span><span class="pi">:</span> <span class="s">.</span>
    <span class="na">container_name</span><span class="pi">:</span> <span class="s">rocksdb</span>
    <span class="na">volumes</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">./data:/data</span>
    <span class="na">networks</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">rocksdb</span>
    <span class="na">command</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">./benchmark.sh"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">input.txt"</span><span class="pi">]</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">8080:8080"</span>
    <span class="na">environment</span><span class="pi">:</span>
</code></pre></div></div> <h2 id="issues">Issues</h2> <p>db_bench cannot find librocksdb.8.11.so only librocksdb.a is available and db_bench is not compiled statically linked.</p> <p>Ways to solve this problem</p> <ol> <li>link db_bench with librocksdb.a</li> <li>Try cmake</li> </ol> <p>Tried cmake and it compiled successfully.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    cmake .. <span class="nt">-DCMAKE_BUILD_TYPE</span><span class="o">=</span>Release <span class="o">&amp;&amp;</span> <span class="se">\</span>
</code></pre></div></div> <h2 id="specify-volume-and-persist-db-data">Specify volume and persist db data</h2> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">version</span><span class="pi">:</span> <span class="s1">'</span><span class="s">3.8'</span>
<span class="na">services</span><span class="pi">:</span>
  <span class="na">rocksdb</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">rocksdb</span>
    <span class="c1"># build: .</span>
    <span class="na">container_name</span><span class="pi">:</span> <span class="s">rocksdb</span>
    <span class="c1"># tty: true</span>
    <span class="na">volumes</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">db_data:/data</span>
    <span class="na">command</span><span class="pi">:</span> <span class="s">bash -c "cd /usr/src/rocksdb/build &amp;&amp; ./db_bench -benchmarks=fillseq -compression-type=none -db=/data/ &amp;&amp; tail -f /dev/null"</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">8080:8080"</span>
    <span class="na">working_dir</span><span class="pi">:</span>
      <span class="s">/usr/src/rocksdb/build</span>
    <span class="na">environment</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">LD_LIBRARY_PATH=/usr/local/lib</span>

<span class="na">volumes</span><span class="pi">:</span>
  <span class="na">db_data</span><span class="pi">:</span>
</code></pre></div></div> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker volume list

</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DRIVER    VOLUME NAME
local     docker_db_data

</code></pre></div></div> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker volume inspect docker_db_data


</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[
    {
        "CreatedAt": "2024-06-14T22:45:30+08:00",
        "Driver": "local",
        "Labels": {
            "com.docker.compose.project": "docker",
            "com.docker.compose.version": "2.20.2",
            "com.docker.compose.volume": "db_data"
        },
        "Mountpoint": "/mnt/nvme1n1/docker-images/volumes/docker_db_data/_data",
        "Name": "docker_db_data",
        "Options": null,
        "Scope": "local"
    }
]
</code></pre></div></div>]]></content><author><name></name></author><category term="cloud"/><category term="cloud"/><category term="docker"/><category term="storage"/><summary type="html"><![CDATA[cloud]]></summary></entry><entry><title type="html">LightGBM usage and implementation</title><link href="https://bilyz98.github.io/blog/2024/lightgbm-usage/" rel="alternate" type="text/html" title="LightGBM usage and implementation"/><published>2024-06-08T11:59:00+00:00</published><updated>2024-06-08T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/lightgbm-usage</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/lightgbm-usage/"><![CDATA[<h1 id="lightgbm">LightGBM</h1> <h2 id="lightgbm-pay-more-attention-minority-class">LightGBM pay more attention minority class</h2> <p>In LightGBM, there are several ways to handle imbalanced data and pay more attention to the minority class:</p> <p>is_unbalance parameter: You can set the is_unbalance parameter to true when training the LightGBM model. This will automatically adjust the weights of the classes to be inversely proportional to their frequencies1. scale_pos_weight parameter: This parameter can provide better control of the weights of the minority and majority classes1. It allows you to set a configurable weight for the minority class1. class_weight parameter: This parameter is available in the LGBMClassifier and can be used to directly handle imbalanced data2. Customized metric or sample weights: You can also use a customized metric or apply weights to your samples3. Remember, when dealing with imbalanced data, accuracy is not the best metric. Instead, consider using metrics such as recall, precision, F1 score, or AUC4. You can also use ‘weighted’ or ‘micro’ averaging methods4.</p> <p>Here’s a simple example of how you might use the is_unbalance parameter in the C API:</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;LightGBM/c_api.h&gt;</span><span class="cp">
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">param</span> <span class="o">=</span> <span class="s">"objective=binary is_unbalance=true"</span><span class="p">;</span>
    <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">train_data_filename</span> <span class="o">=</span> <span class="s">"train.txt"</span><span class="p">;</span>
    <span class="n">DatasetHandle</span> <span class="n">train_data</span><span class="p">;</span>
    <span class="n">BoosterHandle</span> <span class="n">booster</span><span class="p">;</span>

    <span class="c1">// Load training data</span>
    <span class="n">LGBM_DatasetCreateFromFile</span><span class="p">(</span><span class="n">train_data_filename</span><span class="p">,</span> <span class="n">param</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">train_data</span><span class="p">);</span>

    <span class="c1">// Create booster</span>
    <span class="n">LGBM_BoosterCreate</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">param</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">booster</span><span class="p">);</span>

    <span class="c1">// Train model</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">100</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">LGBM_BoosterUpdateOneIter</span><span class="p">(</span><span class="n">booster</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="c1">// Save model</span>
    <span class="n">LGBM_BoosterSaveModel</span><span class="p">(</span><span class="n">booster</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s">"LightGBM_model.txt"</span><span class="p">);</span>

    <span class="c1">// Free resources</span>
    <span class="n">LGBM_BoosterFree</span><span class="p">(</span><span class="n">booster</span><span class="p">);</span>
</code></pre></div></div> <h2 id="id3-algorithm-that-trains-decision-tree">ID3 algorithm that trains decision tree</h2> <p>The training process of a decision tree involves building the tree and determining the split points of the features that most effectively separate the data. Here’s a simplified example of how a decision tree might be trained using the ID3 algorithm:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">ID3</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">original_data</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">target_attribute_name</span><span class="o">=</span><span class="sh">"</span><span class="s">class</span><span class="sh">"</span><span class="p">,</span> <span class="n">parent_node_class</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="c1"># If all target_values have the same value, return this value
</span>    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">target_attribute_name</span><span class="p">]))</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">target_attribute_name</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># If the dataset is empty, return the mode target feature value in the original dataset
</span>    <span class="k">elif</span> <span class="nf">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">original_data</span><span class="p">[</span><span class="n">target_attribute_name</span><span class="p">])[</span><span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">original_data</span><span class="p">[</span><span class="n">target_attribute_name</span><span class="p">],</span> <span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">])]</span>

    <span class="c1"># If the feature space is empty, return the mode target feature value of the direct parent node
</span>    <span class="k">elif</span> <span class="nf">len</span><span class="p">(</span><span class="n">features</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">parent_node_class</span>

    <span class="c1"># If none of the above holds true, grow the tree!
</span>    <span class="k">else</span><span class="p">:</span>
        <span class="n">parent_node_class</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">target_attribute_name</span><span class="p">])[</span><span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">target_attribute_name</span><span class="p">],</span> <span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">])]</span>

        <span class="c1"># Select the feature which best splits the dataset
</span>        <span class="n">item_values</span> <span class="o">=</span> <span class="p">[</span><span class="nc">InfoGain</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">feature</span><span class="p">,</span> <span class="n">target_attribute_name</span><span class="p">)</span> <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">features</span><span class="p">]</span>
        <span class="n">best_feature_index</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">item_values</span><span class="p">)</span>
        <span class="n">best_feature</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">best_feature_index</span><span class="p">]</span>

        <span class="c1"># Create the tree structure
</span>        <span class="n">tree</span> <span class="o">=</span> <span class="p">{</span><span class="n">best_feature</span><span class="p">:</span> <span class="p">{}}</span>

        <span class="c1"># Remove the feature with the best info gain from the feature space
</span>        <span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">features</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">best_feature</span><span class="p">]</span>

        <span class="c1"># Grow a branch under the root node for each possible value of the root node feature
</span>        <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">best_feature</span><span class="p">]):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">value</span>
            <span class="n">sub_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">best_feature</span><span class="p">]</span> <span class="o">==</span> <span class="n">value</span><span class="p">).</span><span class="nf">dropna</span><span class="p">()</span>

            <span class="c1"># Call the ID3 algorithm for each of those sub_datasets with the new parameters
</span>            <span class="n">subtree</span> <span class="o">=</span> <span class="nc">ID3</span><span class="p">(</span><span class="n">sub_data</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">target_attribute_name</span><span class="p">,</span> <span class="n">parent_node_class</span><span class="p">)</span>

            <span class="c1"># Add the sub tree, grown from the sub_dataset to the tree under the root node
</span>            <span class="n">tree</span><span class="p">[</span><span class="n">best_feature</span><span class="p">][</span><span class="n">value</span><span class="p">]</span> <span class="o">=</span> <span class="n">subtree</span>

        <span class="k">return</span> <span class="n">tree</span>
</code></pre></div></div> <p>In this code, the ID3 function is a recursive function that builds a decision tree using the ID3 algorithm. The function takes as input a dataset, a list of features to consider for splitting, and the name of the target attribute. It also takes an optional argument parent_node_class that is used to determine the class label for a node when no further splitting can be done.</p> <p>The function works by first checking for the base cases that would terminate the recursion: all instances having the same class, no more instances left, no more features left, or no more value left for the feature to split upon. If none of these cases are met, it calculates the information gain of the features and selects the feature with the highest information gain to split upon. It then creates a new tree node for this feature and calls the ID3 function recursively on the sub-datasets to build the subtrees.</p> <p>Please note that this is a simplified example. Real-world decision tree learning algorithms like those used in scikit-learn or LightGBM are more complex and optimized. They also handle more cases, like missing values and different types of features (continuous, categorical, etc.). They also use different criteria for splitting, like Gini impurity or information gain ratio. The ID3 algorithm is one of the simplest decision tree learning algorithms and is a good starting point for understanding the basics.</p> <h2 id="code-example-of-calling-lgbm_boosterpredictforcsrsinglerowfast">Code example of calling LGBM_BoosterPredictForCSRSingleRowFast</h2> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;lightgbm/c_api.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;stdlib.h&gt;</span><span class="cp">
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="c1">// Assume we have a trained model and a FastConfigHandle</span>
    <span class="n">FastConfigHandle</span> <span class="n">fastConfig_handle</span><span class="p">;</span>

    <span class="c1">// Define a single row of data in CSR format</span>
    <span class="kt">int</span> <span class="n">indptr_type</span> <span class="o">=</span> <span class="n">C_API_DTYPE_INT32</span><span class="p">;</span>
    <span class="kt">int64_t</span> <span class="n">nindptr</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="kt">int64_t</span> <span class="n">nelem</span> <span class="o">=</span> <span class="mi">3</span><span class="p">;</span>

    <span class="kt">int</span><span class="o">*</span> <span class="n">indptr</span> <span class="o">=</span> <span class="p">(</span><span class="kt">int</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">nindptr</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
    <span class="n">indptr</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="n">indptr</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">nelem</span><span class="p">;</span>

    <span class="kt">int32_t</span><span class="o">*</span> <span class="n">indices</span> <span class="o">=</span> <span class="p">(</span><span class="kt">int32_t</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">nelem</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">int32_t</span><span class="p">));</span>
    <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="n">indices</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span>
    <span class="n">indices</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>

    <span class="kt">double</span><span class="o">*</span> <span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="kt">double</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">nelem</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">double</span><span class="p">));</span>
    <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">.</span><span class="mi">0</span><span class="p">;</span>
    <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">3</span><span class="p">.</span><span class="mi">0</span><span class="p">;</span>
    <span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">5</span><span class="p">.</span><span class="mi">0</span><span class="p">;</span>

    <span class="c1">// Output variables</span>
    <span class="kt">int64_t</span> <span class="n">out_len</span><span class="p">;</span>
    <span class="kt">double</span><span class="o">*</span> <span class="n">out_result</span> <span class="o">=</span> <span class="p">(</span><span class="kt">double</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">double</span><span class="p">));</span>

    <span class="c1">// Call the function</span>
    <span class="kt">int</span> <span class="n">result</span> <span class="o">=</span> <span class="n">LGBM_BoosterPredictForCSRSingleRowFast</span><span class="p">(</span><span class="n">fastConfig_handle</span><span class="p">,</span> <span class="n">indptr</span><span class="p">,</span> <span class="n">indptr_type</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">nindptr</span><span class="p">,</span> <span class="n">nelem</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">out_len</span><span class="p">,</span> <span class="n">out_result</span><span class="p">);</span>

    <span class="c1">// Check the result</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">result</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"Prediction successful, output length: %lld</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">out_len</span><span class="p">);</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"Prediction failed, error code: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">result</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="c1">// Free allocated memory</span>
    <span class="n">free</span><span class="p">(</span><span class="n">indptr</span><span class="p">);</span>
    <span class="n">free</span><span class="p">(</span><span class="n">indices</span><span class="p">);</span>
    <span class="n">free</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>
    <span class="n">free</span><span class="p">(</span><span class="n">out_result</span><span class="p">);</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div> <p>In this example, we’re creating a single row of data with three non-zero elements. The <code class="language-plaintext highlighter-rouge">indptr</code> array defines the start and end of the row in the <code class="language-plaintext highlighter-rouge">indices</code> and <code class="language-plaintext highlighter-rouge">data</code> arrays. The <code class="language-plaintext highlighter-rouge">indices</code> array contains the column indices of the non-zero elements, and the <code class="language-plaintext highlighter-rouge">data</code> array contains the values of the non-zero elements.</p> <p>Please replace the placeholders with your actual data and handle. Also, make sure to handle the memory correctly, especially for the <code class="language-plaintext highlighter-rouge">out_result</code> pointer. This is just a basic example and does not include error checking or memory management. You should add those in your actual code.</p> <p>Remember to link against the LightGBM library when compiling this code. If you’re using gcc, you can do this with <code class="language-plaintext highlighter-rouge">-lLightGBM</code>. If you’re using Visual Studio, you’ll need to add the LightGBM library to your project settings.</p> <h2 id="source-code-of-gbdt-train">Source code of GBDT train()</h2> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">class</span> <span class="n">ObjectiveFunction</span> <span class="p">{</span>
 <span class="nl">public:</span>
  <span class="cm">/*! \brief virtual destructor */</span>
  <span class="k">virtual</span> <span class="o">~</span><span class="n">ObjectiveFunction</span><span class="p">()</span> <span class="p">{}</span>

  <span class="cm">/*!
  * \brief Initialize
  * \param metadata Label data
  * \param num_data Number of data
  */</span>
  <span class="k">virtual</span> <span class="kt">void</span> <span class="n">Init</span><span class="p">(</span><span class="k">const</span> <span class="n">Metadata</span><span class="o">&amp;</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">data_size_t</span> <span class="n">num_data</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

  <span class="cm">/*!
  * \brief calculating first order derivative of loss function
  * \param score prediction score in this round
  * \gradients Output gradients
  * \hessians Output hessians
  */</span>
  <span class="k">virtual</span> <span class="kt">void</span> <span class="n">GetGradients</span><span class="p">(</span><span class="k">const</span> <span class="kt">double</span><span class="o">*</span> <span class="n">score</span><span class="p">,</span>
    <span class="n">score_t</span><span class="o">*</span> <span class="n">gradients</span><span class="p">,</span> <span class="n">score_t</span><span class="o">*</span> <span class="n">hessians</span><span class="p">)</span> <span class="k">const</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>


</code></pre></div></div> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="n">GBDT</span><span class="o">::</span><span class="n">Train</span><span class="p">(</span><span class="kt">int</span> <span class="n">snapshot_freq</span><span class="p">,</span> <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span> <span class="n">model_output_path</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">Common</span><span class="o">::</span><span class="n">FunctionTimer</span> <span class="n">fun_timer</span><span class="p">(</span><span class="s">"GBDT::Train"</span><span class="p">,</span> <span class="n">global_timer</span><span class="p">);</span>
  <span class="n">bool</span> <span class="n">is_finished</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
  <span class="k">auto</span> <span class="n">start_time</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">steady_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">iter</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">iter</span> <span class="o">&lt;</span> <span class="n">config_</span><span class="o">-&gt;</span><span class="n">num_iterations</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">is_finished</span><span class="p">;</span> <span class="o">++</span><span class="n">iter</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">is_finished</span> <span class="o">=</span> <span class="n">TrainOneIter</span><span class="p">(</span><span class="n">nullptr</span><span class="p">,</span> <span class="n">nullptr</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">is_finished</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">is_finished</span> <span class="o">=</span> <span class="n">EvalAndCheckEarlyStopping</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="k">auto</span> <span class="n">end_time</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">steady_clock</span><span class="o">::</span><span class="n">now</span><span class="p">();</span>
    <span class="c1">// output used time per iteration</span>
    <span class="n">Log</span><span class="o">::</span><span class="n">Info</span><span class="p">(</span><span class="s">"%f seconds elapsed, finished iteration %d"</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">duration</span><span class="o">&lt;</span><span class="kt">double</span><span class="p">,</span>
              <span class="n">std</span><span class="o">::</span><span class="n">milli</span><span class="o">&gt;</span><span class="p">(</span><span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="n">iter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">snapshot_freq</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">iter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">snapshot_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">snapshot_out</span> <span class="o">=</span> <span class="n">model_output_path</span> <span class="o">+</span> <span class="s">".snapshot_iter_"</span> <span class="o">+</span> <span class="n">std</span><span class="o">::</span><span class="n">to_string</span><span class="p">(</span><span class="n">iter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">);</span>
      <span class="n">SaveModelToFile</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">config_</span><span class="o">-&gt;</span><span class="n">saved_feature_importance_type</span><span class="p">,</span> <span class="n">snapshot_out</span><span class="p">.</span><span class="n">c_str</span><span class="p">());</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>
    <span class="n">bool</span> <span class="n">GBDT</span><span class="o">::</span><span class="n">TrainOneIter</span><span class="p">(</span><span class="k">const</span> <span class="n">score_t</span><span class="o">*</span> <span class="n">gradients</span><span class="p">,</span> <span class="k">const</span> <span class="n">score_t</span><span class="o">*</span> <span class="n">hessians</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">Common</span><span class="o">::</span><span class="n">FunctionTimer</span> <span class="n">fun_timer</span><span class="p">(</span><span class="s">"GBDT::TrainOneIter"</span><span class="p">,</span> <span class="n">global_timer</span><span class="p">);</span>
      <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="n">init_scores</span><span class="p">(</span><span class="n">num_tree_per_iteration_</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">);</span>
      <span class="c1">// boosting first</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">gradients</span> <span class="o">==</span> <span class="n">nullptr</span> <span class="o">||</span> <span class="n">hessians</span> <span class="o">==</span> <span class="n">nullptr</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">cur_tree_id</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">cur_tree_id</span> <span class="o">&lt;</span> <span class="n">num_tree_per_iteration_</span><span class="p">;</span> <span class="o">++</span><span class="n">cur_tree_id</span><span class="p">)</span> <span class="p">{</span>
          <span class="n">init_scores</span><span class="p">[</span><span class="n">cur_tree_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">BoostFromAverage</span><span class="p">(</span><span class="n">cur_tree_id</span><span class="p">,</span> <span class="nb">true</span><span class="p">);</span>
        <span class="p">}</span>
        <span class="n">Boosting</span><span class="p">();</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">gradients_pointer_</span><span class="p">;</span>
        <span class="n">hessians</span> <span class="o">=</span> <span class="n">hessians_pointer_</span><span class="p">;</span>
      <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="c1">// use customized objective function</span>
        <span class="n">CHECK</span><span class="p">(</span><span class="n">objective_function_</span> <span class="o">==</span> <span class="n">nullptr</span><span class="p">);</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">data_sample_strategy_</span><span class="o">-&gt;</span><span class="n">IsHessianChange</span><span class="p">())</span> <span class="p">{</span>
          <span class="c1">// need to copy customized gradients when using GOSS</span>
          <span class="kt">int64_t</span> <span class="n">total_size</span> <span class="o">=</span> <span class="n">static_cast</span><span class="o">&lt;</span><span class="kt">int64_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">num_data_</span><span class="p">)</span> <span class="o">*</span> <span class="n">num_tree_per_iteration_</span><span class="p">;</span>
          <span class="cp">#pragma omp parallel for schedule(static)
</span>          <span class="k">for</span> <span class="p">(</span><span class="kt">int64_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">total_size</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">gradients_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
            <span class="n">hessians_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">hessians</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
          <span class="p">}</span>
          <span class="n">CHECK_EQ</span><span class="p">(</span><span class="n">gradients_pointer_</span><span class="p">,</span> <span class="n">gradients_</span><span class="p">.</span><span class="n">data</span><span class="p">());</span>
          <span class="n">CHECK_EQ</span><span class="p">(</span><span class="n">hessians_pointer_</span><span class="p">,</span> <span class="n">hessians_</span><span class="p">.</span><span class="n">data</span><span class="p">());</span>
          <span class="n">gradients</span> <span class="o">=</span> <span class="n">gradients_pointer_</span><span class="p">;</span>
          <span class="n">hessians</span> <span class="o">=</span> <span class="n">hessians_pointer_</span><span class="p">;</span>
        <span class="p">}</span>
      <span class="p">}</span>

            <span class="kt">void</span> <span class="n">GBDT</span><span class="o">::</span><span class="n">Boosting</span><span class="p">()</span> <span class="p">{</span>
              <span class="n">Common</span><span class="o">::</span><span class="n">FunctionTimer</span> <span class="n">fun_timer</span><span class="p">(</span><span class="s">"GBDT::Boosting"</span><span class="p">,</span> <span class="n">global_timer</span><span class="p">);</span>
              <span class="k">if</span> <span class="p">(</span><span class="n">objective_function_</span> <span class="o">==</span> <span class="n">nullptr</span><span class="p">)</span> <span class="p">{</span>
                <span class="n">Log</span><span class="o">::</span><span class="n">Fatal</span><span class="p">(</span><span class="s">"No objective function provided"</span><span class="p">);</span>
              <span class="p">}</span>
              <span class="c1">// objective function will calculate gradients and hessians</span>
              <span class="kt">int64_t</span> <span class="n">num_score</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
              <span class="n">objective_function_</span><span class="o">-&gt;</span>
                <span class="n">GetGradients</span><span class="p">(</span><span class="n">GetTrainingScore</span><span class="p">(</span><span class="o">&amp;</span><span class="n">num_score</span><span class="p">),</span> <span class="n">gradients_pointer_</span><span class="p">,</span> <span class="n">hessians_pointer_</span><span class="p">);</span>
            <span class="p">}</span>
              <span class="kt">void</span> <span class="n">GetGradients</span><span class="p">(</span><span class="k">const</span> <span class="kt">double</span><span class="o">*</span> <span class="n">score</span><span class="p">,</span> <span class="n">score_t</span><span class="o">*</span> <span class="n">gradients</span><span class="p">,</span> <span class="n">score_t</span><span class="o">*</span> <span class="n">hessians</span><span class="p">)</span> <span class="k">const</span> <span class="n">override</span> <span class="p">{</span>
                <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">need_train_</span><span class="p">)</span> <span class="p">{</span>
                  <span class="k">return</span><span class="p">;</span>
                <span class="p">}</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">weights_</span> <span class="o">==</span> <span class="n">nullptr</span><span class="p">)</span> <span class="p">{</span>
                  <span class="cp">#pragma omp parallel for schedule(static)
</span>                  <span class="k">for</span> <span class="p">(</span><span class="n">data_size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_data_</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
                    <span class="c1">// get label and label weights</span>
                    <span class="k">const</span> <span class="kt">int</span> <span class="n">is_pos</span> <span class="o">=</span> <span class="n">is_pos_</span><span class="p">(</span><span class="n">label_</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
                    <span class="k">const</span> <span class="kt">int</span> <span class="n">label</span> <span class="o">=</span> <span class="n">label_val_</span><span class="p">[</span><span class="n">is_pos</span><span class="p">];</span>
                    <span class="k">const</span> <span class="kt">double</span> <span class="n">label_weight</span> <span class="o">=</span> <span class="n">label_weights_</span><span class="p">[</span><span class="n">is_pos</span><span class="p">];</span>
                    <span class="c1">// calculate gradients and hessians</span>
                    <span class="k">const</span> <span class="kt">double</span> <span class="n">response</span> <span class="o">=</span> <span class="o">-</span><span class="n">label</span> <span class="o">*</span> <span class="n">sigmoid_</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span> <span class="o">+</span> <span class="n">std</span><span class="o">::</span><span class="n">exp</span><span class="p">(</span><span class="n">label</span> <span class="o">*</span> <span class="n">sigmoid_</span> <span class="o">*</span> <span class="n">score</span><span class="p">[</span><span class="n">i</span><span class="p">]));</span>
                    <span class="k">const</span> <span class="kt">double</span> <span class="n">abs_response</span> <span class="o">=</span> <span class="n">fabs</span><span class="p">(</span><span class="n">response</span><span class="p">);</span>
                    <span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">static_cast</span><span class="o">&lt;</span><span class="n">score_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">response</span> <span class="o">*</span> <span class="n">label_weight</span><span class="p">);</span>
                    <span class="n">hessians</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">static_cast</span><span class="o">&lt;</span><span class="n">score_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">abs_response</span> <span class="o">*</span> <span class="p">(</span><span class="n">sigmoid_</span> <span class="o">-</span> <span class="n">abs_response</span><span class="p">)</span> <span class="o">*</span> <span class="n">label_weight</span><span class="p">);</span>
                  <span class="p">}</span>
                <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>

</code></pre></div></div> <h2 id="training-code-snipet">Training code snipet</h2> <p>python</p> <p>c</p> <h2 id="csrcompressed-sparsed-row-format">CSR(Compressed Sparsed Row) format</h2> <p>It uses three one dimensional arrays to store non-zero values. This is efficient for sparse matrixes where most of the elements are zero.</p> <p>In the context of a Compressed Sparse Row (CSR) matrix, <code class="language-plaintext highlighter-rouge">indptr</code> and <code class="language-plaintext highlighter-rouge">indices</code> are arrays used to represent sparse data. Here’s what they mean:</p> <ul> <li> <p><code class="language-plaintext highlighter-rouge">indptr</code>: This is short for “index pointer”. It is an integer array of length <code class="language-plaintext highlighter-rouge">n_rows + 1</code> where <code class="language-plaintext highlighter-rouge">n_rows</code> is the number of rows in your matrix. The <code class="language-plaintext highlighter-rouge">indptr</code> array defines the index ranges for rows of the matrix. If <code class="language-plaintext highlighter-rouge">indptr[i] = x</code> and <code class="language-plaintext highlighter-rouge">indptr[i+1] = y</code>, this means that the data for row <code class="language-plaintext highlighter-rouge">i</code> in the matrix is stored in <code class="language-plaintext highlighter-rouge">indices[x:y]</code> and <code class="language-plaintext highlighter-rouge">data[x:y]</code>.</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">indices</code>: This is an integer array that contains column indices of non-zero elements. The column indices for row <code class="language-plaintext highlighter-rouge">i</code> are stored in <code class="language-plaintext highlighter-rouge">indices[indptr[i]:indptr[i+1]]</code>.</p> </li> </ul> <p>Here’s a simple example:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">scipy.sparse</span> <span class="kn">import</span> <span class="n">csr_matrix</span>

<span class="c1"># Create a CSR matrix
</span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">indptr</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">csr</span> <span class="o">=</span> <span class="nf">csr_matrix</span><span class="p">((</span><span class="n">data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">indptr</span><span class="p">),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="nf">print</span><span class="p">(</span><span class="n">csr</span><span class="p">.</span><span class="nf">toarray</span><span class="p">())</span>
</code></pre></div></div> <p>This will output:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[[</span><span class="mi">1</span> <span class="mi">0</span> <span class="mi">2</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">3</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">4</span> <span class="mi">5</span> <span class="mi">6</span><span class="p">]]</span>
</code></pre></div></div> <p>In this matrix, the non-zero elements of the first row are <code class="language-plaintext highlighter-rouge">1</code> (at column <code class="language-plaintext highlighter-rouge">0</code>) and <code class="language-plaintext highlighter-rouge">2</code> (at column <code class="language-plaintext highlighter-rouge">2</code>), which corresponds to <code class="language-plaintext highlighter-rouge">indices[0:2]</code> and <code class="language-plaintext highlighter-rouge">data[0:2]</code>. The non-zero elements of the second row are <code class="language-plaintext highlighter-rouge">3</code> (at column <code class="language-plaintext highlighter-rouge">2</code>), which corresponds to <code class="language-plaintext highlighter-rouge">indices[2:3]</code> and <code class="language-plaintext highlighter-rouge">data[2:3]</code>. The non-zero elements of the third row are <code class="language-plaintext highlighter-rouge">4</code> (at column <code class="language-plaintext highlighter-rouge">0</code>), <code class="language-plaintext highlighter-rouge">5</code> (at column <code class="language-plaintext highlighter-rouge">1</code>), and <code class="language-plaintext highlighter-rouge">6</code> (at column <code class="language-plaintext highlighter-rouge">2</code>), which corresponds to <code class="language-plaintext highlighter-rouge">indices[3:6]</code> and <code class="language-plaintext highlighter-rouge">data[3:6]</code>.</p>]]></content><author><name></name></author><category term="ai"/><category term="ai"/><category term="ml"/><summary type="html"><![CDATA[Artificial Intelligence]]></summary></entry><entry><title type="html">Git</title><link href="https://bilyz98.github.io/blog/2024/git/" rel="alternate" type="text/html" title="Git"/><published>2024-06-08T11:59:00+00:00</published><updated>2024-06-08T11:59:00+00:00</updated><id>https://bilyz98.github.io/blog/2024/git</id><content type="html" xml:base="https://bilyz98.github.io/blog/2024/git/"><![CDATA[<h2 id="git-update-commit-message-of-latest-commit">git update commit message of latest commit</h2> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git commit <span class="nt">--amend</span> <span class="nt">-m</span> <span class="s2">"New commit message"</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="git"/><category term="git"/><summary type="html"><![CDATA[git]]></summary></entry></feed>