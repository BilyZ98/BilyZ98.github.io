---
layout: post
title: llm.c  
date: 2024-06-17 07:59:00-0400
description: llm minikune
tags:  ml  ai cuda
categories: ml
featured: false
---

roadmap
- [x] Running llm.c
- [x] Running llm.c with cuda
- [ ] Inference with fp16
- [ ] Inference with vllm
- [ ] try other inference acceleartion tech

## Running llm.c
[https://github.com/karpathy/llm.c](https://github.com/karpathy/llm.c)
### GPU 
Had issue running gpu
There is only cuda 11.2 on my machine
but torch 2.1.0 is installed which requires cuda 12.0

Solution:
Manually specify torch==1.3.1

Get error
```bash
yhrun -n 4 -p gpu_v100 python train_gpt2.py
```
```
Traceback (most recent call last):
  File "train_gpt2.py", line 24, in <module>
    from contextlib import nullcontext
ImportError: cannot import name 'nullcontext'
Traceback (most recent call last):
  File "train_gpt2.py", line 24, in <module>
    from contextlib import nullcontext
ImportError: cannot import name 'nullcontext'
Traceback (most recent call last):
  File "train_gpt2.py", line 24, in <module>
    from contextlib import nullcontext
ImportError: cannot import name 'nullcontext'
Traceback (most recent call last):
  File "train_gpt2.py", line 24, in <module>
    from contextlib import nullcontext
ImportError: cannot import name 'nullcontext'
yhrun: error: gpu55: tasks 0-3: Exited with exit code 1
```
The issue is that nullcontext is introduced in python >=3.7
So I need to upgrade python version

Still can not solve problem above because I
can't not import new module to existing module list.
```
Currently Loaded Modulefiles:
 1) proxy/1.0   2) CUDA/10.0   3) cudnn/7.6.4-CUDA10.0   4) PyTorch/1.2.0-CUDA10.0-py3.6

 $ yhrun -n 4 -p gpu_v100 python train_gpt2.py
Traceback (most recent call last):
  File "train_gpt2.py", line 24, in <module>
    from contextlib import nullcontext
ImportError: cannot import name 'nullcontext'
Traceback (most recent call last):
  File "train_gpt2.py", line 24, in <module>
    from contextlib import nullcontext
ImportError: cannot import name 'nullcontext'
Traceback (most recent call last):
  File "train_gpt2.py", line 24, in <module>
    from contextlib import nullcontext
ImportError: cannot import name 'nullcontext'
Traceback (most recent call last):
  File "train_gpt2.py", line 24, in <module>
    from contextlib import nullcontext
ImportError: cannot import name 'nullcontext'
```

My friend told me that I can just use conda to create new namespace
and then I can ssh to the compute node and activate the conda environment.
And then I can run training process.

This means that compute node shares the same file system with login node.
But the operating system is different. Because each node has its own hostname.

Learn new thing every day.

Here's all available nodes I  have.

Karpathy has updated gpt2 parameter download script so now
I can download parameter via shell script

Issue:
Can not connect to huggingface todownload pretrained model via proxy
```
(llmc) [nsccgz_qylin_1@ln102%tianhe2-K llm.c]$ curl -v https://huggingface.co
* About to connect() to proxy 10.20.18.21 port 3128 (#0)
*   Trying 10.20.18.21...
* Connected to 10.20.18.21 (10.20.18.21) port 3128 (#0)
* Establish HTTP proxy tunnel to huggingface.co:443
> CONNECT huggingface.co:443 HTTP/1.1
> Host: huggingface.co:443
> User-Agent: curl/7.29.0
> Proxy-Connection: Keep-Alive
>
< HTTP/1.1 503 Service Unavailable
< Proxy-Agent: gost/2.11.1
< Content-Length: 0
<
* Received HTTP code 503 from proxy after CONNECT
* Connection #0 to host 10.20.18.21 left intact
curl: (56) Received HTTP code 503 from proxy after CONNECT
```
Solution:
I decide to download on my local laptop and then upload these model parameter
files to gpu nodes.


```bash
chmod u+x ./dev/download_starter_pack.sh
./dev/download_starter_pack.sh
make train_gpt2fp32cu
./train_gpt2fp32cu
```
cuda env:
```
Currently Loaded Modulefiles:
 1) proxy/1.0   2) python/3.6.7_anaconda3   3) CUDA/11.2   4) gmp/4.2.4   5) mpfr/2.4.2   6) mpc/0.8.1   7) gcc/9.2.0
```


Output :
```
step   61/74: train loss 3.213066 (312.014672 ms, 13127 tok/s)
step   62/74: train loss 3.450736 (314.262273 ms, 13033 tok/s)
step   63/74: train loss 3.370245 (315.130342 ms, 12997 tok/s)
step   64/74: train loss 3.407992 (316.778140 ms, 12930 tok/s)
step   65/74: train loss 3.580323 (315.324538 ms, 12989 tok/s)
step   66/74: train loss 3.029552 (317.274858 ms, 12909 tok/s)
step   67/74: train loss 3.296448 (317.588671 ms, 12897 tok/s)
step   68/74: train loss 3.675703 (314.929981 ms, 13006 tok/s)
step   69/74: train loss 3.297087 (313.282229 ms, 13074 tok/s)
step   70/74: train loss 3.646337 (315.271277 ms, 12991 tok/s)
step   71/74: train loss 3.566427 (316.123225 ms, 12956 tok/s)
step   72/74: train loss 3.732521 (315.446478 ms, 12984 tok/s)
step   73/74: train loss 3.825229 (318.325142 ms, 12867 tok/s)
step   74/74: train loss 3.380326 (318.066751 ms, 12877 tok/s)
val loss 3.491223
generating:
---
BUCKINGHAM:
But of my penitent ambition
Rome Slicom against Reimy, justice about him!
In case the witness should speak with joy:
Shall now that by these dwelling House,
Suspicions are declaim'd of the Albanian king.
Go
---
total average iteration time: 312.354733 ms
```
### CPU 
```bash
pip install -r requirements.txt
python dev/data/tinyshakespeare.py
python train_gpt2.py
make train_gpt2
OMP_NUM_THREADS=8 ./train_gpt2
```
Output
```
step 20: train loss 4.527330 (took 2636.617334 ms)
step 21: train loss 4.065797 (took 2701.692621 ms)
step 22: train loss 3.965316 (took 2681.297241 ms)
step 23: train loss 3.449409 (took 2650.111416 ms)
step 24: train loss 4.490954 (took 2637.116332 ms)
step 25: train loss 4.035361 (took 2659.843151 ms)
step 26: train loss 3.445302 (took 2652.557792 ms)
step 27: train loss 3.993789 (took 2649.868369 ms)
step 28: train loss 4.199468 (took 2638.095098 ms)
step 29: train loss 4.538460 (took 2669.385015 ms)
val loss 4.350866
step 30: train loss 4.306292 (took 2658.306411 ms)
step 31: train loss 4.851407 (took 2634.616368 ms)
step 32: train loss 4.577479 (took 2670.470130 ms)
step 33: train loss 4.124943 (took 2660.545565 ms)
step 34: train loss 4.330319 (took 2669.532886 ms)
step 35: train loss 3.399416 (took 2639.378693 ms)
step 36: train loss 3.661207 (took 2632.377219 ms)
step 37: train loss 3.330453 (took 2637.114896 ms)
step 38: train loss 3.567853 (took 2645.744510 ms)
step 39: train loss 3.902004 (took 2635.939546 ms)
val loss 4.319361
generating:
---
EditBOOK IX:
Under the boasted sute of Georges:
So lordly is the prize had sin is high;
Hell is the way to God: frankish friends from blessed daughters
To Bermuda have heard the saying,
Then how to place the artscape.
Strong should a bellow
---
step 40: train loss 3.952987 (took 2665.948189 ms)
```


Some questions?
How many low end gpus are there in the market?
I am thinking about utilizing low end gpus to train model, large 
or small model.






