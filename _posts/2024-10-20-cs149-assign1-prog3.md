




## Speedup with ISPC
launching 80 tasks brings 62x speedup.
```cpp

export void mandelbrot_ispc_withtasks(uniform float x0, uniform float y0,
                                      uniform float x1, uniform float y1,
                                      uniform int width, uniform int height,
                                      uniform int maxIterations,
                                      uniform int output[])
{

    uniform int rowsPerTask = height / 80;

    // create 2 tasks
    launch[80] mandelbrot_ispc_task(x0, y0, x1, y1,
                                     width, height,
                                     rowsPerTask,
                                     maxIterations,
                                     output); 
}
```
```
(base) âžœ  prog3_mandelbrot_ispc git:(master) âœ— ./mandelbrot_ispc  --tasks
[mandelbrot serial]:            [268.624] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot ispc]:              [55.141] ms
Wrote image file mandelbrot-ispc.ppm
[mandelbrot multicore ispc]:    [4.328] ms
Wrote image file mandelbrot-task-ispc.ppm
                                (4.87x speedup from ISPC)
                                (62.07x speedup from task ISPC)
```


Speedup for different image generation task with same task parallelism settings is different
```
(base) âžœ  prog3_mandelbrot_ispc git:(master) âœ— ./mandelbrot_ispc  --tasks  --view 0
[mandelbrot serial]:            [267.687] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot ispc]:              [54.364] ms
Wrote image file mandelbrot-ispc.ppm
[mandelbrot multicore ispc]:    [4.698] ms
Wrote image file mandelbrot-task-ispc.ppm                                                                                                                                                    (4.92x speedup from ISPC)                                                                                                                                    
(56.97x speedup from task ISPC)

(base) âžœ  prog3_mandelbrot_ispc git:(master) âœ— ./mandelbrot_ispc  --tasks  --view 1
[mandelbrot serial]:            [266.777] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot ispc]:              [53.877] ms
Wrote image file mandelbrot-ispc.ppm
[mandelbrot multicore ispc]:    [5.287] ms
Wrote image file mandelbrot-task-ispc.ppm
                                (4.95x speedup from ISPC)
                                (50.46x speedup from task ISPC)

(base) âžœ  prog3_mandelbrot_ispc git:(master) âœ— ./mandelbrot_ispc  --tasks  --view 2
[mandelbrot serial]:            [159.744] ms
Wrote image file mandelbrot-serial.ppm
[mandelbrot ispc]:              [37.937] ms
Wrote image file mandelbrot-ispc.ppm
[mandelbrot multicore ispc]:    [5.020] ms
Wrote image file mandelbrot-task-ispc.ppm                                                                                                                                                    (4.21x speedup from ISPC)                                                                                                                                    (31.82x speedup from task ISPC)
```
## Difference between launch and foreach in ISPC 

TLDR; both `launch` and `foreach` can do task parallelism. But 
`foreach` can use SIMD and `launch` can not do that itself.

The difference between `launch` and `foreach` in ISPC lies in the type of parallelism they express and how they are used:

- **`launch`**: This keyword is used to create a task that runs independently. When you use `launch`, you're telling ISPC to execute a function asynchronously, potentially on a different core. This is useful for task parallelism, where you have separate tasks that can run concurrently. For example:
  ```c
  launch myFunction();
  ```
  This will execute `myFunction` as a separate task.

- **`foreach`**: This construct is used for data parallelism, where the same operation is applied to multiple data elements in parallel. The `foreach` loop allows ISPC to execute iterations in parallel, utilizing SIMD vector units. For example:
  ```c
  foreach (i = 0 ... N) {
      // loop body
  }
  ```
  This will execute the loop body in parallel for each value of `i` from `0` to `N-1`.

In summary, `launch` is used for task parallelism to run independent tasks concurrently, while `foreach` is used for data parallelism to apply the same operation to multiple data elements in parallel. Both constructs help you write parallel code, but they are suited for different types of parallelism. ðŸ˜Š

 The `launch` construct in ISPC is primarily designed for task parallelism, which means it can run tasks in parallel on multiple cores. However, `launch` itself does not directly utilize SIMD parallelism. 

Here's a more detailed breakdown:
- **`launch`**: When you use `launch`, ISPC creates a new task that can run concurrently with other tasks. These tasks can be scheduled on different CPU cores, allowing for parallel execution. The focus of `launch` is on task-level parallelism, not on vectorization or SIMD parallelism.

- **`foreach`**: On the other hand, `foreach` is designed for data parallelism and can utilize both SIMD and multi-core parallelism. It vectorizes the loop to use SIMD instructions and also distributes the iterations across multiple cores.

While `launch` does not directly use SIMD, the tasks that are launched can themselves contain `foreach` loops or other code that uses SIMD parallelism. So, you can combine `launch` and `foreach` to achieve a mix of task parallelism and data parallelism. For example:
```c
void taskFunction(float* data, int N) {
    foreach (i = 0 ... N) {
        data[i] = data[i] * 2.0f;
    }
}

launch taskFunction(data, N);
```
In this example, `taskFunction` uses `foreach` to process data in parallel using SIMD, and `launch` runs `taskFunction` as a separate task on a different core.

Would you like to explore more about how to effectively combine `launch` and `foreach` in ISPC, or have any other questions? ðŸ˜Š
